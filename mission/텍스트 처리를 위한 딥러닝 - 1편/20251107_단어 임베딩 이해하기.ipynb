{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMln1rkxiTyTl7LXojkZB3x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4GguBwaky4d","executionInfo":{"status":"ok","timestamp":1762489757132,"user_tz":-540,"elapsed":8432,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"219f7394-63bc-4e6b-c472-589b1812e34b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from gensim.models import Word2Vec\n","import warnings\n","\n","# 경고 메시지 무시 (gensim 관련)\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"SHQghmLswvL6","executionInfo":{"status":"ok","timestamp":1762489774236,"user_tz":-540,"elapsed":6379,"user":{"displayName":"김광무","userId":"03808645168826839149"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osby0s5lkw9Q","executionInfo":{"status":"ok","timestamp":1762489833286,"user_tz":-540,"elapsed":277,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"3845018b-c641-4b9a-d563-4e92d72b5ff7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\n","# --- 2. 학습용 데이터 (Corpus) 준비 ---\n","# Word2Vec는 '문맥'을 학습해야 하므로, 여러 문장이 필요합니다.\n","corpus_text = \"\"\"\n","King Henry VIII was the ruler of England. Queen Elizabeth I was his daughter.\n","The man walked down the street. The woman watched him from the window.\n","France is a country in Europe. Paris is the capital of France.\n","Germany is also a country in Europe. Berlin is the capital of Germany.\n","I enjoy eating a fresh apple. An orange is also a tasty fruit.\n","\"\"\"\n","\n","print(\"--- 원본 텍스트 ---\")\n","print(corpus_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CgNf2BVlD3d","executionInfo":{"status":"ok","timestamp":1762489811921,"user_tz":-540,"elapsed":11,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"6f6ff241-258e-4fb0-b2fe-b28637b631f1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 원본 텍스트 ---\n","\n","King Henry VIII was the ruler of England. Queen Elizabeth I was his daughter.\n","The man walked down the street. The woman watched him from the window.\n","France is a country in Europe. Paris is the capital of France.\n","Germany is also a country in Europe. Berlin is the capital of Germany.\n","I enjoy eating a fresh apple. An orange is also a tasty fruit.\n","\n"]}]},{"cell_type":"code","source":["\n","# --- 3. 텍스트 전처리 ---\n","# Word2Vec는 '문장 리스트'를 입력으로 받으며,\n","# 각 문장은 '토큰 리스트'여야 합니다.\n","# (예: [['king', 'henry', ...], ['queen', 'elizabeth', ...], ...])\n","\n","sentences = sent_tokenize(corpus_text.lower())\n","tokenized_sentences = []\n","for sentence in sentences:\n","  tokens = word_tokenize(sentence)\n","  # 알파벳으로만 구성된 단어만 사용\n","  cleaned_tokens = [word for word in tokens if word.isalpha()]\n","  if cleaned_tokens: # 빈 리스트가 아닌 경우에만 추가\n","    tokenized_sentences.append(cleaned_tokens)\n","\n","print(\"\\n--- 전처리된 문장 (토큰 리스트의 리스트) ---\")\n","print(tokenized_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EixnVFLXlG_9","executionInfo":{"status":"ok","timestamp":1762489836885,"user_tz":-540,"elapsed":91,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"ea5c89f6-33e5-4cb4-cb14-6f9577164545"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 전처리된 문장 (토큰 리스트의 리스트) ---\n","[['king', 'henry', 'viii', 'was', 'the', 'ruler', 'of', 'england'], ['queen', 'elizabeth', 'i', 'was', 'his', 'daughter'], ['the', 'man', 'walked', 'down', 'the', 'street'], ['the', 'woman', 'watched', 'him', 'from', 'the', 'window'], ['france', 'is', 'a', 'country', 'in', 'europe'], ['paris', 'is', 'the', 'capital', 'of', 'france'], ['germany', 'is', 'also', 'a', 'country', 'in', 'europe'], ['berlin', 'is', 'the', 'capital', 'of', 'germany'], ['i', 'enjoy', 'eating', 'a', 'fresh', 'apple'], ['an', 'orange', 'is', 'also', 'a', 'tasty', 'fruit']]\n"]}]},{"cell_type":"code","source":["\n","# --- 4. Word2Vec 모델 학습 ---\n","print(\"\\n--- Word2Vec 모델 학습 시작 ---\")\n","\n","# Word2Vec 모델을 초기화하고 학습시킵니다.\n","# vector_size=100 : 단어를 100차원의 벡터로 표현\n","# window=5 : 현재 단어를 예측하기 위해 앞뒤 5개의 단어를 봄\n","# min_count=1 : 최소 1번 이상 등장한 단어만 학습\n","# sg=1 : Skip-Gram 모델 사용 (CBOW(0)보다 성능이 좋은 경향이 있음)\n","model = Word2Vec(\n","  sentences=tokenized_sentences,\n","  vector_size=100,\n","  window=5,\n","  min_count=1,\n","  sg=1, # 1: Skip-Gram, 0: CBOW\n","  workers=4 # 학습 시 사용할 CPU 코어 수\n",")\n","\n","# 학습된 어휘 수 확인\n","vocab = list(model.wv.key_to_index.keys())\n","print(f\"학습 완료. 총 {len(vocab)}개의 단어에 대한 임베딩 생성.\")\n","print(\"---------------------------------------\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7S-9RoUlNRA","executionInfo":{"status":"ok","timestamp":1762489850532,"user_tz":-540,"elapsed":27,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"15f93bfa-ba17-4413-bb13-b637900a9c92"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Word2Vec 모델 학습 시작 ---\n","학습 완료. 총 41개의 단어에 대한 임베딩 생성.\n","---------------------------------------\n"]}]},{"cell_type":"code","source":["# --- 5. 학습된 임베딩 활용 (과제 수행) ---\n","\n","# 5.1. 특정 단어의 임베딩 벡터 확인\n","try:\n","  king_vector = model.wv['king']\n","  print(f\"\\n'king'의 임베딩 벡터 (처음 5개 차원):\")\n","  print(king_vector[:5])\n","  print(f\"벡터 차원 수: {king_vector.shape[0]}\")\n","except KeyError:\n","  print(\"\\n'king'이 어휘 사전에 없습니다.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QXhTqZmlP6H","executionInfo":{"status":"ok","timestamp":1762489861402,"user_tz":-540,"elapsed":12,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"9e9b9edc-d987-4351-f389-d18ad27ea883"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","'king'의 임베딩 벡터 (처음 5개 차원):\n","[-0.00479407 -0.00431655 -0.0048006  -0.00980397 -0.00077741]\n","벡터 차원 수: 100\n"]}]},{"cell_type":"code","source":["\n","# 5.2. 유사한 단어 찾기 (model.wv.most_similar)\n","print(\"\\n--- 'king'과 가장 유사한 단어 Top 5 ---\")\n","#\n","try:\n","  similar_to_king = model.wv.most_similar('king', topn=5)\n","  for word, score in similar_to_king:\n","    print(f\"  {word}: {score:.4f}\")\n","except KeyError:\n","  print(\"'king'이 어휘 사전에 없습니다.\")\n","\n","print(\"\\n--- 'paris'와 가장 유사한 단어 Top 5 ---\")\n","try:\n","  similar_to_paris = model.wv.most_similar('paris', topn=5)\n","  for word, score in similar_to_paris:\n","    print(f\"  {word}: {score:.4f}\")\n","except KeyError:\n","  print(\"'paris'이 어휘 사전에 없습니다.\")\n","\n"],"metadata":{"id":"ZHUPOcBylTFm","executionInfo":{"status":"ok","timestamp":1762489874594,"user_tz":-540,"elapsed":22,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"7e5cffe5-f4c8-487c-ec30-32fac6fd712d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 'king'과 가장 유사한 단어 Top 5 ---\n","  queen: 0.2598\n","  woman: 0.2598\n","  window: 0.2220\n","  was: 0.1215\n","  is: 0.1178\n","\n","--- 'paris'와 가장 유사한 단어 Top 5 ---\n","  orange: 0.1966\n","  is: 0.1891\n","  man: 0.1425\n","  down: 0.1365\n","  window: 0.1074\n"]}]},{"cell_type":"code","source":["\n","# 5.3. 단어 간 유사도 계산 (model.wv.similarity)\n","print(\"\\n--- 단어 간 유사도 계산 (Cosine Similarity) ---\")\n","try:\n","  # 의미적으로 유사한 단어\n","  sim_king_queen = model.wv.similarity('king', 'queen')\n","  print(f\"  Similarity('king', 'queen'): {sim_king_queen:.4f}\")\n","\n","  # 의미적으로 관련 없는 단어\n","  sim_king_apple = model.wv.similarity('king', 'apple')\n","  print(f\"  Similarity('king', 'apple'): {sim_king_apple:.4f}\")\n","except KeyError as e:\n","  print(f\"유사도 계산 실패: {e} 단어가 어휘 사전에 없습니다.\")\n","\n"],"metadata":{"id":"Rdlx3afQlVO9","executionInfo":{"status":"ok","timestamp":1762489882803,"user_tz":-540,"elapsed":44,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"14dccba1-2b59-459a-cc6c-fb8b35c948a0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 단어 간 유사도 계산 (Cosine Similarity) ---\n","  Similarity('king', 'queen'): 0.2598\n","  Similarity('king', 'apple'): 0.0217\n"]}]},{"cell_type":"code","source":["\n","\n","\n","# 5.4. (보너스) 단어 유추 (벡터 연산)\n","# Word2Vec의 가장 유명한 특징: 'king' - 'man' + 'woman' = ?\n","print(\"\\n--- 단어 유추 (벡터 연산) ---\")\n","print(\"  'king' - 'man' + 'woman' = ?\")\n","try:\n","  #\n","  result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n","  print(f\"  => {result[0][0]} (유사도: {result[0][1]:.4f})\")\n","except KeyError:\n","  print(\"  (계산에 필요한 단어가 어휘 사전에 없습니다.)\")\n","\n","print(\"\\n  'paris' - 'france' + 'germany' = ?\")\n","try:\n","  result = model.wv.most_similar(positive=['paris', 'germany'], negative=['france'], topn=1)\n","  print(f\"  => {result[0][0]} (유사도: {result[0][1]:.4f})\")\n","except KeyError:\n","  print(\"  (계산에 필요한 단어가 어휘 사전에 없습니다.)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sx3GcJjRkqTq","executionInfo":{"status":"ok","timestamp":1762489890836,"user_tz":-540,"elapsed":12,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"7b3bf493-cf55-4245-aa5d-16e02e3bd6c0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 단어 유추 (벡터 연산) ---\n","  'king' - 'man' + 'woman' = ?\n","  => in (유사도: 0.1891)\n","\n","  'paris' - 'france' + 'germany' = ?\n","  => also (유사도: 0.2200)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jK6Xh_AelXcr"},"execution_count":null,"outputs":[]}]}