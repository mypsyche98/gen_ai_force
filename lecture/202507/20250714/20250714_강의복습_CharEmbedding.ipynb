{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181525,
     "status": "ok",
     "timestamp": 1752478602284,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "ZLxzvrfy2oiq",
    "outputId": "b5147e68-5572-45a8-ab3d-d948b26eac20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.18.0\n",
      "Uninstalling tensorflow-2.18.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/import_pb_to_tensorboard\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/bin/toco_from_protos\n",
      "    /usr/local/lib/python3.11/dist-packages/tensorflow-2.18.0.dist-info/*\n",
      "    /usr/local/lib/python3.11/dist-packages/tensorflow/*\n",
      "Proceed (Y/n)? y\n",
      "  Successfully uninstalled tensorflow-2.18.0\n",
      "\u001b[33mWARNING: Skipping tensorflow-addons as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: keras 3.8.0\n",
      "Uninstalling keras-3.8.0:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.11/dist-packages/keras-3.8.0.dist-info/*\n",
      "    /usr/local/lib/python3.11/dist-packages/keras/*\n",
      "Proceed (Y/n)? y\n",
      "  Successfully uninstalled keras-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow tensorflow-addons keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 66391,
     "status": "ok",
     "timestamp": 1752478671858,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "DDcU5ys42odG",
    "outputId": "beb9df4e-6cd2-4526-a6fe-13ed3b3fef99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15.0\n",
      "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.14.1)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.73.1)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.1)\n",
      "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.17.2\n",
      "    Uninstalling wrapt-1.17.2:\n",
      "      Successfully uninstalled wrapt-1.17.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.4.1\n",
      "    Uninstalling ml-dtypes-0.4.1:\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
      "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
      "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "dcdf13130c8c4da1b556ef0a3c87cf6f",
       "pip_warning": {
        "packages": [
         "google",
         "keras",
         "ml_dtypes",
         "numpy",
         "tensorflow",
         "wrapt"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14980,
     "status": "ok",
     "timestamp": 1752478696037,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "_2yLQYgN2oVt",
    "outputId": "6503343e-1bc5-4420-c632-e9564e9ce708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 4.4.4\n",
      "    Uninstalling typeguard-4.4.4:\n",
      "      Successfully uninstalled typeguard-4.4.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5603,
     "status": "ok",
     "timestamp": 1752478712435,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "5rapcspn2sfR",
    "outputId": "245f7011-ec6b-48b1-c73a-53e7341748e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-crf\n",
      "  Downloading keras_crf-0.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from keras-crf) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (from keras-crf) (0.23.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (4.25.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (4.14.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (1.73.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-crf) (2.15.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->keras-crf) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (1.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (2025.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-crf) (3.3.1)\n",
      "Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
      "Installing collected packages: keras-crf\n",
      "Successfully installed keras-crf-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1752479292728,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "kFyPs5_0Fhen"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mypsyche/Downloads\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1752479293984,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "OHQh4U6aFoNj",
    "outputId": "0c4cd83d-b285-460c-9b58-b7a72c6fba34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"BiLSTM_BER/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752479294543,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "a5AL3DqzFsfL",
    "outputId": "585813f7-c2eb-475d-9cab-a60a40eceea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터프레임 행의 개수 : 1048575\n"
     ]
    }
   ],
   "source": [
    "print('데이터프레임 행의 개수 : {}'.format(len(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1752479295436,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "FlXGKVepFuF0",
    "outputId": "2c0c537b-2f20-4656-c26c-c7f7c1759b62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : True\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1752479296126,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "QenpUYGwFvN2",
    "outputId": "a676483d-eb0a-4249-e36e-5f42ba78eedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어떤 열에 Null값이 있는지 출력\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentence #    1000616\n",
       "Word               10\n",
       "POS                 0\n",
       "Tag                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('어떤 열에 Null값이 있는지 출력')\n",
    "print('==============================')\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1752479296914,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "vpSJDnb8Fw6H",
    "outputId": "a107f5a8-0423-4543-87b6-a6a02c4ae356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence # 열의 중복을 제거한 값의 개수 : 47959\n",
      "Word 열의 중복을 제거한 값의 개수 : 35177\n",
      "Tag 열의 중복을 제거한 값의 개수 : 17\n"
     ]
    }
   ],
   "source": [
    "print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n",
    "print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1752479297326,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "jNc7pH5dF1SR",
    "outputId": "5525d0a3-58d0-4603-eaf3-ff6c25f34d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 열의 각각의 값의 개수 카운트\n",
      "================================\n",
      "      Tag   count\n",
      "0   B-art     402\n",
      "1   B-eve     308\n",
      "2   B-geo   37644\n",
      "3   B-gpe   15870\n",
      "4   B-nat     201\n",
      "5   B-org   20143\n",
      "6   B-per   16990\n",
      "7   B-tim   20333\n",
      "8   I-art     297\n",
      "9   I-eve     253\n",
      "10  I-geo    7414\n",
      "11  I-gpe     198\n",
      "12  I-nat      51\n",
      "13  I-org   16784\n",
      "14  I-per   17251\n",
      "15  I-tim    6528\n",
      "16      O  887908\n"
     ]
    }
   ],
   "source": [
    "print('Tag 열의 각각의 값의 개수 카운트')\n",
    "print('================================')\n",
    "print(data.groupby('Tag').size().reset_index(name='count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1752479298547,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "NctmypxaF3nK",
    "outputId": "632fac36-9e4f-4fb9-b1fb-96a138f3c84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Sentence #       Word  POS Tag\n",
      "1048570  Sentence: 47959       they  PRP   O\n",
      "1048571  Sentence: 47959  responded  VBD   O\n",
      "1048572  Sentence: 47959         to   TO   O\n",
      "1048573  Sentence: 47959        the   DT   O\n",
      "1048574  Sentence: 47959     attack   NN   O\n"
     ]
    }
   ],
   "source": [
    "data = data.ffill()\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1752479299345,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "A_2CplyKF86x",
    "outputId": "bd290917-5bb9-4015-c6fc-0a4607c6803d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터에 Null 값이 있는지 유무 : False\n"
     ]
    }
   ],
   "source": [
    "print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1752479300143,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "oSMAJDEjGEEd",
    "outputId": "1594c166-1ed5-4762-f687-f7a2dd1ad50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 열의 중복을 제거한 값의 개수 : 31817\n"
     ]
    }
   ],
   "source": [
    "data['Word'] = data['Word'].str.lower()\n",
    "print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1752479300392,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "u_D3wtqOGFx2",
    "outputId": "c3f76654-6fdb-4ec6-fe49-f2cbb5d051ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      thousands  NNS   O\n",
      "1  Sentence: 1             of   IN   O\n",
      "2  Sentence: 1  demonstrators  NNS   O\n",
      "3  Sentence: 1           have  VBP   O\n",
      "4  Sentence: 1        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "print(data[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6242,
     "status": "ok",
     "timestamp": 1752479307207,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "yfsC9WkeGHTi",
    "outputId": "87d93427-59f2-4906-d382-98a04841999d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수: 47959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/3r49bs6178v7nfhcxh7lpzd80000gn/T/ipykernel_10049/3510394031.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n"
     ]
    }
   ],
   "source": [
    "func = lambda temp: [(w, t) for w, t in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
    "tagged_sentences=[t for t in data.groupby(\"Sentence #\").apply(func)]\n",
    "print(\"전체 샘플 개수: {}\".format(len(tagged_sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1752479308581,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "WEPXwF3vGIs-",
    "outputId": "a0917f90-3d9c-42e6-93fc-68fab16effbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0]) # 첫번째 샘플 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1752479310184,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "da-IbeKxHrxU"
   },
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], []\n",
    "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
    "\n",
    "    # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentence, tag_info = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752479310189,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "xNBi58RsHtnJ",
    "outputId": "e4d6331a-2db2-465b-9579-feec8ac8d5b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(ner_tags[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1752479311979,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "lSIwU46fHzo5"
   },
   "outputs": [],
   "source": [
    "# 모든 단어를 사용하며 인덱스 1에는 단어 'OOV'를 할당.\n",
    "src_tokenizer = Tokenizer(oov_token='OOV')\n",
    "# 태깅 정보들은 내부적으로 대문자를 유지한 채 저장\n",
    "tar_tokenizer = Tokenizer(lower=False)\n",
    "\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "tar_tokenizer.fit_on_texts(ner_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752479311996,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "-2y64D56H1nV",
    "outputId": "8eff8852-ae6b-47a1-ca87-4e07c4bf872f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 31819\n",
      "개체명 태깅 정보 집합의 크기 : 18\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1752479312612,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "VNaOxbOyH7Bf",
    "outputId": "d90fd598-b54f-48cd-9062-9646c0799726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 OOV의 인덱스 : 1\n"
     ]
    }
   ],
   "source": [
    "print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1752479313884,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "tVIQPa6BH8_M",
    "outputId": "e3a93b54-a1cd-488b-a262-59dbef35c6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
      "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tar_tokenizer.texts_to_sequences(ner_tags)\n",
    "print(X_data[0])\n",
    "print(y_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1752479314133,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "Aw8YjB3BIAVq",
    "outputId": "b82f0d67-94f5-4f83-c535-4a8986fcbc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'O', 2: 'B-geo', 3: 'B-tim', 4: 'B-org', 5: 'I-per', 6: 'B-per', 7: 'I-org', 8: 'B-gpe', 9: 'I-geo', 10: 'I-tim', 11: 'B-art', 12: 'B-eve', 13: 'I-art', 14: 'I-eve', 15: 'B-nat', 16: 'I-gpe', 17: 'I-nat', 0: 'PAD'}\n"
     ]
    }
   ],
   "source": [
    "word_to_index = src_tokenizer.word_index\n",
    "index_to_word = src_tokenizer.index_word\n",
    "ner_to_index = tar_tokenizer.word_index\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "print(index_to_ner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1752479316428,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "ddYadFSEICXV",
    "outputId": "3f33b6b2-d250-4717-be17-a1647351ebd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "디코딩 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print('기존의 문장 : {}'.format(sentences[0]))\n",
    "print('디코딩 문장 : {}'.format(decoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1752479318634,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "jhTKj3eqIELQ",
    "outputId": "0370965e-0c9a-496f-f859-55be0867089a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(정수 인코딩)의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블(원-핫 인코딩)의 크기 : (38367, 70, 18)\n",
      "테스트 샘플 문장의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(정수 인코딩)의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블(원-핫 인코딩)의 크기 : (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "max_len = 70\n",
    "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
    "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)\n",
    "X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)\n",
    "y_train = to_categorical(y_train_int, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test_int, num_classes=tag_size)\n",
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))\n",
    "print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))\n",
    "print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1752479319692,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "oNP0zK7m1W78",
    "outputId": "f0718c97-e8b1-4008-95bc-f5b6eb079596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 : ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
     ]
    }
   ],
   "source": [
    "# char_vocab 만들기\n",
    "words = list(set(data[\"Word\"].values))\n",
    "chars = set([w_i for w in words for w_i in w])\n",
    "chars = sorted(list(chars))\n",
    "print('문자 집합 :',chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1752479320917,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "ewsTMx7Z1W5E"
   },
   "outputs": [],
   "source": [
    "char_to_index = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char_to_index[\"OOV\"] = 1\n",
    "char_to_index[\"PAD\"] = 0\n",
    "\n",
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3470,
     "status": "ok",
     "timestamp": 1752479325955,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "eeQuU3Tn1W2q"
   },
   "outputs": [],
   "source": [
    "max_len_char = 15\n",
    "\n",
    "# 문자 시퀀스에 대한 패딩하는 함수\n",
    "def padding_char_indice(char_indice, max_len_char):\n",
    "  return pad_sequences(\n",
    "        char_indice, maxlen=max_len_char, padding='post', value = 0)\n",
    "\n",
    "# 각 단어를 문자 시퀀스로 변환 후 패딩 진행\n",
    "def integer_coding(sentences):\n",
    "  char_data = []\n",
    "  for ts in sentences:\n",
    "    word_indice = [word_to_index[t] for t in ts]\n",
    "    char_indice = [[char_to_index[char] for char in t]\n",
    "                                          for t in ts]\n",
    "    char_indice = padding_char_indice(char_indice, max_len_char)\n",
    "\n",
    "    for chars_of_token in char_indice:\n",
    "      if len(chars_of_token) > max_len_char:\n",
    "        continue\n",
    "    char_data.append(char_indice)\n",
    "  return char_data\n",
    "\n",
    "# 문자 단위 정수 인코딩 결과\n",
    "X_char_data = integer_coding(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1752479328209,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "Y1fSanMe1W0c",
    "outputId": "53508cb3-ec79-42e7-f765-cae3ad8ca70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장 : ['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 이전의 기존 문장\n",
    "print('기존 문장 :',sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752479329859,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "-p8inmMb5S0m",
    "outputId": "484cea3b-1e61-49b6-d60e-1478927d4a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 단 어 단 위 정 수 인 코 딩 :\n",
      "[ 254    6  967   16 1795  238  468    7  523    2  129    5   61    9\n",
      "  571    2  833    6  186   90   22   15   56    3    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 단 어 단 위 정 수 인 코 딩 + 패 딩\n",
    "print(' 단 어 단 위 정 수 인 코 딩 :')\n",
    "print(X_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1752479333057,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "eysegPmW1WyD",
    "outputId": "03c58e3e-e7f7-439d-e576-7955a2368dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 단위 정수 인코딩 :\n",
      "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
      " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
      " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
      " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
      " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
      " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
      " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
      " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
      " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
      " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
      " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위 정수 인코딩 + 패딩\n",
    "print('단어 단위 정수 인코딩 :')\n",
    "print(X_char_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1752479336084,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "aDJnibMz1Wvc"
   },
   "outputs": [],
   "source": [
    "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1752479337420,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "IgXSRIDz1Ws4"
   },
   "outputs": [],
   "source": [
    "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, y_data, test_size=.2, random_state=777)\n",
    "\n",
    "X_char_train = np.array(X_char_train)\n",
    "X_char_test = np.array(X_char_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752479338684,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "Kevu9JP21Wng",
    "outputId": "03886406-b400-4337-eafb-50d9d4b679e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 [[52 48 45 ...  0  0  0]\n",
      " [51 38 53 ...  0  0  0]\n",
      " [39 42 51 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_char_train[0]), X_char_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1752479341444,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "zSGV6c_l1Wd3",
    "outputId": "2c4fbd92-bd94-4d1d-d198-b668cdc0d07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752479342402,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "weTC1xQQ2E9K",
    "outputId": "d76e27d4-570a-49e4-f36c-09081cbbca87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s o l d i e r s PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([index_to_char[index] for index in X_char_train[0][0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752479343992,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "DgHImZ202E6g",
    "outputId": "0cff66eb-c6b5-45a3-89a9-bd26c94f3090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (38367, 70)\n",
      "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
      "훈련 샘플 char 데이터의 크기 : (38367, 70, 15)\n",
      "테스트 샘플 문장의 크기 : (9592, 70)\n",
      "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11395,
     "status": "ok",
     "timestamp": 1752478827096,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "RTmCpuThIfxI",
    "outputId": "84464657-d395-4547-a2fa-12228d5431c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=378ea0e306a2ef84e4f1aca23c502600db524b12083e119a8fcd5e9855be3ef3\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1752479352809,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "c7thHL602E3-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow_215/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from keras_crf import CRFModel\n",
    "\n",
    "embedding_dim = 128\n",
    "char_embedding_dim = 64\n",
    "dropout_ratio = 0.5\n",
    "hidden_units = 256\n",
    "num_filters = 30\n",
    "kernel_size = 3\n",
    "\n",
    "# 단어 임베딩\n",
    "word_ids = Input(shape=(None,),dtype='int32', name='words_input')\n",
    "word_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(word_ids)\n",
    "\n",
    "# char 임베딩\n",
    "char_ids = Input(shape=(None, max_len_char,), name='char_input')\n",
    "embed_char_out = TimeDistributed(Embedding(len(char_to_index), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(char_ids)\n",
    "dropout = Dropout(dropout_ratio)(embed_char_out)\n",
    "\n",
    "# char 임베딩에 대해서는 Conv1D 수행\n",
    "conv1d_out = TimeDistributed(Conv1D(kernel_size=kernel_size, filters=num_filters, padding='same', activation='tanh', strides=1))(dropout)\n",
    "maxpool_out = TimeDistributed(MaxPooling1D(max_len_char))(conv1d_out)\n",
    "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
    "char_embeddings = Dropout(dropout_ratio)(char_embeddings)\n",
    "\n",
    "# char 임베딩을 Conv1D 수행한 뒤에 단어 임베딩과 연결\n",
    "output = concatenate([word_embeddings, char_embeddings])\n",
    "\n",
    "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
    "output = Bidirectional(LSTM(hidden_units, return_sequences=True, dropout=dropout_ratio))(output)\n",
    "\n",
    "# 출력층\n",
    "output = TimeDistributed(Dense(tag_size, activation='softmax'))(output)\n",
    "\n",
    "model = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam',  metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkvRESMz2E1f",
    "outputId": "7ec138cb-1fb8-4780-ce5b-ce1bcc368a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2006 - acc: 0.9493\n",
      "Epoch 1: val_acc improved from -inf to 0.97632, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 77s 281ms/step - loss: 0.2006 - acc: 0.9493 - val_loss: 0.0867 - val_acc: 0.9763\n",
      "Epoch 2/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0645 - acc: 0.9816\n",
      "Epoch 2: val_acc improved from 0.97632 to 0.98481, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 76s 280ms/step - loss: 0.0645 - acc: 0.9816 - val_loss: 0.0524 - val_acc: 0.9848\n",
      "Epoch 3/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9866\n",
      "Epoch 3: val_acc improved from 0.98481 to 0.98657, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 76s 280ms/step - loss: 0.0457 - acc: 0.9866 - val_loss: 0.0453 - val_acc: 0.9866\n",
      "Epoch 4/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9886\n",
      "Epoch 4: val_acc improved from 0.98657 to 0.98705, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 74s 272ms/step - loss: 0.0382 - acc: 0.9886 - val_loss: 0.0426 - val_acc: 0.9870\n",
      "Epoch 5/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0335 - acc: 0.9899\n",
      "Epoch 5: val_acc improved from 0.98705 to 0.98770, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 74s 274ms/step - loss: 0.0335 - acc: 0.9899 - val_loss: 0.0404 - val_acc: 0.9877\n",
      "Epoch 6/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.9906\n",
      "Epoch 6: val_acc did not improve from 0.98770\n",
      "270/270 [==============================] - 76s 282ms/step - loss: 0.0304 - acc: 0.9906 - val_loss: 0.0402 - val_acc: 0.9877\n",
      "Epoch 7/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0281 - acc: 0.9913\n",
      "Epoch 7: val_acc improved from 0.98770 to 0.98795, saving model to 20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras\n",
      "270/270 [==============================] - 72s 265ms/step - loss: 0.0281 - acc: 0.9913 - val_loss: 0.0398 - val_acc: 0.9880\n",
      "Epoch 8/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.9918\n",
      "Epoch 8: val_acc did not improve from 0.98795\n",
      "270/270 [==============================] - 71s 262ms/step - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "Epoch 9/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0245 - acc: 0.9922\n",
      "Epoch 9: val_acc did not improve from 0.98795\n",
      "270/270 [==============================] - 63s 233ms/step - loss: 0.0245 - acc: 0.9922 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "Epoch 10/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0231 - acc: 0.9926\n",
      "Epoch 10: val_acc did not improve from 0.98795\n",
      "270/270 [==============================] - 63s 233ms/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "Epoch 11/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0217 - acc: 0.9930\n",
      "Epoch 11: val_acc did not improve from 0.98795\n",
      "270/270 [==============================] - 62s 230ms/step - loss: 0.0217 - acc: 0.9930 - val_loss: 0.0420 - val_acc: 0.9876\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit([X_train, X_char_train], y_train, batch_size=128, epochs=15, validation_split=0.1, verbose=1, callbacks=[es, mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FteyprQH2Ewq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "model = load_model('20250714_강의복습_CharEmbedding_BiLSTM_CNN.keras')\n",
    "\n",
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])\n",
    "\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경.\n",
    "labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 정수 인코딩으로 변경.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)\n",
    "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "A_GSu3Or2EuN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 9s 31ms/step\n",
      "F1-score: 79.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow_215/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        63\n",
      "         eve       0.73      0.21      0.33        52\n",
      "         geo       0.82      0.87      0.84      7620\n",
      "         gpe       0.95      0.94      0.95      3145\n",
      "         nat       0.00      0.00      0.00        37\n",
      "         org       0.61      0.55      0.58      4033\n",
      "         per       0.74      0.73      0.73      3545\n",
      "         tim       0.86      0.83      0.85      4067\n",
      "\n",
      "   micro avg       0.80      0.79      0.79     22562\n",
      "   macro avg       0.59      0.52      0.53     22562\n",
      "weighted avg       0.79      0.79      0.79     22562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict([X_test, X_char_test])\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvLvCFfv6aGV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMP9XHqkrjefRVh3YyR3ZRa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
