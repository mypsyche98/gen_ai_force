{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6029,
     "status": "ok",
     "timestamp": 1752558941680,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "oJWRnk7DRWsm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib3\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2598,
     "status": "ok",
     "timestamp": 1752558944281,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "QjpVnDGwpvqZ",
    "outputId": "683ba6ca-5ff2-4e25-fb5f-f53208305f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file downloaded to fra-eng.zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def download_zip(url, output_path):\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"ZIP file downloaded to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n",
    "\n",
    "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "output_path = \"fra-eng.zip\"\n",
    "download_zip(url, output_path)\n",
    "\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, output_path)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1752558963758,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "cldmr2jlpx70",
    "outputId": "7fd56c54-74b1-406f-bcc4-02ecf2bf30a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 237838\n"
     ]
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "print('전체 샘플의 개수 :',len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1752558972661,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "KA779WfMp4ft",
    "outputId": "143fe400-923c-419b-c684-2b4f40909342"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24959</th>\n",
       "      <td>You are not kind.</td>\n",
       "      <td>Vous n'êtes pas gentil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41267</th>\n",
       "      <td>I did it many times.</td>\n",
       "      <td>Je l'ai fait de nombreuses fois.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57607</th>\n",
       "      <td>I can't give you that.</td>\n",
       "      <td>Je ne peux pas te donner ça.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295</th>\n",
       "      <td>Goodnight, ladies.</td>\n",
       "      <td>Bonsoir Mesdames !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55096</th>\n",
       "      <td>You can count on Tom.</td>\n",
       "      <td>Tu peux compter sur Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49041</th>\n",
       "      <td>I can barely breathe.</td>\n",
       "      <td>Je peux à peine respirer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11949</th>\n",
       "      <td>I'll be direct.</td>\n",
       "      <td>Je serai direct.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7247</th>\n",
       "      <td>Are you young?</td>\n",
       "      <td>Es-tu jeune ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47397</th>\n",
       "      <td>Are your hands clean?</td>\n",
       "      <td>Vos mains sont-elles propres ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>I'm taller.</td>\n",
       "      <td>Je suis plus grand.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                               tar\n",
       "24959       You are not kind.           Vous n'êtes pas gentil.\n",
       "41267    I did it many times.  Je l'ai fait de nombreuses fois.\n",
       "57607  I can't give you that.      Je ne peux pas te donner ça.\n",
       "26295      Goodnight, ladies.                Bonsoir Mesdames !\n",
       "55096   You can count on Tom.          Tu peux compter sur Tom.\n",
       "49041   I can barely breathe.         Je peux à peine respirer.\n",
       "11949         I'll be direct.                  Je serai direct.\n",
       "7247           Are you young?                     Es-tu jeune ?\n",
       "47397   Are your hands clean?    Vos mains sont-elles propres ?\n",
       "2299              I'm taller.               Je suis plus grand."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1752558985361,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "SifH0QBZp65h",
    "outputId": "86543455-bf3b-40c7-ed61-7fe11f01df7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41785</th>\n",
       "      <td>I left school early.</td>\n",
       "      <td>\\t J'ai quitté tôt l'école. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>Let me pay.</td>\n",
       "      <td>\\t Laisse-moi payer. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34851</th>\n",
       "      <td>I wasn't sick then.</td>\n",
       "      <td>\\t Je n'étais pas malade à l'époque. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>Bring a shovel.</td>\n",
       "      <td>\\t Apporte une pelle ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22182</th>\n",
       "      <td>It needs washing.</td>\n",
       "      <td>\\t On doit le laver. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>I'm a bit late.</td>\n",
       "      <td>\\t Je suis un peu en retard. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50411</th>\n",
       "      <td>I was up before dawn.</td>\n",
       "      <td>\\t J'étais debout avant l'aube. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>We're Canadians.</td>\n",
       "      <td>\\t Nous sommes Canadiens. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23108</th>\n",
       "      <td>That's about all.</td>\n",
       "      <td>\\t C'est à peu près tout. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13952</th>\n",
       "      <td>We're the same.</td>\n",
       "      <td>\\t Nous sommes pareils. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                                      tar\n",
       "41785   I left school early.           \\t J'ai quitté tôt l'école. \\n\n",
       "2441             Let me pay.                  \\t Laisse-moi payer. \\n\n",
       "34851    I wasn't sick then.  \\t Je n'étais pas malade à l'époque. \\n\n",
       "10603        Bring a shovel.                \\t Apporte une pelle ! \\n\n",
       "22182      It needs washing.                  \\t On doit le laver. \\n\n",
       "12003        I'm a bit late.          \\t Je suis un peu en retard. \\n\n",
       "50411  I was up before dawn.       \\t J'étais debout avant l'aube. \\n\n",
       "18654       We're Canadians.             \\t Nous sommes Canadiens. \\n\n",
       "23108      That's about all.             \\t C'est à peu près tout. \\n\n",
       "13952        We're the same.               \\t Nous sommes pareils. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1752559002854,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "kAca3Wccp9-s"
   },
   "outputs": [],
   "source": [
    "# 문자 집합 구축\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 문자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752559005555,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "WAReaU1wqCOO",
    "outputId": "6ef7104e-04d2-4e6f-e42d-73dc317e4b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 char 집합 : 80\n",
      "target 문장의 char 집합 : 102\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print('source 문장의 char 집합 :',src_vocab_size)\n",
    "print('target 문장의 char 집합 :',tar_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1752559022837,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "v7JcNcrkqC8a",
    "outputId": "9d568fd1-b5b7-4881-beac-851179e41417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752559033986,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "VXQxnxeWqHKW",
    "outputId": "842bb4ca-4cec-4703-dcf0-b2c7f4c139c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, 'ï': 77, '’': 78, '€': 79}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, ',': 10, '-': 11, '.': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '«': 77, '»': 78, 'À': 79, 'Ç': 80, 'É': 81, 'Ê': 82, 'Ô': 83, 'à': 84, 'â': 85, 'ç': 86, 'è': 87, 'é': 88, 'ê': 89, 'ë': 90, 'î': 91, 'ï': 92, 'ô': 93, 'ù': 94, 'û': 95, 'œ': 96, '\\u2009': 97, '‘': 98, '’': 99, '\\u202f': 100, '‽': 101}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1752559045668,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "pdN3djKPqJ4m",
    "outputId": "5992839f-d807-4bfa-ffa8-f21e7cfe75e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "# 1개의 문장\n",
    "for line in lines.src:\n",
    "  encoded_line = []\n",
    "  # 각 줄에서 1개의 char\n",
    "  for char in line:\n",
    "    # 각 char을 정수로 변환\n",
    "    encoded_line.append(src_to_index[char])\n",
    "  encoder_input.append(encoded_line)\n",
    "print('source 문장의 정수 인코딩 :',encoder_input[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1752559118810,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "upAZF7sTqeJB",
    "outputId": "00f1e365-d912-47d3-e7e5-c6f8304e7c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장의 정수 인코딩 : [[1, 3, 46, 50, 3, 4, 3, 2], [1, 3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [1, 3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [1, 3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [1, 3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    encoded_line.append(tar_to_index[char])\n",
    "  decoder_input.append(encoded_line)\n",
    "print('target 문장의 정수 인코딩 :',decoder_input[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1752559054062,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "_hCSMM3NqMpJ",
    "outputId": "44715f1d-118b-4a9d-d70b-ada074dfa6af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장 레이블의 정수 인코딩 : [[3, 46, 50, 3, 4, 3, 2], [3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "  timestep = 0\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    if timestep > 0:\n",
    "      encoded_line.append(tar_to_index[char])\n",
    "    timestep = timestep + 1\n",
    "  decoder_target.append(encoded_line)\n",
    "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752559069341,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "kyNh_OOoqOsn",
    "outputId": "68aa8582-7c4b-4781-9591-02db64298447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 최대 길이 : 22\n",
      "target 문장의 최대 길이 : 76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('source 문장의 최대 길이 :',max_src_len)\n",
    "print('target 문장의 최대 길이 :',max_tar_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1752559122425,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "6U278lwpqSgv"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4978,
     "status": "ok",
     "timestamp": 1752559134691,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "9D31MB3ZqUDE"
   },
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1752559142464,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "ZiVLmX_YqhQU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "\n",
    "# encoder_outputs은 여기서는 불필요\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1752559186670,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "fVAZvQIPqkVm"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fuh2bHQmqvJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "750/750 [==============================] - 97s 128ms/step - loss: 0.7227 - val_loss: 0.6383\n",
      "Epoch 2/40\n",
      "750/750 [==============================] - 91s 122ms/step - loss: 0.4497 - val_loss: 0.5123\n",
      "Epoch 3/40\n",
      "750/750 [==============================] - 91s 121ms/step - loss: 0.3777 - val_loss: 0.4575\n",
      "Epoch 4/40\n",
      "750/750 [==============================] - 94s 126ms/step - loss: 0.3347 - val_loss: 0.4190\n",
      "Epoch 5/40\n",
      "750/750 [==============================] - 98s 131ms/step - loss: 0.3063 - val_loss: 0.3916\n",
      "Epoch 6/40\n",
      "750/750 [==============================] - 97s 129ms/step - loss: 0.2856 - val_loss: 0.3771\n",
      "Epoch 7/40\n",
      "750/750 [==============================] - 100s 134ms/step - loss: 0.2696 - val_loss: 0.3633\n",
      "Epoch 8/40\n",
      "750/750 [==============================] - 100s 133ms/step - loss: 0.2568 - val_loss: 0.3540\n",
      "Epoch 9/40\n",
      "750/750 [==============================] - 102s 135ms/step - loss: 0.2459 - val_loss: 0.3468\n",
      "Epoch 10/40\n",
      "750/750 [==============================] - 111s 148ms/step - loss: 0.2368 - val_loss: 0.3402\n",
      "Epoch 11/40\n",
      "750/750 [==============================] - 111s 148ms/step - loss: 0.2287 - val_loss: 0.3375\n",
      "Epoch 12/40\n",
      "750/750 [==============================] - 138s 184ms/step - loss: 0.2216 - val_loss: 0.3343\n",
      "Epoch 13/40\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 0.2151 - val_loss: 0.3330\n",
      "Epoch 14/40\n",
      "750/750 [==============================] - 103s 137ms/step - loss: 0.2092 - val_loss: 0.3291\n",
      "Epoch 15/40\n",
      "750/750 [==============================] - 107s 142ms/step - loss: 0.2039 - val_loss: 0.3289\n",
      "Epoch 16/40\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 0.1990 - val_loss: 0.3293\n",
      "Epoch 17/40\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 0.1943 - val_loss: 0.3291\n",
      "Epoch 18/40\n",
      "750/750 [==============================] - 108s 144ms/step - loss: 0.1900 - val_loss: 0.3293\n",
      "Epoch 19/40\n",
      "750/750 [==============================] - 99s 132ms/step - loss: 0.1861 - val_loss: 0.3288\n",
      "Epoch 20/40\n",
      "750/750 [==============================] - 104s 139ms/step - loss: 0.1821 - val_loss: 0.3309\n",
      "Epoch 21/40\n",
      "750/750 [==============================] - 101s 134ms/step - loss: 0.1786 - val_loss: 0.3310\n",
      "Epoch 22/40\n",
      "750/750 [==============================] - 102s 136ms/step - loss: 0.1751 - val_loss: 0.3318\n",
      "Epoch 23/40\n",
      "750/750 [==============================] - 102s 136ms/step - loss: 0.1720 - val_loss: 0.3331\n",
      "Epoch 24/40\n",
      "750/750 [==============================] - 106s 141ms/step - loss: 0.1688 - val_loss: 0.3362\n",
      "Epoch 25/40\n",
      "750/750 [==============================] - 104s 138ms/step - loss: 0.1659 - val_loss: 0.3384\n",
      "Epoch 26/40\n",
      "750/750 [==============================] - 95s 127ms/step - loss: 0.1630 - val_loss: 0.3383\n",
      "Epoch 27/40\n",
      "750/750 [==============================] - 100s 134ms/step - loss: 0.1603 - val_loss: 0.3411\n",
      "Epoch 28/40\n",
      "750/750 [==============================] - 101s 134ms/step - loss: 0.1578 - val_loss: 0.3433\n",
      "Epoch 29/40\n",
      "750/750 [==============================] - 102s 135ms/step - loss: 0.1553 - val_loss: 0.3462\n",
      "Epoch 30/40\n",
      "750/750 [==============================] - 103s 138ms/step - loss: 0.1530 - val_loss: 0.3468\n",
      "Epoch 31/40\n",
      "750/750 [==============================] - 106s 142ms/step - loss: 0.1508 - val_loss: 0.3490\n",
      "Epoch 32/40\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 0.1486 - val_loss: 0.3525\n",
      "Epoch 33/40\n",
      "750/750 [==============================] - 111s 148ms/step - loss: 0.1466 - val_loss: 0.3523\n",
      "Epoch 34/40\n",
      "750/750 [==============================] - 105s 141ms/step - loss: 0.1444 - val_loss: 0.3556\n",
      "Epoch 35/40\n",
      "750/750 [==============================] - 104s 138ms/step - loss: 0.1426 - val_loss: 0.3577\n",
      "Epoch 36/40\n",
      "750/750 [==============================] - 109s 145ms/step - loss: 0.1407 - val_loss: 0.3610\n",
      "Epoch 37/40\n",
      "750/750 [==============================] - 107s 143ms/step - loss: 0.1388 - val_loss: 0.3643\n",
      "Epoch 38/40\n",
      "750/750 [==============================] - 109s 145ms/step - loss: 0.1372 - val_loss: 0.3661\n",
      "Epoch 39/40\n",
      "750/750 [==============================] - 108s 144ms/step - loss: 0.1354 - val_loss: 0.3669\n",
      "Epoch 40/40\n",
      "750/750 [==============================] - 112s 149ms/step - loss: 0.1338 - val_loss: 0.3708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3586e6cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "fYYZazdPqxMK"
   },
   "outputs": [],
   "source": [
    "model.save('20250715_강의복습_seq2seq_CharacterLevel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # 입력으로부터 인코더의 상태를 얻음\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = \"\"\n",
    "\n",
    "  # stop_condition이 True가 될 때까지 루프 반복\n",
    "  while not stop_condition:\n",
    "    # 이전 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 문자로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sentence += sampled_char\n",
    "\n",
    "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "    if (sampled_char == '\\n' or\n",
    "        len(decoded_sentence) > max_tar_len):\n",
    "        stop_condition = True\n",
    "\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "  return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장: Bouge ! \n",
      "번역 문장: Dégage. \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장: Bonjour ! \n",
      "번역 문장: Bonjour ! \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장: Allez-y maintenant. \n",
      "번역 문장: Aujourd'hui. \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Go away.\n",
      "정답 문장: Décampe ! \n",
      "번역 문장: Décampez ! \n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "-----------------------------------\n",
      "입력 문장: Feel this.\n",
      "정답 문장: Sentez ça ! \n",
      "번역 문장: Tenez-moi ça. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "  input_seq = encoder_input[seq_index:seq_index+1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "  print(35 * \"-\")\n",
    "  print('입력 문장:', lines.src[seq_index])\n",
    "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNALQX+emubcl+mY84mIOle",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
