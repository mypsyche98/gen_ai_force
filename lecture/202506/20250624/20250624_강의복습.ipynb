{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXIP7Iyo3TiETixFZlGMoe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# page6\n","\n","import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Data Generation\n","np.random.seed(42)\n","x = np.random.rand(100,1)\n","y = 1 + 2 * x + 1 * np.random.randn(100,1)\n","\n","# Shuffles the indices\n","idx = np.arange(100)\n","np.random.shuffle(idx)\n","\n","# Uses first 80 random indices for train\n","train_idx = idx[:80]\n","\n","# Uses the remaining indices for validation\n","val_idx = idx[80:]\n","\n","# Generation train and validation sets\n","x_train, y_train = x[train_idx], y[train_idx]\n","x_val, y_val = x[val_idx], y[val_idx]\n","\n","# NumPy 배열을 PyTorch 텐서로 변환하여 GPU로 이동 (필요시)\n","x_train_tensor = torch.from_numpy(x_train).float().to(device)\n","y_train_tensor = torch.from_numpy(y_train).float().to(device)\n","x_val_tensor = torch.from_numpy(x_val).float().to(device) # x_val 텐서 추가\n","y_val_tensor = torch.from_numpy(y_val).float().to(device) # y_val 텐서 추가\n","\n","# DataLoader 생성\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True) # 배치 크기 설정\n","\n","val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n","val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False) # 검증셋은 섞지 않음\n","\n","# 모델 정의 (nn.Linear는 가중치와 편향을 내부적으로 관리합니다)\n","model_seq = nn.Sequential(nn.Linear(in_features=1, out_features=1)).to(device)\n","\n","print(f\"초기 모델 상태: {model_seq.state_dict()}\") # 초기 가중치와 편향 확인\n","\n","# 손실 함수 정의\n","loss_fn = nn.MSELoss(reduction=\"mean\")\n","\n","# 옵티마이저 정의: model_seq의 매개변수들을 최적화 대상으로 지정\n","optimizer = optim.SGD(model_seq.parameters(), lr=1e-1) # lr = 1e-1\n","\n","# 학습 스텝 함수 정의\n","def make_train_step(model, loss_fn, optimizer):\n","  def train_step(x,y):\n","    model.train() # 모델을 훈련 모드로 설정\n","\n","    yhat = model(x) # 예측\n","\n","    loss = loss_fn(yhat, y) # 손실 계산\n","    loss.backward() # 역전파: 기울기 계산\n","\n","    optimizer.step() # 매개변수 업데이트\n","    optimizer.zero_grad() # 다음 배치를 위해 기울기 초기화\n","\n","    return loss.item() # 손실 값 반환\n","  return train_step\n","\n","train_step = make_train_step(model_seq, loss_fn, optimizer)\n","losses = [] # 훈련 손실 저장 리스트\n","val_losses = [] # 검증 손실 저장 리스트 (추가)\n","\n","n_epochs = 1000 # 에포크 수\n","\n","for epoch in range(n_epochs):\n","  batch_losses = []\n","  for x_batch, y_batch in train_loader: # train_loader 사용\n","    x_batch = x_batch.to(device)\n","    y_batch = y_batch.to(device)\n","\n","    loss = train_step(x_batch, y_batch)\n","    batch_losses.append(loss)\n","  losses.append(np.mean(batch_losses)) # 에포크별 평균 훈련 손실 저장\n","\n","  # 검증 단계 (torch.no_grad()로 기울기 계산 비활성화)\n","  with torch.no_grad():\n","    val_batch_losses = []\n","    for x_val_batch, y_val_batch in val_loader: # val_loader 사용\n","      x_val_batch = x_val_batch.to(device)\n","      y_val_batch = y_val_batch.to(device)\n","\n","      model_seq.eval() # 모델을 평가 모드로 설정 (드롭아웃/배치 정규화 등에 영향)\n","\n","      yhat_val = model_seq(x_val_batch) # x_val_batch만 입력\n","      val_loss = loss_fn(yhat_val, y_val_batch)\n","      val_batch_losses.append(val_loss.item())\n","    val_losses.append(np.mean(val_batch_losses)) # 에포크별 평균 검증 손실 저장\n","\n","  # 진행 상황 출력 (선택 사항)\n","  if (epoch + 1) % 100 == 0:\n","    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n","\n","# 학습 후 모델의 최종 가중치와 편향 확인\n","print(f\"학습 후 모델 상태: {model_seq.state_dict()}\")\n"],"metadata":{"id":"DHjzPvyRefj3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750732099583,"user_tz":-540,"elapsed":4510,"user":{"displayName":"김광무","userId":"03808645168826839149"}},"outputId":"a78a4a27-209c-4ddc-d9e7-0d58bc11aa76"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["초기 모델 상태: OrderedDict([('0.weight', tensor([[0.8749]])), ('0.bias', tensor([-0.1011]))])\n","Epoch 100/1000, Train Loss: 0.8121, Val Loss: 0.5856\n","Epoch 200/1000, Train Loss: 0.8244, Val Loss: 0.5676\n","Epoch 300/1000, Train Loss: 0.8185, Val Loss: 0.5510\n","Epoch 400/1000, Train Loss: 0.8081, Val Loss: 0.5695\n","Epoch 500/1000, Train Loss: 0.8178, Val Loss: 0.5407\n","Epoch 600/1000, Train Loss: 0.8108, Val Loss: 0.5562\n","Epoch 700/1000, Train Loss: 0.8150, Val Loss: 0.5401\n","Epoch 800/1000, Train Loss: 0.8080, Val Loss: 0.5589\n","Epoch 900/1000, Train Loss: 0.8190, Val Loss: 0.5295\n","Epoch 1000/1000, Train Loss: 0.8059, Val Loss: 0.5505\n","학습 후 모델 상태: OrderedDict([('0.weight', tensor([[1.6793]])), ('0.bias', tensor([1.2268]))])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vZjRtecBuQ9U"},"execution_count":null,"outputs":[]}]}