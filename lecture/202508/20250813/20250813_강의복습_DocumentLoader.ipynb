{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHjzPvyRefj3",
    "outputId": "6a95054f-2b46-425d-f493-d94e0af0927f"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oJWRnk7DRWsm"
   },
   "outputs": [],
   "source": [
    "def get_langchain():\n",
    "  with open('20250812_LangChain_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai():\n",
    "  with open('20250723_OpenAI_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_name = 'CH06_DocumentLoader'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = get_langchain()\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = get_langchain()\n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH06_DocumentLoader\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document = Document(\"안녕하세요? 이건 랭체인의 도큐먼드 입니다\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {},\n",
       " 'page_content': '안녕하세요? 이건 랭체인의 도큐먼드 입니다',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도큐먼트의 속성 확인\n",
    "document.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 추가\n",
    "document.metadata[\"source\"] = \"TeddyNote\"\n",
    "document.metadata[\"page\"] = 1\n",
    "document.metadata[\"author\"] = \"Teddy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'TeddyNote', 'page': 1, 'author': 'Teddy'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도큐먼트의 속성 확인\n",
    "document.metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 파일 경로\n",
    "FILE_PATH = \"./SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 로더 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF 로더\n",
    "docs = loader.load()\n",
    "\n",
    "# 로드된 문서의 수 확인\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='2023 년 12월호')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 문서 확인\n",
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='2023 년 12월호')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문열 분할기 설정\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "# 문서 분할\n",
    "docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# 로드된 문서의 수 확인\n",
    "len(docs)\n",
    "# 첫번째 문서 확인\n",
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 1, 'page_label': '2'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 2, 'page_label': '3'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 3, 'page_label': '4'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 4, 'page_label': '5'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 5, 'page_label': '6'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 6, 'page_label': '7'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 7, 'page_label': '8'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 8, 'page_label': '9'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 9, 'page_label': '10'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 11, 'page_label': '12'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 12, 'page_label': '13'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 13, 'page_label': '14'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 14, 'page_label': '15'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 15, 'page_label': '16'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 16, 'page_label': '17'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 17, 'page_label': '18'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 18, 'page_label': '19'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 19, 'page_label': '20'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 20, 'page_label': '21'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 21, 'page_label': '22'}\n",
      "{'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 22, 'page_label': '23'}\n"
     ]
    }
   ],
   "source": [
    "# generator 방식으로 문서 로드\n",
    "for doc in loader.lazy_load():\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 async 방식으로 로드\n",
    "adocs = loader.aload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 0, 'page_label': '1'}, page_content='2023 년 12월호'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 1, 'page_label': '2'}, page_content='2023 년 12월호\\nⅠ. 인공지능 산업 동향 브리프\\n 1. 정책/법제 \\n   ▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표  ························· 1\\n   ▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의··························· 2\\n   ▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언··························· 3\\n   ▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각····································· 4\\n   ▹ 미국 연방거래위원회 , 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출················· 5\\n   ▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항··················································· 6\\n \\n 2. 기업/산업 \\n   ▹ 미국 프런티어 모델 포럼, 1,000 만 달러 규모의 AI 안전 기금 조성································ 7\\n   ▹ 코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개  ······································· 8\\n   ▹ 알리바바 클라우드 , 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9\\n   ▹ 삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개 ··························································· 10\\n   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027 년 AI 소프트웨어 매출 2,500 억 달러 돌파 전망··········································· 12\\n   ▹ 빌 게이츠 , AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································ 13\\n   ▹ 유튜브 , 2024 년부터 AI 생성 콘텐츠 표시 의무화 ···························································· 14\\n 3. 기술/연구\\n   ▹ 영국 과학혁신기술부 , AI 안전 연구소 설립 발표······························································ 15\\n   ▹ 구글 딥마인드 , 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························ 16\\n   ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4 가 가장 우수 ··········································· 17\\n   \\n 4. 인력/교육     \\n   ▹ 영국 옥스퍼드 인터넷 연구소 , AI 기술자의 임금이 평균 21% 높아······························· 18\\n   \\n   \\n \\nⅡ. 주요 행사\\n   ▹CES 2024 ····························································································································· 19\\n   ▹AIMLA 2024 ························································································································· 19\\n   ▹AAAI Conference on Artificial Intelligence ·································································· 19'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 2, 'page_label': '3'}, page_content='Ⅰ. 인공지능 산업 동향 브리프'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 3, 'page_label': '4'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 \\nn미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 ’에 서명하고 \\n광범위한 행정 조치를 명시\\nn행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 \\n보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력을 골자로 함KEY Contents\\n£바이든 대통령 , AI 행정명령 통해 안전하고 신뢰할 수 있는 AI 개발과 활용 추진\\nn미국 바이든 대통령이 2023년 10월 30일 연방정부 차원에서 안전하고 신뢰할 수 있는 AI 개발과 \\n사용을 보장하기 위한 행정명령을 발표\\n∙행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 보호 \\n△노동자 지원 △혁신과 경쟁 촉진 △국제협력에 관한 내용을 포괄\\nn(AI 안전과 보안 기준) 강력한 AI 시스템을 개발하는 기업에게 안전 테스트 결과와 시스템에 관한 \\n주요 정보를 미국 정부와 공유할 것을 요구하고 , AI 시스템의 안전성과 신뢰성 확인을 위한 표준 및 \\nAI 생성 콘텐츠 표시를 위한 표준과 모범사례 확립을 추진\\n∙△1026 플롭스 (FLOPS, Floating Point Operation Per Second) 를 초과하는 컴퓨팅 성능 또는 생물학적 \\n서열 데이터를 주로 사용하고 1023플롭스를 초과하는 컴퓨팅 성능을 사용하는 모델 △단일 데이터센터에서 \\n1,000Gbit/s 이상의 네트워킹으로 연결되며 AI 훈련에서 이론상 최대 1020 플롭스를 처리할 수 있는 \\n컴퓨팅 용량을 갖춘 컴퓨팅 클러스터가 정보공유 요구대상\\nn(형평성과 시민권 향상) 법률, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타 \\n문제를 방지하는 조치를 확대\\n∙형사사법 시스템에서 AI 사용 모범사례를 개발하고 , 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한 \\n지침을 제공하며 , 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련 \\nn(소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교 \\n내 AI 교육 도구 관련 자원을 개발하며 , AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과 \\n모범사례를 마련\\nn(혁신과 경쟁 촉진) 국가AI연구자원 (National Artificial Intelligence Research Resource, NAIRR)* 을 \\n통해 미국 전역의 AI 연구를 촉진하고 , 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램 \\n∙비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서 \\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of \\nArtificial Intelligence (E.O. 14110), 2023.10.30.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 4, 'page_label': '5'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n2G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nnG7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인 \\n채택을 권고하는 AI 국제 행동강령을 마련\\nn행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와 \\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구KEY Contents\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn주요 7개국(G7)* 은 2023 년 10월 30일 ‘히로시마 AI 프로세스 ’를 통해 AI 기업 대상의 AI 국제 \\n행동강령 (International Code of Conduct for Advanced AI Systems) 에 합의\\n∙G7은 2023 년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과 \\n정보공유를 위해 ‘히로시마 AI 프로세스 ’를 출범**\\n∙기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의 \\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스 , 이탈리아 , 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나 , AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nnG7은 행동강령을 통해 아래의 조치를 제시했으며 , 빠르게 발전하는 기술에 대응할 수 있도록 \\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고 , \\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을 \\n보장하고 책임성을 강화\\n∙산업계 , 정부, 시민사회 , 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시 \\n신고를 위해 협력하고 , 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는 \\nAI 거버넌스와 위험 관리 정책을 마련\\n∙AI 수명주기 전반에 걸쳐 물리보안 , 사이버보안 , 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로 \\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축 \\n∙사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고 , 기후 위기 \\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙국제 기술 표준의 개발 및 채택을 가속화하고 , 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집 \\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 5, 'page_label': '6'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\\nn영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 \\n위한 협력 방안을 담은 블레츨리 선언을 발표\\nn첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며 , \\n영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정 KEY Contents\\n£AI 안전성 정상회의 참가국들 , 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\\nn2023 년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의 (AI Safety Summit) 에 \\n참가한 28개국 대표들이  AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 \\n∙선언은 AI 안전 보장을 위해 국가, 국제기구 , 기업, 시민사회 , 학계를 포함한 모든 이해관계자의 협력이 \\n중요하다고 강조했으며 , 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여 \\nAI 시스템의 안전을 보장할 책임이 있다고 지적\\n∙각국은 AI 안전 보장을 위해 첨단 AI 개발기업의 투명성 향상, 적절한 평가지표와 안전 테스트 도구 \\n개발, 공공부문 역량 구축과 과학 연구개발 등의 분야에서 협력하기로 합의\\n£영국 총리, 정부 주도의 첨단 AI 시스템 안전 테스트 계획 발표\\nn리시 수낙 영국 총리는 AI 안전성 정상회의를 마무리하며 첨단 AI 모델에 대한 안전성 시험 계획 \\n수립과  테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표\\n∙첨단 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한 \\n시험을 포함하며 , 참석자들은 정부 주도의 외부 안전 테스트에 합의\\n∙각국 정부는 테스트와 기타 안전 연구를 위한 공공부문 역량에 투자하고 , 테스트 결과가 다른 국가와 \\n관련된 경우 해당 국가와 결과를 공유하며 , 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의 \\nn참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of \\nthe Science)’ 보고서 작성에도 합의했으며 , 보고서를 통해 첨단 AI의 위험과 가능성에 관한 \\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획 \\nn한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며 , \\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit \\nconcludes, 2023.11.02.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 6, 'page_label': '7'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n4미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각\\nn미국 캘리포니아 북부지방법원은 미드저니 , 스태빌리티 AI, 디비언트아트를 대상으로 예술가 \\n3인이 제기한 저작권 침해 소송을 기각\\nn법원은 기각 이유로 고소장에 제시된 상당수 작품이 저작권청에 등록되지 않았으며 , AI로 \\n생성된 이미지와 특정 작품 간 유사성을 입증하기 어렵다는 점을 제시 KEY Contents\\n£예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각\\nn미국 캘리포니아 북부지방법원의 윌리엄 오릭(W illiam Orrick) 판사는 2023년 10월 30일 미드저니\\n(M idjourney),  스태빌리티 AI(Stability AI), 디비언트아트 (DeviantArt) 에 제기된 저작권 침해 소송을 기각 \\n∙2023 년 1월 예술가 사라 앤더슨 (Sarah Anderson), 캘리 맥커넌 (Kelly McKernan), 칼라 \\n오르티즈 (Karla Ortiz) 는 이미지 생성 AI 서비스를 개발한 3개 기업을 상대로 저작권 침해 소송을 제기\\n∙예술가들은 3개 기업이 AI 모델을 학습시키기 위해 원작자 동의 없이 작품을 학습 데이터셋에 \\n포함하여 저작권을 침해했다고 주장했으며 , 법원은 지난 4월 피소 기업들이 제출한 기각 신청을 \\n수용해 소송을 기각 \\nn오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시\\n∙판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 미국 저작권청에 예술 작품에 대한 저작권을 \\n제출하지 않았다는 점을 지적했으며 , 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에 \\n대해서만 저작권을 보유\\nn판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나 , 생성 AI로 만든 \\n이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이  부족하다고  \\n지적\\n∙AI는 새로운 이미지를 생성할 때 다양한 예술가의 작품을 참조하므로 , 생성된 이미지와 저작권을 가진 \\n특정 작품과의 실질적 유사성을 입증할 수 없다면 저작권 침해를 인정받기 어려움\\nn오릭 판사는 원고 측에 고소장을 수정하고 저작권이 침해된 특정 이미지를 중심으로 소송 범위를 \\n줄여 소송을 다시 제기할 것을 요청\\n∙단, 사라 앤더슨이 저작권을 보유한 16개 작품을 무단으로 복제한 스태빌리티 AI에 대한 저작권 침해 \\n소송은 인정되어 계속 진행됨\\n☞ 출처: Venturebeat, Midjourney, Stability AI and DeviantArt win a victory in copyright case by artists- but the \\nfight continues, 2023.10.30.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 7, 'page_label': '8'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n미국 연방거래위원회 , 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출\\nn미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁 \\n측면의 의견을 제시\\nnFTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부 \\n빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기KEY Contents\\n£FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려\\nn미국 연방거래위원회 (FTC) 가 2023 년 10월 30일 저작권청 (U.S. Copyright Office, USCO) 이 \\n지난 9월 발표한 저작권과 AI 관련 질의공고 (Notice of Inquiry, NOI)에 대한 의견서를 발표\\n∙저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며 , 폭넓은 의견 수렴을 통해 \\n입법과 규제 조치의 필요성을 검토할 계획\\n∙FTC는 생성 AI의 개발과 배포가 소비자 , 근로자 , 중소기업에 피해를 줄 수 있다며 소비자의 개인정보 \\n침해, 차별과 편견의 자동화 , 사기 범죄 등 AI 사용과 관련된 위험에 주목\\nnFTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해 \\n창작자의 경쟁력이 불공정한 피해를 볼 수 있으며 , 소비자가 특정 창작자의 작품을 생성 AI가 \\n만들었다고 오해할 소지가 있다고 지적\\n∙저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며 , 창작자의 평판 악화, \\n저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능\\nnFTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용 \\n데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기\\n∙이와 관련 FTC는 아마존 AI 비서 ‘알렉사 (Alexa)’ 와 스마트홈 보안 기기 ‘링(Ring)’ 이 소비자의 사적 \\n정보를 알고리즘 훈련에 사용하여 프라이버시를 침해한 혐의를 조사하는 등 법적 권한을 활용해 AI \\n관련 불법 행위에 대처하고 있음\\n* FTC는 2023년 5월 31일 동의를 받지 않고 어린이들의 음성과 위치 정보를 활용한 ‘알렉사 ’와 고객의 사적 영상에 대하여 \\n직원에게 무제한 접근 권한을 부여한 ‘링’에 3,080 만 달러(약 420억 원)의 과징금을 부과  \\nnFTC는 빠르게 발전하는 생성 AI가 여러 산업과 비즈니스에 변화를 가져올 수 있지만 , 현행법상 \\nAI에 관한 예외 조항은 없다며 , 모든 권한을 활용해 소비자를 보호하고 개방적이고 공정한 경쟁 \\n시장을 유지하겠다고 강조\\n☞ 출처: FTC, In Comment Submitted to U.S. Copyright Office, FTC Raises AI-related Competition and \\nConsumer Protection Issues, Stressing That It Will Use Its Authority to Protect Competition and \\nConsumers in AI Markets, 2023.10.30.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 8, 'page_label': '9'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n6EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항\\nn유럽의회 , EU 집행위원회 , EU 이사회가 진행 중인 AI 법 최종협상에서 프랑스 , 이탈리아 , \\n독일이 기반모델에 대한 규제에 반대하며 협상이 난관에 봉착\\nn프랑스 , 이탈리아 , 독일 3개국은 기반모델 개발기업에 대하여 자율적 행동강령을 도입하고 \\n준수를 의무화하는 방안을 제안KEY Contents\\n£AI 법 3자 협상, 이사회 일부 국가가 기반모델 규제에 반대하며 차질\\nn유럽의회 , EU 집행위원회 , EU 이사회가 ‘AI 법(AI act)’에 대한 최종협상을 진행 중인 가운데 , \\n일부 국가가 기반모델에 대한 규제에 반대하며 협상이 난관에 봉착  \\n∙10월 24일 열린 3자 협상 회의에서는 사회에 더 큰 영향을 미치는 강력한 AI 모델에 더 엄격한 규칙을 \\n적용하는 계층적 접근방식에 따라 기반 모델 규제에 대한 기본적인 합의에 도달\\n∙그러나 11월 10일 열린 통신작업반 회의에서 EU 이사회의 프랑스 , 독일, 이탈리아 대표가 \\n기반모델에 대한 모든 유형의 규제에 반대하며 협상이 중단됨\\nn유럽 정책 미디어 유랙티브 (Euractive) 에 따르면 프랑스 AI 기업 미스트랄 (Mistral) 이 로비를 통해 \\n기반모델에 대한 규제 반대를 주도  \\n∙독일의 대표적인 AI 기업 알레프 알파(Aleph Alpha) 역시 독일 정부에 압력을 행사하고 있으며 , 이들 \\n기업은 EU의 AI 규제로 인해 미국과 중국의 경쟁사보다 뒤처질 것을 우려 \\n£독일, 프랑스 , 이탈리아 3개국, 기반모델에 대한 ‘의무적 자율규제 ’ 제안\\nn통신작업반 회의가 결렬된 이후 독일, 프랑스 , 이탈리아는 2023 년 11월 19일 비공식 문서를 통해 \\n‘의무적 자율규제 (Mandatory Self-regulation)’ 방식의 기반모델 규제를 제안\\n∙3개국은 기반모델 전반에 대한 규제가 기술 중립적이고 위험 기반의 AI 규제 원칙에 어긋난다고 \\n주장하며 기반모델 전반에 대한 규제가 아닌, 특정 용도로 사용될 수 있는 AI 시스템에 대한 규제를 요구  \\n∙3개국은 자발적인 행동강령을 도입하고 준수를 의무화하는 방안을 제안하며 , 기반모델 개발기업에 \\n머신러닝 기술 정보와 모델의 기능과 한계를 요약한 ‘모델 카드’ 작성을 요구하겠다고 설명\\n∙3개국은 AI 감독기관이 모델 카드를 토대로 기반모델 개발기업의 행동강령 준수 여부를 확인하되 , \\n위반 시 곧바로 제재를 가하지 않고 위반행위 분석과 영향 평가를 시행한 후 제재하는 방안을 제안\\n☞ 출처: Euractiv, EU’s AI Act negotiations hit the brakes over foundation models, 2023.11.1.\\n Euractiv, France, Germany, Italy push for ‘mandatory self-regulation’ for foundation models in EU’s AI law, 2023.11.19.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 9, 'page_label': '10'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n미국 프런티어 모델 포럼, 1,000 만 달러 규모의 AI 안전 기금 조성\\nn구글, 앤스로픽 , 마이크로소프트 , 오픈AI가 참여하는 프런티어 모델 포럼이 자선단체와 함께 AI \\n안전 연구를 위한 1,000 만 달러 규모의 AI 안전 기금을 조성\\nn프런티어 모델 포럼은 AI 모델의 취약점을 발견하고 검증하는 레드팀 활동을 지원하기 위한 \\n모델 평가 기법 개발에 자금을 중점 지원할 계획KEY Contents\\n£프런티어 모델 포럼, 자선단체와 함께 AI 안전 연구를 위한 기금 조성\\nn구글, 앤스로픽 , 마이크로소프트 , 오픈AI가 출범한 프런티어 모델 포럼이 2023년 10월 25일 AI 안전 \\n연구를 위한 기금을 조성한다고 발표\\n∙참여사들은 맥거번 재단(Patrick J. McGovern Foundation), 데이비드 앤 루실 패커드 재단(The \\nDavid and Lucile Packard Foundation ) 등의 자선단체와 함께 AI 안전 연구를 위한 기금에 \\n1,000 만 달러 이상을 기부 \\n∙또한 신기술의 거버넌스와 안전 분야에서 전문성을 갖춘 브루킹스 연구소 출신의 크리스 메서롤 (Chris \\nMeserole) 을 포럼의 상무이사로 임명\\nn최근 AI 기술이 급속히 발전하면서 AI 안전에 관한 연구가 부족한 시점에 , 포럼은 이러한 격차를 해소\\n하기 위해 AI 안전 기금을 조성\\n∙참여사들은 지난 7월 백악관 주재의 AI 안전 서약에서 외부자의 AI 시스템 취약점 발견과 신고를 \\n촉진하기로 약속했으며 , 약속을 이행하기 위해 기금을 활용해 외부 연구집단의 AI 시스템 평가에 \\n자금을 지원할 계획\\n£AI 안전 기금으로 AI 레드팀을 위한 모델 평가 기법 개발을 중점 지원할 계획\\nn프런티어 모델 포럼은 AI 안전 기금을 통해 AI 레드팀 활동을 위한 새로운 모델 평가 기법의  개발을 \\n중점 지원할 예정\\n∙포럼에 따르면 AI 레드팀에 대한 자금 지원은 AI 모델의 안전과 보안 기준의 개선과 함께 AI 시스템 \\n위험 대응 방안에 관한 산업계와 정부, 시민사회의 통찰력 확보에 도움이 될 전망으로 , 포럼은 향후 몇 \\n달 안에 기금 지원을 위한 제안 요청을 받을 계획\\nn프런티어 모델 포럼은 출범 이후 업계 전반에 걸쳐 AI 레드팀 구성에 관한 모범사례 공유를 추진하는  \\n한편, 첨단 AI 모델의 취약점이나 잠재적으로 위험한 기능 및 위험 완화 관련 정보를 공유할 수 \\n있는 공개 절차도 개발 중\\n☞ 출처: Google, Anthropic, Google, Microsoft and OpenAI announce Executive Director of the Frontier Model \\nForum and over $10 million for a new AI Safety Fund, 2023.10.25.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 10, 'page_label': '11'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n8코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\\nn코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \\n작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기 ’ 플랫폼을 출시\\nn대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \\n구성과 계보도 추적 가능KEY Contents\\n£데이터 출처 탐색기 , 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\\nnAI 기업 코히어 (Cohere) 가 매사추세츠 공과⼤(MIT), 하버드 ⼤ 로스쿨 , 카네기멜론 ⼤ 등 12개 기관과  \\n함께 2023 년 10월 25일 ‘데이터 출처 탐색기 (Data Provenance Explorer)’ 플랫폼을 공개\\n∙AI 모델 훈련에 사용되는 데이터셋의 불분명한 출처로 인해 데이터 투명성이 확보되지 않아 다양한 \\n법적·윤리적 문제가 발생\\n∙이에 연구진은 가장 널리 사용되는 2,000 여 개의 미세조정 데이터셋을 감사 및 추적하여 데이터셋에 \\n원본 데이터소스에 대한 태그, 재라이선스 (Relicensing) 상태, 작성자 , 기타 데이터 속성을 지정하고 \\n이러한 정보에 접근할 수 있는 플랫폼을 출시\\n∙대화형 플랫폼 형태의 데이터 출처 탐색기를 통해 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 , \\n주요 데이터셋의 구성과 데이터 계보도 추적 가능\\nn연구진은 오픈소스 데이터셋에 대한 광범위한 감사를 통해 데이터 투명성에 영향을 미치는 주요 \\n요인을  발견\\n∙깃허브 (GitHub), 페이퍼위드코드 (Papers with Code) 와 같은 크라우드소싱 플랫폼에서 수집한 \\n데이터로 훈련된 오픈소스 LLM에서는 데이터 라이선스의 누락 비율이 72~83% 에 달함 \\n∙또한 크라우드소싱 플랫폼이 할당한 라이선스는 데이터셋 원저작자의 의도보다 더 광범위한 사용을 \\n허용한 경우가 상당수\\n∙데이터 생태계 분석 결과, 부정확하거나 모호한 라이선스 문서화 등 데이터 출처 입증과 관련된 관행 \\n전반에서 구조적 문제가 드러남\\nn연구진은 데이터 출처 탐색기만으로는 해결이 어려운 법적 이슈도 존재한다며 일관된 법적 프레임\\n워크의 필요성을 제기\\n∙일례로 데이터를 수집한 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을 \\n적용해야 하는지 실무자의 판단이 어려울 수 있으며 , 서로 다른 라이선스를 적용받는 개별 데이터셋을 \\n하나로 통합해 사용하는 경우에도 각각의 라이선스 조건 준수에 어려움이 발생\\n☞ 출처 : Cohere, Data Provenance Explorer Launches to Tackle Data Transparency Crisis, 2023.10.25.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 11, 'page_label': '12'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n알리바바 클라우드 , 최신 LLM ‘통이치엔원 2.0’ 공개\\nn알리바바 클라우드가 복잡한 지침 이해, 광고문구 작성, 추론, 암기 등에서 성능이 향상된 최신 \\nLLM ‘통이치엔원 2.0’을 공개\\nn알리바바 클라우드는 산업별로 특화된 생성 AI 모델을 공개하는 한편, 모델 개발과 애플리케이션 \\n구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼도 출시KEY Contents\\n£알리바바의 통이치엔원 2.0, 주요 벤치마크 테스트에서 여타 LLM 능가\\nn중국의 알리바바 클라우드가 2023 년 10월 31일 열린 연례 기술 컨퍼런스에서 최신 LLM ‘통이\\n치엔원 (Tongyi Qianwen) 2.0’을 공개\\n∙알리바바 클라우드는 통이치엔원 2.0이 2023 년 4월 출시된 1.0 버전보다 복잡한 지침 이해, \\n광고문구 작성, 추론, 암기 등에서 성능이 향상되었다고 설명\\n∙통이치엔원 2.0은 언어 이해 테스트 (MMLU), 수학(GSM8k), 질문 답변(ARC-C) 과 같은 벤치마크 \\n테스트에서 라마(Llama-2-70B) 와 GPT-3.5 를 비롯한 주요 AI 모델을 능가 \\n∙통이치엔원 2.0은 알리바바 클라우드의 웹사이트와 모바일 앱을 통해 대중에 제공되며 개발자는 \\nAPI를 통해 사용 가능 \\nn알리바바 클라우드는 여러 산업 영역에서 생성 AI를 활용해 사업 성과를 개선할 수 있도록 지원\\n하는 산업별 모델도 출시\\n∙산업 영역은 고객지원 , 법률 상담, 의료, 금융, 문서관리 , 오디오와 동영상 관리, 코드 개발, 캐릭터 \\n제작을 포함\\nn알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를 \\n간소화하는 올인원 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’ 도 공개\\n∙이 플랫폼은 데이터 관리, 모델 배포와 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여 \\n다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\\n∙생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼 (PAI), \\n데이터베이스 솔루션 , 컨테이너 서비스와 같은 클라우드 신제품도 발표\\nn알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720억 개 매개변수를 가진 통이치엔원  \\n모델을 오픈소스화한다는 계획도 공개\\n☞ 출처 : Alibaba Cloud, Alibaba Cloud Launches Tongyi Qianwen 2.0 and Industry-specific Models to Support \\nCustomers Reap Benefits of Generative AI, 2023.10.31.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 12, 'page_label': '13'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n10삼성전자 , 자체 개발 생성 AI ‘삼성 가우스 ’ 공개\\nn삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스 ’를 공개\\nn삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로 , 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유KEY Contents\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스 , 온디바이스 작동 지원\\nn삼성전자가 2023 년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스 ’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스 (Gauss) 의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며 , \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며 , 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는  \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며 , 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원\\n∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이 (code.i)’ 는 대화형 인터페이스로 서비스를 제공하며 \\n사내 소프트웨어 개발에 최적화\\n∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \\n저해상도 이미지의 고해상도 전환도 지원\\nnIT 전문지 테크리퍼블릭 (TechRepublic) 은 온디바이스 AI가 주요 기술 트렌드로 부상했다며 , \\n2024 년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2 를 탑재한 퀄컴 기기 및 구글 \\n어시스턴트를 적용한 구글 픽셀(Pixel) 과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자 , ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스 ’ 공개, 2023.11.08.\\n삼성전자 , ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 13, 'page_label': '14'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 \\nn구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며 , 앤스로픽은 \\n구글과 클라우드 서비스 사용 계약도 체결\\nn3대 클라우드 사업자인 구글, 마이크로소프트 , 아마존은 차세대 AI 모델의 대표 기업인 \\n앤스로픽 및 오픈AI와 협력을 확대하는 추세KEY Contents\\n£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\nn구글이 2023 년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며 , 이 중 5억 \\n달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\\n∙구글은 2023 년 2월 앤스로픽에 이미 5억 5,000 만 달러를 투자한 바 있으며 , 아마존도 지난 9월 \\n앤스로픽에 최대 40억 달러의 투자 계획을 공개\\n∙한편, 2023 년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해 \\n4년간 30억 달러 규모의 계약을 체결\\n∙오픈AI 창업자 그룹의 일원이었던 다리오 (Dario Amodei) 와 다니엘라 아모데이 (Daniela Amodei) \\n남매가 2021 년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드 (Claude)’ LLM을 개발\\nn아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인  오픈\\nAI와 협력을 확대\\n∙마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023 년 1월 추가로 100억 달러를 \\n투자하기로 하면서 오픈AI의 지분 49%를 확보했으며 , 오픈AI는 마이크로소프트의 애저(Azure) \\n클라우드 플랫폼을 사용해 AI 모델을 훈련\\n£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\\nn구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를 \\n통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속  \\n∙구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이 (Runway) 와 오픈소스 소프트웨어 \\n기업 허깅 페이스 (Hugging Face) 에도 투자\\n∙구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니 (Gemini)’ 를 포함한 자체 AI \\n시스템 개발에도 수십억 달러를 투자했으며 , 2024 년 제미니를 출시할 계획\\n☞ 출처 : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\\nBloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 14, 'page_label': '15'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n12IDC, 2027년 AI 소프트웨어 매출 2,500 억 달러 돌파 전망\\nnIDC의 예측에 의하면 AI 소프트웨어 시장은 2027년 2,510 억 달러로 달할 전망이며 , 생성 \\nAI 플랫폼과 애플리케이션은 2027 년까지 283억 달러의 매출을 창출할 전망 \\nn2023년 기준 AI 소프트웨어 매출의 3분의 1을 차지하는 최대 시장인 AI 애플리케이션은 \\n2027년까지 21.1% 의 연평균 성장률을 기록할 전망KEY Contents\\n£기업들의 AI 투자 증가에 힘입어 AI 소프트웨어 시장 급성장 예상\\nn시장조사기관 IDC는 AI 소프트웨어 시장이 2022년 640억 달러에서 2027년 2,510 억 달러로 연평\\n균 성장률 31.4% 를 기록하며 급성장할 것으로 예상\\n∙AI 소프트웨어 시장은 AI 플랫폼 , AI 애플리케이션 , AI 시스템 인프라 소프트웨어 (SIS), AI 애플리케이션 \\n개발·배포(AI AD&D) 소프트웨어를 포괄\\n∙협업, 콘텐츠 관리, 전사적 자원관리 (ERM), 공급망 관리, 생산 및 운영, 엔지니어링 , 고객관계관리 (CRM) 를 \\n포함하는 AI 애플리케이션은 AI 소프트웨어의 최대 시장으로 2023년 전체 매출의 약 3분의 1을 차지하며 \\n2027년까지 21.1% 의 연평균 성장률을 기록할 전망\\n∙AI 비서를 포함한 AI 모델과 애플리케이션의 개발을 뒷받침하는 AI 플랫폼은 두 번째로 시장 규모가 큰 \\n분야로 , 2027년까지 35.8% 의 연평균 성장률이 예상됨\\n∙분석, 비즈니스 인텔리전스 , 데이터 관리와 통합을 포함하는 AI SIS는 기존 소프트웨어 시스템과 통합되어 \\n방대한 데이터를 활용한 의사결정과 운영 최적화를 지원하며 , 현재 매출 규모는 비교적 작지만 5년간 \\n연평균 성장률은 32.6% 로 시장 전체를 웃돌 전망\\n∙애플리케이션 개발, 소프트웨어 품질과 수명주기 관리 소프트웨어 , 애플리케이션 플랫폼을 포함하는 AI \\nAD&D 는 향후 5년간 카테고리 중 가장 높은 38.7% 의 연평균 성장률이 예상됨\\nnIDC에 따르면 경제적 불확실성과 시장 역학의 변화에도 AI와 자동화 기술에 대한 기업들의 투자 \\n의지는 확고하며 , 기업들은 AI 도입이 사업 성공과 경쟁우위에 필수적이라고 인식\\n∙IDC 설문조사에 따르면 향후 12개월 동안 응답자의 3분의 1은 기업이 특정 사용 사례나 응용 영역에서 \\n외부 AI 소프트웨어의 구매를 고려하거나 외부 AI 소프트웨어와 내부 자원의 결합을 고려\\nn한편, AI 소프트웨어 시장에 포함되지 않는 생성 AI 플랫폼과 애플리케이션은 2027 년까지 283억 \\n달러의 매출을 창출할 전망 \\n☞ 출처 : IDC, IDC Forecasts Revenue for Artificial Intelligence Software Will Reach $279 Billion Worldwide in \\n2027, 2023.10.31.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 15, 'page_label': '16'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n빌 게이츠 , AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망\\nn빌 게이츠가 5년 내 일상언어로 모든 작업을 처리할 수 있는 AI 에이전트가 보급되며 컴퓨터를 \\n사용하는 방식이 완전히 바뀔 것으로 예상\\nn에이전트의 보급은 컴퓨터 분야를 넘어 산업 전 영역에 영향을 미칠 전망으로 특히 의료와 \\n교육, 생산성 , 엔터테인먼트 ·쇼핑 영역에서 고가로 제공되던 서비스가 대중화될 전망KEY Contents\\n£5년 내 기기에 일상언어로 말하기만 하면 되는 AI 에이전트의 보급 예상\\nn빌 게이츠 마이크로소프트 창업자가 2023 년 11월 9일 공식 블로그를 통해 AI 에이전트가 컴퓨터  \\n사용방식과 소프트웨어 산업을 완전히 변화시킬 것이라는 전망을 제시\\n∙자연어에 반응하고 사용자에 대한 지식을 바탕으로 다양한 작업을 수행하는 소프트웨어를 의미하는 \\n에이전트는 컴퓨터 사용방식이 키보드 입력에서 아이콘 클릭으로 바뀐 이후 최대의 컴퓨팅 혁명을 \\n가져올 전망\\n∙현재는 컴퓨터 작업 시 작업 내용에 따라 각각 다른 앱을 사용해야 하지만 5년 내 에이전트의 발전으로 \\n기기에 일상언어로 말하기만 하면 되는 미래가 도래할 것\\n∙온라인에 접속하는 모든 사람이 AI 기반의 개인 비서를 사용할 수 있게 되며, 에이전트는 사용자에 대한 \\n풍부한 지식을 바탕으로 맞춤화된 대응이 가능하며 시간이 지날수록 개선됨\\n∙일례로 여행 계획 수립 시 AI 챗봇이 예산에 맞는 호텔을 제안하는데 머문다면 , 에이전트는 사용자의 여행 \\n패턴을 분석해 여행지를 제안하고 관심사에 따른 활동을 추천하며 선호하는 스타일의 레스토랑 예약도 가능  \\n£AI 에이전트가 의료와 교육, 생산성 , 엔터테인먼트 ·쇼핑 영역의 서비스 대중화를 주도할 것\\nn에이전트로 인해 주목할 만한 변화는 고비용 서비스의 대중화로 특히 △의료 △교육 △생산성 △\\n엔터테인먼트 ·쇼핑의 4개 영역에서 대규모 변화 예상\\n∙(의료) 에이전트가 환자 분류를 지원하고 건강 문제에 대한 조언을 제공하며 치료의 필요 여부를 결정하면서 \\n의료진의 의사결정과 생산성 향상에 기여\\n∙(교육) 에이전트가 1대 1 가정교사의 역할을 맡아 모든 학생에게 평등한 교육 기회를 제공할 수 있으며 , \\n아이가 좋아하는 게임이나 노래 등을 활용해 시청각 기반의 풍부한 맞춤형 교육 경험을 제공\\n∙(생산성 ) 사용자의 아이디어를 기반으로 에이전트가 사업계획과 발표 자료 작성, 제품 이미지 생성을 \\n지원하며 , 임원의 개인 비서와 같은 역할도 수행 \\n∙(엔터테인먼트 ·쇼핑) 쇼핑 시 에이전트가 모든 리뷰를 읽고 요약해 최적의 제품을 추천하고 사용자 대신 \\n주문할 수 있으며 사용자의 관심사에 맞춤화된 뉴스와 엔터테인먼트를 구독 가능\\n☞ 출처 : GatesNotes, AI is about to completely change how you use computers, 2023.11.09.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 16, 'page_label': '17'}, page_content='SPRi AI Brief |  \\n2023-12 월호\\n14유튜브 , 2024년부터 AI 생성 콘텐츠 표시 의무화 \\nn유튜브가 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI 라벨 표시를 의무화하기로 했으며 , 이를 \\n준수하지 않는 콘텐츠는 삭제하고 크리에이터에 대한 수익 배분도 중단할 수 있다고 설명\\nn유튜브는 AI 생성 콘텐츠가 신원 파악이 가능한 개인을 모방한 경우 개인정보 침해 신고 \\n절차에 따라 콘텐츠 삭제 요청도 받을 계획KEY Contents\\n£유튜브 , 생성 AI 콘텐츠에 AI 라벨 표시 안 하면 콘텐츠 삭제\\nn유튜브가 2023 년 11월 14일 공식 블로그를 통해 몇 달 안에 생성 AI를 사용한 콘텐츠에 AI \\n라벨을 표시하는 새로운 규칙을 시행한다고 발표 \\n∙실제로 일어나지 않은 사건을 사실적으로 묘사하거나 실제로 하지 않은 말이나 행동을 보여주는 콘텐츠와 \\n같이 AI 도구를 사용해 사실적으로 변경되거나 합성된 콘텐츠에는 AI 라벨을 표시 필요\\n∙유튜브는 이러한 규칙이 선거나 분쟁 상황, 공중 보건, 공직자 관련 문제와 같이 민감한 주제를 다루는 \\n콘텐츠에서 특히 중요하다고 강조했으며 , 크리에이터가 AI로 제작한 콘텐츠에 AI 라벨을 표시하지 않으면 \\n해당 콘텐츠는 삭제되고 광고 수익을 배분하는 유튜브 파트너 프로그램도 정지될 수 있음\\n∙유튜브는 두 가지 방식으로 AI를 이용한 콘텐츠의 변경이나 합성 여부를 시청자에게 전달할 계획으로 \\n동영상 설명 패널에 라벨을 표시하는 방식이 기본이며 , 민감한 주제를 다루는 특정 유형의 콘텐츠는 동영상 \\n플레이어에 더욱 눈에 띄는 라벨을 적용 \\n∙유튜브는 커뮤니티 정책에 위반되는 일부 합성 콘텐츠에 대해서는 라벨 지정 여부와 관계없이 삭제할 \\n방침으로 , 가령 사실적인 폭력을 보여주는 합성 동영상이 시청자에게 충격이나 혐오감을 줄 수 있다면 \\n삭제될 수 있음\\n£유튜브 , 특정인을 모방한 AI 생성 콘텐츠에 대한 삭제 요청에도 대응 계획\\nn유튜브는 몇 달 내에 신원 파악이 가능한 개인의 얼굴이나 음성을 모방한 AI 생성 콘텐츠에 대하\\n여 개인정보 침해 신고 절차를 마련해 삭제 요청을 받을 계획  \\n∙단, 모든 콘텐츠가 삭제 대상은 아니며 유튜브는 콘텐츠가 패러디나 풍자인지 , 해당 영상에서 삭제 요청을 \\n한 특정인을 식별할 수 있는지 , 공직자나 유명인이 등장하는지 등 다양한 요소를 고려할 예정\\n∙유튜브는 음반사가 아티스트의 고유한 노래나 목소리를 모방한 AI 생성 음악에 대하여 삭제를 요청할 수 \\n있는 기능도 도입할 방침\\n☞ 출처 : Youtube, Our approach to responsible AI innovation, 2023.11.14.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 17, 'page_label': '18'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n영국 과학혁신기술부 , AI 안전 연구소 설립 발표\\nn영국 과학혁신기술부가 첨단 AI 시스템에 대한 평가를 통해 안전성을 보장하기 위한 AI \\n안전 연구소를 설립한다고 발표\\nnAI 안전 연구소는 핵심 기능으로 첨단 AI 시스템 평가 개발과 시행, AI 안전 연구 촉진, \\n정보교류 활성화를 추진할 계획KEY Contents\\n£영국 AI 안전 연구소 , 첨단 AI 시스템 평가와 AI 안전 연구, 정보 교류 추진\\nn영국 과학혁신기술부가 2023 년 11월 2일 첨단 AI 안전에 중점을 둔 국가 연구기관으로 AI \\n안전 연구소 (AI Safety Institute) 를 설립한다고 발표\\n∙AI 안전 연구소는 첨단 AI의 위험을 이해하고 거버넌스 마련에 필요한 사회·기술적 인프라 개발을 통해 \\n영국을 AI 안전 연구의 글로벌 허브로 확립하는 것을 목표로 함\\n∙영국 정부는 향후 10년간 연구소에 공공자금을 투자해 연구를 지원할 계획으로 , 연구소는 △첨단 AI 시스템 \\n평가 개발과 시행 △AI 안전 연구 촉진 △정보 교류 활성화를 핵심 기능으로 함\\nn(첨단 AI 시스템 평가 개발과 시행) 시스템의 안전 관련 속성을 중심으로 안전과 보안 기능을 이해\\n하고 사회적 영향을 평가\\n∙평가 우선순위는 △사이버범죄 조장, 허위 정보 유포 등 악의적으로 활용될 수 있는 기능 △사회에 미치는 \\n영향 △시스템 안전과 보안 △인간의 통제력 상실 가능성 순\\n∙연구소는 외부 기관과 협력해 자체 시스템 평가를 개발 및 수행하고 , 평가와 관련된 의견 공유 및 지침 \\n마련을 위해 전문가 커뮤니티를 소집할 계획\\nn(AI 안전 연구 촉진) 외부 연구자를 소집하고 다양한 예비 연구 프로젝트를 통해 AI 안전 기초연구를 수행\\n∙AI 시스템의 효과적 거버넌스를 위한 도구 개발* 및 안전한 AI 시스템 개발을 위한 새로운 접근 방식 연구를 수행\\n* 편향된 훈련 데이터에 대한 분석기술 , 민감한 정보를 포함하는 AI 시스템에 대한 미세 조정 방법\\nn(정보 교류 활성화 ) 현행 개인정보보호와 데이터 규제 하에서 연구소와 정책입안자 , 국제 파트너 , \\n학계, 시민사회 및 일반 대중과 정보 공유 채널을 구축\\n∙AI 안전성 정상회의 (AI Safety Summit) 에서 합의된 대로 첨단 AI 모델의 평가 후 해당 모델이 배포된 \\n타국의 정부 및 연구소와 평가 결과를 공유하고 , 학계와 대중이 AI 시스템의 피해와 취약점을 보고할 수 \\n있는 명확한 절차를 수립\\n☞ 출처 : Gov.uk, Introducing the AI Safety Institute, 2023.11.02.\\n             Venturebeat, Researchers turn to Harry Potter to make AI forget about copyrighted material, 2023.10.06.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 18, 'page_label': '19'}, page_content='16구글 딥마인드 , 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\\nn구글 딥마인드 연구진이 성능과 범용성 , 자율성을 기준으로 범용 AI(AGI) 의 수준을 \\n0~5단계까지 총 6단계로 구분한 프레임워크를 공개\\nn현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만 \\n광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음KEY Contents\\n£챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\\nn구글 딥마인드 연구진은 2023 년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와 \\n성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\\n∙프레임워크의 목적은 AGI의 성능, 범용성 , 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI \\n달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\\nn연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\\n∙(프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 중요\\n∙(범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\\n∙(인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며 , 인지 작업과 \\n메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\\n∙(실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행 \\n∙(생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적 · 사회적 또는 예술적으로 \\n가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\\n∙(종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정\\nn연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정 \\n과업에 활용되는 특수 AI로 분류했으며 , 특수 AI에서는 5단계까지 달성되었으나 , 범용 AI는 현재 1단계 수준\\n성능 특수 AI 예시 범용 AI 예시\\n0단계: AI 아님 계산기 소프트웨어 , 컴파일러 아마존 메커니컬 터크\\n1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\\n2단계: 유능(숙련된 인간의 50% 이상)스마트 스피커 (애플 시리, 아마존 알렉사 , 구글 \\n어시스턴트 ), IBM 왓슨 미달성\\n3단계: 전문가 (숙련된 인간의 90% 이상)문법 교정기 (그래머리 ), 생성 이미지 모델(달리2) 미달성\\n4단계: 거장(숙련된 인간의 99% 이상) 딥블루 , 알파고 미달성\\n5단계: 초인간 (인간을 100% 능가) 알파폴드 , 알파제로 , 스톡피시 미달성<구글 딥마인드의 범용 AI 분류 프레임워크 > \\n☞ 출처 : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 19, 'page_label': '20'}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n갈릴레오의 LLM 환각 지수 평가에서 GPT-4 가 가장 우수\\nn주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4 는 작업 유형과 관계없이 \\n가장 우수한 성능을 보였으며 GPT-3.5 도 거의 동등한 성능을 발휘\\nn오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트 \\n생성에서 가장 우수한 성능을 발휘KEY Contents\\n£주요 LLM 중 GPT-4 가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\\nn머신러닝 데이터 관리 기업 갈릴레오 (Galileo) 가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한 \\n‘LLM 환각 지수(LLM Hallucination Index)’ 를 발표\\n∙생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나 , 현실과 다른 부정확한 결과를 내놓는 \\n현상으로 , 기업의 AI 도입을 가로막는 주요 장애물이며 , 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해 \\n환각을 평가하고 측정하는 구조화된 접근방식을 제공\\n∙환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)* 을 포함한 질문과 답변 △RAG \\n없는 질문과 답변 △긴 형식의 텍스트 (보고서나 기사, 에세이 ) 생성의 3개 작업 유형에 대하여 환각을 \\n기준으로 LLM의 순위를 평가\\n* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋 , 데이터베이스 , 문서 등)에서 가져온 정보를 검색해 활용하는 기술\\nn3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4 가 최고의 성능을 기록했으며 , GPT-3.5 터보도 \\nGPT-4 와 거의 동등한 성능을 발휘\\n∙메타의 라마2(Llama-2-70b) 는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴 \\n형식의 텍스트 생성에서도 GPT-4 에 준하는 성능을 기록했으나 , RAG 포함 질문과 답변에서는 허깅 \\n페이스의  제퍼(Zephyr-7b) 가 라마2를 능가\\n<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\\n☞ 출처: Galileo, LLM Hallucination Index, 2023.11.15.'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 20, 'page_label': '21'}, page_content='18영국 옥스퍼드 인터넷 연구소 , AI 기술자의 임금이 평균 21% 높아\\nn옥스퍼드 인터넷 연구소의 연구에 따르면 특정 기술의 경제적 가치는 다른 기술과 결합 \\n가능성이 높을수록 높게 평가됨 \\nnAI의 확산은 기술의 경제적 가치에 크게 영향을 미치며 , AI 기술을 가진 근로자는 평균 21%, \\n최대 40% 높은 임금을 받을 수 있음  KEY Contents\\n£AI 기술 중 머신러닝 , 텐서플로우 , 딥러닝의 임금 프리미엄이 높게 평가\\nn옥스퍼드 인터넷 연구소 (Oxford Internet Institute) 가 2023년 10월 24일 962개 기술과 2만 5천 \\n명을 대상으로 한 연구에서 AI를 포함한 주요 기술의 경제적 가치를 분석한 결과를 발표 \\n∙연구에 따르면 한 기술의 경제적 가치는 근로자의 여타 역량과 얼마나 잘 결합하는지를 보여주는 \\n‘상보성 (complementarity)’ 에 따라 결정됨\\n∙특정 기술은 다른 기술과 결합 가능성이 높을수록 경제적 가치가 높아지며 , 일례로 데이터 분석과 같은 \\n기술은 여타 고부가가치 기술과 결합할 수 있어 가치가 높지만 , 사진 리터칭 같은 기술은 특정 기술과만 \\n결합할 수 있어 가치가 낮게 평가됨 \\n∙대부분 직업은 여러 기술의 조합이 필요하며 , 근로자의 재교육에서 경제적 효율성을 높이려면 기존 기술과 \\n신기술 간 상보성을 극대화할 필요\\nnAI의 확산은 기술의 경제적 가치에 크게 영향을 미치는 요소로 , AI 기술을 가진 근로자는 평균적으로  \\n21% 높은 임금을 획득 가능\\n∙AI 기술 중 근로자에 대한 경제적 가치(시간당 임금 증가율 기준) 측면에서 상위 5개 기술은 \\n머신러닝 (+40%), 텐서플로우 (+38%), 딥러닝 (+27%), 자연어처리 (+19%), 데이터 과학(+17%) 순\\n☞  출 처  : Oxford Internet Institute, AI com es out on top: Oxford Study identifies the economic value of specific skills, 2023.10.24.\\n<AI 기술 유형 평균 기술 대비 갖는 임금 프리미엄 >'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 21, 'page_label': '22'}, page_content='행사명 행사 주요 개요\\nCES 2024\\n-미국 소비자기술 협회(CTA) 가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스 , 교통·모빌리티 등 \\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n-CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며 , \\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한 \\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\nAIMLA 2024\\n-머신러닝 및 응용에 관한 국제 컨퍼런스 (AIMLA 2024) 는 \\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 \\n지식과  최신 연구 결과 공유\\n-이론 및 실무 측면에서 인공지능 , 기계학습의 주요 분야를 \\n논의하고 , 학계, 산업계의 연구자와 실무자들에게 해당 분\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\n2024.1.27~28 덴마크 , 코펜하겐https://ccnet2024.org/aimla\\n/index\\nAAAI Conference \\non Artificial \\nIntelligence\\n-AI 발전 협회 컨퍼런스 (AAAI) 는 AI 연구를 촉진하고 , AI 분야 \\n연구원 , 실무자 , 과학자 , 학생 및 공학자 간 교류의 기회 제공\\n-컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, \\n워크숍 , 튜토리얼 , 포스터 세션, 주제 발표, 대회, 전시 프\\n로그램 등 진행   \\n기간 장소 홈페이지\\n2024.2.20~27 캐나다 , 밴쿠버https://aaai.org/aaai-confere\\nnce/\\nⅡ. 주요 행사 일정'),\n",
       " Document(metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'author': 'dj', 'moddate': '2023-12-08T13:28:38+09:00', 'pdfversion': '1.4', 'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'page': 22, 'page_label': '23'}, page_content='홈페이지 : https://spri.kr/\\n보고서와 관련된 문의는 AI정책연구실 (jayoo@spri.kr, 031-739-7352) 으로 연락주시기 바랍니다 .')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 로드\n",
    "await adocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-readers-file 0.2.2 requires pypdf<5.0.0,>=4.0.1, but you have pypdf 6.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install -qU pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12 월호\n",
      "8코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기 ’ 플랫폼을 출시\n",
      "n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능KEY Contents\n",
      "£데이터 출처 탐색기 , 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "nAI 기업 코히어 (\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'pdfversion', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "author       : dj\n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "pdfversion   : 1.4\n",
      "source       : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "total_pages  : 23\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 출력\n",
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDF(OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidocr-onnxruntime in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (1.4.4)\n",
      "Requirement already satisfied: pyclipper>=1.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (1.3.0.post6)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (4.11.0.86)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.19.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (1.17.0)\n",
      "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (2.1.1)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (6.0.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (10.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (1.22.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rapidocr-onnxruntime) (4.67.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install -U rapidocr-onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutParser : A Uniﬁed Toolkit for DL-Based DIA 5\n",
      "Table 1: Current layout detection models in the LayoutParser model zoo\n",
      "Dataset Base Model1Large Model Notes\n",
      "PubLayNet [38] F / M M Layouts of modern scientiﬁc documents\n",
      "PRImA [3] M - Layouts of scanned modern magazines and scientiﬁc reports\n",
      "Newspape\n"
     ]
    }
   ],
   "source": [
    "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2103.15348.pdf\", extract_images=True)\n",
    "\n",
    "# PDF 페이지 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 페이지 내용 접근\n",
    "print(docs[4].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'keywords', 'moddate', 'ptex.fullbanner', 'subject', 'title', 'trapped', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer        : pdfTeX-1.40.21\n",
      "creator         : LaTeX with hyperref\n",
      "creationdate    : 2021-06-22T01:27:10+00:00\n",
      "author          : \n",
      "keywords        : \n",
      "moddate         : 2021-06-22T01:27:10+00:00\n",
      "ptex.fullbanner : This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2\n",
      "subject         : \n",
      "title           : \n",
      "trapped         : /False\n",
      "source          : https://arxiv.org/pdf/2103.15348.pdf\n",
      "total_pages     : 16\n",
      "page            : 0\n",
      "page_label      : 1\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (1.25.4)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-macosx_11_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "  Attempting uninstall: pymupdf\n",
      "    Found existing installation: PyMuPDF 1.25.4\n",
      "    Uninstalling PyMuPDF-1.25.4:\n",
      "      Successfully uninstalled PyMuPDF-1.25.4\n",
      "Successfully installed pymupdf-1.26.3\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install -U pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n 코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'source', 'file_path', 'total_pages', 'format', 'title', 'author', 'subject', 'keywords', 'moddate', 'trapped', 'modDate', 'creationDate', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "source       : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "file_path    : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "total_pages  : 23\n",
      "format       : PDF 1.4\n",
      "title        : \n",
      "author       : dj\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "trapped      : \n",
      "modDate      : D:20231208132838+09'00'\n",
      "creationDate : D:20231208132838+09'00'\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (0.17.0)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.11-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: filetype in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (5.3.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (4.13.4)\n",
      "Requirement already satisfied: emoji in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (3.13.0)\n",
      "Requirement already satisfied: backoff in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (4.14.1)\n",
      "Requirement already satisfied: unstructured-client in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (0.32.3)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk->unstructured) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk->unstructured) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk->unstructured) (2025.7.34)\n",
      "Requirement already satisfied: olefile in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->unstructured) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->unstructured) (2025.8.3)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (45.0.6)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.10.6)\n",
      "Requirement already satisfied: pypdf>=4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured-client->unstructured) (0.4.1)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (2.27.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Downloading unstructured-0.18.11-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unstructured\n",
      "  Attempting uninstall: unstructured\n",
      "    Found existing installation: unstructured 0.17.0\n",
      "    Uninstalling unstructured-0.17.0:\n",
      "      Successfully uninstalled unstructured-0.17.0\n",
      "Successfully installed unstructured-0.18.11\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install -U unstructured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pi_heif in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: unstructured_inference in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (1.0.5)\n",
      "Requirement already satisfied: pdfminer in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (20191125)\n",
      "Requirement already satisfied: pdfminer.six in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (20231228)\n",
      "Collecting pydf\n",
      "  Downloading pydf-12.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow>=11.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pi_heif) (11.3.0)\n",
      "Requirement already satisfied: python-multipart in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (0.0.20)\n",
      "Requirement already satisfied: huggingface-hub in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (0.29.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.26.4)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (4.11.0.86)\n",
      "Requirement already satisfied: onnx in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.18.0)\n",
      "Requirement already satisfied: onnxruntime>=1.18.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.22.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (3.10.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (2.6.0)\n",
      "Requirement already satisfied: timm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.0.19)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (4.50.3)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.10.0)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (3.13.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (2.2.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (1.16.1)\n",
      "Requirement already satisfied: pypdfium2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from unstructured_inference) (4.30.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer) (3.23.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six) (3.4.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six) (45.0.6)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.18.0->unstructured_inference) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.18.0->unstructured_inference) (25.2.10)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.18.0->unstructured_inference) (24.2)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.18.0->unstructured_inference) (6.31.1)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from onnxruntime>=1.18.0->unstructured_inference) (1.13.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from transformers>=4.25.1->unstructured_inference) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub->unstructured_inference) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub->unstructured_inference) (4.14.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from accelerate->unstructured_inference) (7.0.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from torch->unstructured_inference) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from torch->unstructured_inference) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from sympy->onnxruntime>=1.18.0->unstructured_inference) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.18.0->unstructured_inference) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jinja2->torch->unstructured_inference) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from matplotlib->unstructured_inference) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->unstructured_inference) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->unstructured_inference) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->unstructured_inference) (2025.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->transformers>=4.25.1->unstructured_inference) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->transformers>=4.25.1->unstructured_inference) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests->transformers>=4.25.1->unstructured_inference) (2025.8.3)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from timm->unstructured_inference) (0.21.0)\n",
      "Building wheels for collected packages: pydf\n",
      "\u001b[33m  DEPRECATION: Building 'pydf' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pydf'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pydf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pydf: filename=pydf-12-py2.py3-none-any.whl size=8434 sha256=9da838ea44f6678397ffbb4e1f30a9a88a55d7a3eabcd4b0dc61ece568482b00\n",
      "  Stored in directory: /Users/mypsyche/Library/Caches/pip/wheels/c0/c2/38/099e286446cf34a42d3fb15b8f35ed6e2f7fdd17d91e25c07e\n",
      "Successfully built pydf\n",
      "Installing collected packages: pydf\n",
      "Successfully installed pydf-12\n"
     ]
    }
   ],
   "source": [
    "!pip install pi_heif unstructured_inference pdfminer pdfminer.six pydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer.psexceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m loader = UnstructuredPDFLoader(FILE_PATH)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 문서의 내용 출력\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[32m0\u001b[39m].page_content[:\u001b[32m300\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.lazy_load())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:92\u001b[39m, in \u001b[36mUnstructuredPDFLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename=\u001b[38;5;28mself\u001b[39m.file_path, **\u001b[38;5;28mself\u001b[39m.unstructured_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf.py:70\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mform_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_form_extraction\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     check_element_types_to_extract,\n\u001b[32m     67\u001b[39m     convert_pdf_to_images,\n\u001b[32m     68\u001b[39m     save_elements,\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     check_annotations_within_element,\n\u001b[32m     72\u001b[39m     clean_pdfminer_inner_elements,\n\u001b[32m     73\u001b[39m     get_links_in_element,\n\u001b[32m     74\u001b[39m     get_uris,\n\u001b[32m     75\u001b[39m     get_words_from_obj,\n\u001b[32m     76\u001b[39m     map_bbox_and_index,\n\u001b[32m     77\u001b[39m     merge_inferred_with_extracted_layout,\n\u001b[32m     78\u001b[39m )\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m     PDFMinerConfig,\n\u001b[32m     81\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     82\u001b[39m     rect_to_bbox,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstrategies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m determine_pdf_or_image_strategy, validate_strategy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf_image/pdfminer_processing.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01melements\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoordinatesMetadata, ElementType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_control_characters\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     PDFMinerConfig,\n\u001b[32m     19\u001b[39m     extract_image_objects,\n\u001b[32m     20\u001b[39m     extract_text_objects,\n\u001b[32m     21\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     22\u001b[39m     rect_to_bbox,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m env_config\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SORT_MODE_BASIC, Source\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf_image/pdfminer_utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfinterp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPageInterpreter, PDFResourceManager\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPage\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpsexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PSSyntaxError\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pdfminer.psexceptions'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# UnstructuredPDFLoader 인스턴스 생성\n",
    "loader = UnstructuredPDFLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer.psexceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m loader = UnstructuredPDFLoader(FILE_PATH, mode=\u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 문서의 내용 출력\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[32m0\u001b[39m].page_content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.lazy_load())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:92\u001b[39m, in \u001b[36mUnstructuredPDFLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename=\u001b[38;5;28mself\u001b[39m.file_path, **\u001b[38;5;28mself\u001b[39m.unstructured_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf.py:70\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mform_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_form_extraction\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     check_element_types_to_extract,\n\u001b[32m     67\u001b[39m     convert_pdf_to_images,\n\u001b[32m     68\u001b[39m     save_elements,\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     check_annotations_within_element,\n\u001b[32m     72\u001b[39m     clean_pdfminer_inner_elements,\n\u001b[32m     73\u001b[39m     get_links_in_element,\n\u001b[32m     74\u001b[39m     get_uris,\n\u001b[32m     75\u001b[39m     get_words_from_obj,\n\u001b[32m     76\u001b[39m     map_bbox_and_index,\n\u001b[32m     77\u001b[39m     merge_inferred_with_extracted_layout,\n\u001b[32m     78\u001b[39m )\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m     PDFMinerConfig,\n\u001b[32m     81\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     82\u001b[39m     rect_to_bbox,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstrategies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m determine_pdf_or_image_strategy, validate_strategy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf_image/pdfminer_processing.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01melements\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoordinatesMetadata, ElementType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_control_characters\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     PDFMinerConfig,\n\u001b[32m     19\u001b[39m     extract_image_objects,\n\u001b[32m     20\u001b[39m     extract_text_objects,\n\u001b[32m     21\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     22\u001b[39m     rect_to_bbox,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m env_config\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SORT_MODE_BASIC, Source\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/unstructured/partition/pdf_image/pdfminer_utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfinterp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPageInterpreter, PDFResourceManager\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPage\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpsexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PSSyntaxError\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pdfminer.psexceptions'"
     ]
    }
   ],
   "source": [
    "# UnstructuredPDFLoader 인스턴스 생성(mode=\"elements\")\n",
    "loader = UnstructuredPDFLoader(FILE_PATH, mode=\"elements\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'category'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 데이터 카테고리 추출\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs)  \u001b[38;5;66;03m# 데이터 카테고리 추출\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'category'"
     ]
    }
   ],
   "source": [
    "set(doc.metadata[\"category\"] for doc in docs)  # 데이터 카테고리 추출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDFium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief | \n",
      "2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어(Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDFium2 로더 인스턴스 생성\n",
    "loader = PyPDFium2Loader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'title', 'author', 'subject', 'keywords', 'moddate', 'source', 'total_pages', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "title        : \n",
      "author       : dj\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "source       : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "total_pages  : 23\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년  12월호\n",
      "\f2023년  12월호\n",
      "\n",
      "Ⅰ.  인공지능  산업  동향  브리프\n",
      "\n",
      "  1.  정책/법제 \n",
      "\n",
      "      ▹  미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표    ························· 1\n",
      "\n",
      "      ▹  G7,  히로시마  AI  프로세스를  통해  AI  기업  대상  국제  행동강령에  합의 ··························· 2\n",
      "\n",
      "      ▹  영국  AI  안전성  정상회의에  참가한  28개국,  AI  위험에  공동  \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "# PDFMiner 로더 인스턴스 생성\n",
    "loader = PDFMinerLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'pdfversion', 'total_pages', 'source']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "author       : dj\n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "pdfversion   : 1.4\n",
      "total_pages  : 23\n",
      "source       : ./SPRI_AI_Brief_2023년12월호_F.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html\">\n",
      "</head><body>\n",
      "<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span>\n",
      "<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\n",
      "<div style=\"position:absolute; border\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "\n",
    "# PDFMinerPDFasHTMLLoader 인스턴스 생성\n",
    "loader = PDFMinerPDFasHTMLLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source']\n",
      "\n",
      "[examples]\n",
      "source : ./SPRI_AI_Brief_2023년12월호_F.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(docs[0].page_content, \"html.parser\")  # HTML 파서 초기화\n",
    "content = soup.find_all(\"div\")  # 모든 div 태그 검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cur_fs = None\n",
    "cur_text = \"\"\n",
    "snippets = []  # 동일한 글꼴 크기의 모든 스니펫 수집\n",
    "for c in content:\n",
    "    sp = c.find(\"span\")\n",
    "    if not sp:\n",
    "        continue\n",
    "    st = sp.get(\"style\")\n",
    "    if not st:\n",
    "        continue\n",
    "    fs = re.findall(\"font-size:(\\d+)px\", st)\n",
    "    if not fs:\n",
    "        continue\n",
    "    fs = int(fs[0])\n",
    "    if not cur_fs:\n",
    "        cur_fs = fs\n",
    "    if fs == cur_fs:\n",
    "        cur_text += c.text\n",
    "    else:\n",
    "        snippets.append((cur_text, cur_fs))\n",
    "        cur_fs = fs\n",
    "        cur_text = c.text\n",
    "snippets.append((cur_text, cur_fs))\n",
    "# 중복 스니펫 제거 전략 추가 가능성 (PDF의 헤더/푸터가 여러 페이지에 걸쳐 나타나므로 중복 발견 시 중복 정보로 간주 가능)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='KEY Contents\n",
      "n 미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령’에 서명하고 \n",
      "광범위한  행정  조치를  명시\n",
      "n 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 \n",
      "보호  △노동자  지원  △혁신과  경쟁  촉진  △국제협력을  골자로  함\n",
      "' metadata={'heading': '미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표 \\n', 'content_font': 12, 'heading_font': 15, 'source': './SPRI_AI_Brief_2023년12월호_F.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "cur_idx = -1\n",
    "semantic_snippets = []\n",
    "# 제목 가정: 높은 글꼴 크기\n",
    "for s in snippets:\n",
    "    # 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\n",
    "    if (\n",
    "        not semantic_snippets\n",
    "        or s[1] > semantic_snippets[cur_idx].metadata[\"heading_font\"]\n",
    "    ):\n",
    "        metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "        metadata.update(docs[0].metadata)\n",
    "        semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "        cur_idx += 1\n",
    "        continue\n",
    "\n",
    "    # 동일 섹션 내용 판별: 현재 스니펫 글꼴 <= 이전 내용 글꼴\n",
    "    if (\n",
    "        not semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        or s[1] <= semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "    ):\n",
    "        semantic_snippets[cur_idx].page_content += s[0]\n",
    "        semantic_snippets[cur_idx].metadata[\"content_font\"] = max(\n",
    "            s[1], semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # 새 섹션 생성 조건: 현재 스니펫 글꼴 > 이전 내용 글꼴, 이전 제목 글꼴 미만\n",
    "    metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "    metadata.update(docs[0].metadata)\n",
    "    semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "    cur_idx += 1\n",
    "\n",
    "print(semantic_snippets[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyPDF 디렉토리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 디렉토리 경로\n",
    "loader = PyPDFDirectoryLoader(\"./\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 개수 출력\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 년 12월\n"
     ]
    }
   ],
   "source": [
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFPlumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "KEY Contents\n",
      "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태,\n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의\n",
      "구성과 계보도 추적 가능\n",
      "£데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어(Cohere)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# PDF 문서 로더 인스턴스 생성\n",
    "loader = PDFPlumberLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 첫 번째 문서 데이터 접근\n",
    "print(docs[10].page_content[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'file_path', 'page', 'total_pages', 'Author', 'Creator', 'Producer', 'CreationDate', 'ModDate', 'PDFVersion']\n",
      "\n",
      "[examples]\n",
      "source       : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "file_path    : ./SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "page         : 0\n",
      "total_pages  : 23\n",
      "Author       : dj\n",
      "Creator      : Hwp 2018 10.0.0.13462\n",
      "Producer     : Hancom PDF 1.3.0.542\n",
      "CreationDate : D:20231208132838+09'00'\n",
      "ModDate      : D:20231208132838+09'00'\n",
      "PDFVersion   : 1.4\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HWP (한글)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-teddynote in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (0.3.44)\n",
      "Collecting langchain-teddynote\n",
      "  Downloading langchain_teddynote-0.3.45-py3-none-any.whl.metadata (867 bytes)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.3.27)\n",
      "Requirement already satisfied: langgraph in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.3.18)\n",
      "Requirement already satisfied: kiwipiepy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.20.4)\n",
      "Requirement already satisfied: rank_bm25 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: pinecone-client[grpc] in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (3.2.2)\n",
      "Requirement already satisfied: pinecone-text in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.11.0)\n",
      "Requirement already satisfied: olefile in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: pdf2image in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (1.99.9)\n",
      "Requirement already satisfied: anthropic in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.62.0)\n",
      "Requirement already satisfied: deepl in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (1.21.1)\n",
      "Requirement already satisfied: feedparser in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (6.0.11)\n",
      "Requirement already satisfied: tavily-python in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.7.10)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic->langchain-teddynote) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic->langchain-teddynote) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic->langchain-teddynote) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic->langchain-teddynote) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (2.27.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from deepl->langchain-teddynote) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl->langchain-teddynote) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl->langchain-teddynote) (2.5.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from feedparser->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: kiwipiepy-model<0.21,>=0.20 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (0.20.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.4.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->langchain-teddynote) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->langchain-teddynote) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain-teddynote) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain-teddynote) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain-teddynote) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->langchain-teddynote) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->langchain-teddynote) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain->langchain-teddynote) (0.23.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (0.1.74)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->langchain-teddynote) (1.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdf2image->langchain-teddynote) (11.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.70.0)\n",
      "Requirement already satisfied: grpc-gateway-protoc-gen-openapiv2==0.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.1.0)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.67.1)\n",
      "Requirement already satisfied: lz4>=3.1.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.4.4)\n",
      "Collecting protobuf<3.21.0,>=3.20.0 (from pinecone-client[grpc]->langchain-teddynote)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (1.0.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (2.32.4.20250809)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (2025.7.34)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from tavily-python->langchain-teddynote) (0.9.0)\n",
      "Downloading langchain_teddynote-0.3.45-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: protobuf, langchain-teddynote\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1\n",
      "\u001b[2K  Attempting uninstall: langchain-teddynote\n",
      "\u001b[2K    Found existing installation: langchain-teddynote 0.3.44\n",
      "\u001b[2K    Uninstalling langchain-teddynote-0.3.44:\n",
      "\u001b[2K      Successfully uninstalled langchain-teddynote-0.3.44\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain-teddynote]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-teddynote-0.3.45 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "# 설치\n",
    "!pip install -U langchain-teddynote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.document_loaders import HWPLoader\n",
    "\n",
    "# HWP Loader 객체 생성\n",
    "loader = HWPLoader(\"./디지털 정부혁신 추진계획.hwp\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디지털 정부혁신 추진계획2019. 10. 29.      관계부처 합동순    서Ⅰ. 개요ȃ 1Ⅱ. 디지털 정부혁신 추진계획ㆬȃ 2  1. 우선 추진과제ȃ 2     ① 선제적·통합적 대국민 서비스 혁신     ② 공공부문 마이데이터 활성화     ③ 시민참여를 위한 플랫폼 고도화     ④ 현장중심 협업을 지원하는 스마트 업무환경 구현     ⑤ 클라우드와 디지털서비스 이용 활성화     ⑥ 개방형 데이터·서비스 생태계 구축  2. 중장기 범정부 디지털 전환 로드맵 수립ᲈȃ 4Ⅲ. 추진체계 및 일정ȃ 4 [붙임] 디지털 정부혁신 우선 추진과제(상세)ᬜȃ 8Ⅰ. 개 요□ 추진 배경 ○ 우리나라는 국가적 초고속 정보통신망 투자와 적극적인 공공정보화 사업 추진에 힘입어 세계 최고수준의 전자정부를 구축‧운영     * UN전자정부평가에서 2010‧12‧14년 1위, 16‧18년 3위, UN공공행정상 13회 수상 ○ 그러나, 인공지능‧클라우드 중심의 디지털 전환(Digital Transformation) 시대가 도래함에 따라 기존 전자정부의 한계 표출   - 축적된 행정데이터에도 불구하고 기관간 연계‧활용 미흡, 부처 단위로 단절된 서비스, 신기술 활용을 위한 제도‧기반 부족   - 디지털 전환을 위한 컨트롤타워가 없고, 구체적 전략도 부재 ○ 이에, ‘19.3월부터 공공부문 ICT 활용현황 및 문제점 검토에 착수하여 공공분야 디지털 전환을 위한 추진계획 마련     * 관계부처 협의 21회(행안,과기정통,기재,복지,권익위,국정원 등), 민간전문가 의견청취 10회□ 문제점 진단 및 평가 ○ (서비스) 국민과 최종 이용자 관점에서 서비스 혁신 미흡   - 자격이 있어도 자신이 받을 수 있는 공공서비스를 파악하기 어려워 사각지대가 발생하고, 온라인 신청 가능한 서비스도 제한적 ○ (데이터) 기관별로 축적·보유한 데이터의 연계와 활용 부족   - A기관에서 서류를 발급받아 B기관에 제출하는 관행(연간 증명서 9.5억건‘18년 발급) 등 데이터가 국민편익 향상에 제대로 활용\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(docs[0].page_content[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './디지털 정부혁신 추진계획.hwp'}\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "{'source': './titanic.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# CSV 로더 생성\n",
    "loader = CSVLoader(file_path=\"./titanic.csv\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger ID: 1\n",
      "Survival (1: Survived, 0: Died): 0\n",
      "Passenger Class: 3\n",
      "Name: Braund, Mr. Owen Harris\n",
      "Sex: male\n",
      "Age: 22\n",
      "Number of Siblings/Spouses Aboard: 1\n",
      "Number of Parents/Children Aboard: 0\n",
      "Ticket Number: A/5 21171\n",
      "Fare: 7.25\n",
      "Cabin: \n",
      "Port of Embarkation: S\n"
     ]
    }
   ],
   "source": [
    "# 컬럼정보:\n",
    "# PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "\n",
    "# CSV 파일 경로\n",
    "loader = CSVLoader(\n",
    "    file_path=\"./titanic.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",  # 구분자\n",
    "        \"quotechar\": '\"',  # 인용 부호 문자\n",
    "        \"fieldnames\": [\n",
    "            \"Passenger ID\",\n",
    "            \"Survival (1: Survived, 0: Died)\",\n",
    "            \"Passenger Class\",\n",
    "            \"Name\",\n",
    "            \"Sex\",\n",
    "            \"Age\",\n",
    "            \"Number of Siblings/Spouses Aboard\",\n",
    "            \"Number of Parents/Children Aboard\",\n",
    "            \"Ticket Number\",\n",
    "            \"Fare\",\n",
    "            \"Cabin\",\n",
    "            \"Port of Embarkation\",\n",
    "        ],  # 필드 이름\n",
    "    },\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 데이터 출력\n",
    "print(docs[1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='PassengerId: 2\n",
      "Survived: 1\n",
      "Pclass: 1\n",
      "Name: Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
      "Sex: female\n",
      "Age: 38\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: PC 17599\n",
      "Fare: 71.2833\n",
      "Cabin: C85\n",
      "Embarked: C' metadata={'source': '2', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=\"./titanic.csv\", source_column=\"PassengerId\"\n",
    ")  # CSV 로더 설정, 파일 경로 및 소스 컬럼 지정\n",
    "\n",
    "docs = loader.load()  # 데이터 로드\n",
    "\n",
    "print(docs[1])  # 데이터 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table><tr><td>PassengerId</td><td>Survived</td><td>Pclass</td><td>Name</td><td>Sex</td><td>Age</td><td>SibSp</td><td>Parch</td><td>Ticket</td><td>Fare</td><td>Cabin</td><td>Embarked</td></tr><tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen Harris</td><td>male</td><td>22</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td/><td>S</td></tr><tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female</td><td>38</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td/><td>S</td></tr><tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr><tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. William Henry</td><td>male</td><td>35</\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import UnstructuredCSVLoader\n",
    "\n",
    "# 비구조화 CSV 로더 인스턴스 생성\n",
    "loader = UnstructuredCSVLoader(file_path=\"./titanic.csv\", mode=\"elements\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 첫 번째 문서의 HTML 텍스트 메타데이터 출력\n",
    "print(docs[0].metadata[\"text_as_html\"][:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(\"./titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 처음 다섯 행 조회\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Braund, Mr. Owen Harris\n",
      "{'PassengerId': 1, 'Survived': 0, 'Pclass': 3, 'Sex': 'male', 'Age': 22.0, 'SibSp': 1, 'Parch': 0, 'Ticket': 'A/5 21171', 'Fare': 7.25, 'Cabin': nan, 'Embarked': 'S'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "# 데이터 프레임 로더 설정, 페이지 내용 컬럼 지정\n",
    "loader = DataFrameLoader(df, page_content_column=\"Name\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 데이터 출력\n",
    "print(docs[0].page_content)\n",
    "\n",
    "# 메타데이터 출력\n",
    "print(docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Braund, Mr. Owen Harris' metadata={'PassengerId': 1, 'Survived': 0, 'Pclass': 3, 'Sex': 'male', 'Age': 22.0, 'SibSp': 1, 'Parch': 0, 'Ticket': 'A/5 21171', 'Fare': 7.25, 'Cabin': nan, 'Embarked': 'S'}\n"
     ]
    }
   ],
   "source": [
    "# 큰 테이블에 대한 지연 로딩, 전체 테이블을 메모리에 로드하지 않음\n",
    "for row in loader.lazy_load():\n",
    "    print(row)\n",
    "    break  # 첫 행만 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMs2OSEsEhI+eP+P38efuYH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
