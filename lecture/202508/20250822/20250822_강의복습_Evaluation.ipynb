{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 링크를 복사하여 웹 브라우저에 붙여넣으세요.\n",
      "https://accounts.google.com/o/oauth2/auth?client_id=35726703810-4v13dfqmilhgv6shlc3cv9i3ktuh73j1.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mykeys\n",
    "\n",
    "project_name = 'CH15_Evaluation'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"OPENAI_API_KEY\"] = mykeys.get_key('GPT')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = mykeys.get_key('GOO')\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = mykeys.get_key('HF')\n",
    "os.environ[\"UPSTAGE_API_KEY\"] = mykeys.get_key('UP')\n",
    "os.environ[\"COHERE_API_KEY\"] = mykeys.get_key('COH')\n",
    "os.environ[\"JINA_API_KEY\"] = mykeys.get_key('JINA')\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = mykeys.get_key('ANT')\n",
    "os.environ[\"DEEPL_API_KEY\"] = mykeys.get_key('DEEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH15_Evaluation\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CH15 평가(Evaluations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. 합성 테스트 데이터셋 생성(RAGAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ragas 0.1.21\n",
      "Uninstalling ragas-0.1.21:\n",
      "  Successfully uninstalled ragas-0.1.21\n",
      "Collecting ragas\n",
      "  Using cached ragas-0.3.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (2.10.6)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.2.17)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.2.43)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.2.19)\n",
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.1.25)\n",
      "Requirement already satisfied: typer in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (0.16.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (1.99.9)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (4.67.1)\n",
      "Requirement already satisfied: instructor in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (1.10.0)\n",
      "Requirement already satisfied: gitpython in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (3.1.45)\n",
      "Requirement already satisfied: pillow>=10.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai>=1.0.0->ragas) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.0.0->ragas) (2.27.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (0.34.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets->ragas) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from gitpython->ragas) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from instructor->ragas) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from instructor->ragas) (3.1.6)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from instructor->ragas) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rich->ragas) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from typer->ragas) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->ragas) (2.0.39)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->ragas) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain->ragas) (0.1.147)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from tiktoken->ragas) (2025.7.34)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
      "Using cached ragas-0.3.2-py3-none-any.whl (277 kB)\n",
      "Installing collected packages: ragas\n",
      "Successfully installed ragas-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y ragas\n",
    "!pip install ragas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# 문서 로더 생성\n",
    "loader = PDFPlumberLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 목차, 끝 페이지 제외\n",
    "docs = docs[3:-1]\n",
    "\n",
    "# 문서의 페이지수\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 설정(filename 이 존재해야 함)\n",
    "for doc in docs:\n",
    "    doc.metadata[\"filename\"] = doc.metadata[\"source\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Keyphrases' from 'ragas.testset.transforms.extractors' (/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/ragas/testset/transforms/extractors/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangchainLLMWrapper\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangchainEmbeddingsWrapper\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mragas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtestset\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextractors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Keyphrases\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#from ragas.testset.docstore import InMemoryDocumentStore\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI, OpenAIEmbeddings\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Keyphrases' from 'ragas.testset.transforms.extractors' (/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/ragas/testset/transforms/extractors/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "#from ragas.testset.evolutions import simple, reasoning, multi_context, conditional\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.testset.transforms.extractors import Keyphrases\n",
    "#from ragas.testset.docstore import InMemoryDocumentStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 데이터셋 생성기\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "# 데이터셋 비평기\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
    "# 문서 임베딩\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyphraseExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m langchain_llm = LangchainLLMWrapper(ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 주요 구문 추출기를 초기화합니다. 위에서 정의한 LLM을 사용합니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m keyphrase_extractor = \u001b[43mKeyphraseExtractor\u001b[49m(llm=langchain_llm)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ragas_embeddings 생성\u001b[39;00m\n\u001b[32m     11\u001b[39m ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
      "\u001b[31mNameError\u001b[39m: name 'KeyphraseExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "# 텍스트 분할기를 설정합니다.\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# LangChain의 ChatOpenAI 모델을 LangchainLLMWrapper로 감싸 Ragas와 호환되게 만듭니다.\n",
    "langchain_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "\n",
    "# 주요 구문 추출기를 초기화합니다. 위에서 정의한 LLM을 사용합니다.\n",
    "keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\n",
    "\n",
    "# ragas_embeddings 생성\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# InMemoryDocumentStore를 초기화합니다.\n",
    "# 이는 문서를 메모리에 저장하고 관리하는 저장소입니다.\n",
    "docstore = InMemoryDocumentStore(\n",
    "    splitter=splitter,\n",
    "    embeddings=ragas_embeddings,\n",
    "    extractor=keyphrase_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    ragas_embeddings,\n",
    "    docstore=docstore,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 유형별 분포 결정\n",
    "# simple: 간단한 질문, reasoning: 추론이 필요한 질문, multi_context: 여러 맥락을 고려해야 하는 질문, conditional: 조건부 질문\n",
    "distributions = {simple: 0.4, reasoning: 0.2, multi_context: 0.2, conditional: 0.2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 생성\n",
    "# docs: 문서 데이터, 10: 생성할 질문의 수, distributions: 질문 유형별 분포, with_debugging_logs: 디버깅 로그 출력 여부\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents=docs, test_size=10, distributions=distributions, with_debugging_logs=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 테스트셋을 pandas DataFrame으로 변환\n",
    "test_df = testset.to_pandas()\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame의 상위 5개 행 출력\n",
    "test_df.head()\n",
    "\n",
    "# DataFrame을 CSV 파일로 저장\n",
    "test_df.to_csv(\"data/ragas_synthetic_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/teddylee777/langchain-kr/blob/main/16-Evaluations/data/ragas_synthetic_dataset.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. RAGAS 를 활용한 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "evolution_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metadata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_done",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "ddb9cd84-29b6-4f26-8db4-4ed9cf71b239",
       "rows": [
        [
         "0",
         "What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?",
         "['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,', '저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10']",
         "TechRepublic highlighted several recent developments in generative AI in their November 2023 articles, including the introduction of 'Generative AI' as a key focus, advancements in AI models such as Llama 2, and the application of generative AI in various fields. They also discussed the importance of AI in enhancing user experience and the potential for generative AI to transform industries.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "1",
         "What are the dates and location for CES 2024?",
         "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']",
         "CES 2024 will take place from January 9 to January 12, 2024, in Las Vegas, Nevada.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "2",
         "What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?",
         "['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\\n지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\\nn (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교\\n내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과\\n모범사례를 마련\\nn (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을\\n통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\\n∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서\\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of\\nArtificial Intelligence (E.O. 14110), 2023.10.30.', 'SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nKEY Contents\\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\\n채택을 권고하는 AI 국제 행동강령을 마련\\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nn G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록\\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고,\\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화']",
         "The key aspects of AI global cooperation highlighted in the G7's approach include the establishment of an international code of conduct for advanced AI systems, the promotion of ethical guidelines, and the development of regulatory frameworks that ensure the safe and trustworthy use of AI. The G7 emphasizes the importance of collaboration among member countries to address the challenges posed by AI technologies and to create a unified approach to governance and oversight.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 3, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "3",
         "What measures are suggested to enhance data privacy in the context of advanced AI systems?",
         "['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화\\n∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시\\n신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는\\nAI 거버넌스와 위험 관리 정책을 마련\\n∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로\\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축\\n∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기\\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집\\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.\\n2']",
         "The context suggests several measures to enhance data privacy in advanced AI systems, including the implementation of strict data governance policies, ensuring transparency in data usage, and establishing robust security protocols to protect sensitive information. Additionally, it emphasizes the importance of user consent and the ethical handling of data.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "4",
         "What were the main takeaways from the AI Safety Summit on global AI testing?",
         "['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\\nn 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of\\nthe Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한\\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\nn 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며,\\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\\nconcludes, 2023.11.02.']",
         "The main takeaways from the AI Safety Summit on global AI testing include the establishment of a plan for safety testing of frontier AI technologies, as discussed by world leaders and top AI companies. The summit emphasized the importance of collaboration among nations to ensure AI safety and the need for ongoing dialogue and regulation in the field of AI.",
         "reasoning",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...   \n",
       "1  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...   \n",
       "2  ['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...   \n",
       "3  ['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...   \n",
       "4  ['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  TechRepublic highlighted several recent develo...         simple   \n",
       "1  CES 2024 will take place from January 9 to Jan...         simple   \n",
       "2  The key aspects of AI global cooperation highl...         simple   \n",
       "3  The context suggests several measures to enhan...         simple   \n",
       "4  The main takeaways from the AI Safety Summit o...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "test_dataset = Dataset.from_pandas(df)\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58b6a62503448949575fb08dab74241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import ast \n",
    "def convert_to_list(example):\n",
    "    contexts = ast.literal_eval(example[\"contexts\"])\n",
    "    return {\"contexts\": contexts}\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(convert_to_list)\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1][\"contexts\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?',\n",
       " 'What are the dates and location for CES 2024?',\n",
       " \"What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dataset = [question for question in test_dataset[\"question\"]]\n",
    "batch_dataset[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['According to the provided context, TechRepublic highlighted the rise of on-device AI as a major technology trend in their November 2023 articles. Specifically, they noted the unveiling of Samsung\\'s generative AI model \"Samsung Gauss,\" which is designed to operate on devices (on-device AI) and consists of three models: a language model, a code model, and an image model. The on-device operation of Samsung Gauss is emphasized as a key advantage, as it reduces the risk of user information being leaked externally. TechRepublic pointed out that on-device AI is emerging as a significant trend in the technology industry.',\n",
       " 'CES 2024 will be held from January 9 to January 12, 2024, in Las Vegas, USA.',\n",
       " \"The G7's approach to ethical considerations and regulatory frameworks for advanced AI systems, as highlighted in the provided context, emphasizes several key aspects of global cooperation:\\n\\n1. **International Code of Conduct**: The G7 agreed on an International Code of Conduct for Advanced AI Systems, targeting companies developing advanced AI, including foundation models and generative AI. This code is intended to be adopted voluntarily by companies.\\n\\n2. **Risk Assessment and Mitigation**: The code requires companies to assess and mitigate risks throughout the entire AI lifecycle, including after deployment, to address vulnerabilities, misuse, and incidents.\\n\\n3. **Transparency and Accountability**: Companies are expected to disclose the performance and limitations of advanced AI systems, and clearly communicate appropriate and inappropriate use cases to ensure transparency and strengthen accountability.\\n\\n4. **Information Sharing and Stakeholder Collaboration**: The G7 stresses the importance of information sharing and cooperation among industry, government, civil society, and academia, especially for incident reporting and risk management.\\n\\n5. **Security Controls**: Strong security measures are required, including physical security, cybersecurity, and protection against insider threats, throughout the AI lifecycle.\\n\\n6. **Content Authentication**: The development and implementation of technical mechanisms, such as watermarks, are encouraged to help users identify AI-generated content and verify its source.\\n\\n7. **Social Risk Mitigation and Global Challenges**: The G7 prioritizes research and investment in mitigating social risks and addressing global challenges like climate change, health, and education through advanced AI.\\n\\n8. **International Standards and Data Protection**: Accelerating the development and adoption of international technical standards, and ensuring data protection and intellectual property safeguards during data collection and input.\\n\\n9. **Adaptive Governance**: The code is designed to be updated as needed through stakeholder consultations to keep pace with rapidly evolving AI technologies.\\n\\nThese aspects collectively reflect a commitment to responsible AI development and deployment, emphasizing international collaboration, transparency, risk management, and the protection of fundamental rights.\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chain.batch(batch_dataset)\n",
    "answer[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'answer' 컬럼 덮어쓰기 또는 추가\n",
    "if \"answer\" in test_dataset.column_names:\n",
    "    test_dataset = test_dataset.remove_columns([\"answer\"]).add_column(\"answer\", answer)\n",
    "else:\n",
    "    test_dataset = test_dataset.add_column(\"answer\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b32d3cd386c4636ab06c8f2fba41a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 0.6000, 'faithfulness': 0.5068, 'answer_relevancy': 0.9682, 'context_recall': 0.6833}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=test_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_input",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "retrieved_contexts",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "faithfulness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "answer_relevancy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "context_recall",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "28c75345-cdc6-4c8a-be93-6e8ad8a48947",
       "rows": [
        [
         "0",
         "What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?",
         "['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,', '저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10']",
         "According to the provided context, TechRepublic highlighted the rise of on-device AI as a major technology trend in their November 2023 articles. Specifically, they noted the unveiling of Samsung's generative AI model \"Samsung Gauss,\" which is designed to operate on devices (on-device AI) and consists of three models: a language model, a code model, and an image model. The on-device operation of Samsung Gauss is emphasized as a key advantage, as it reduces the risk of user information being leaked externally. TechRepublic pointed out that on-device AI is emerging as a significant trend in the technology industry.",
         "TechRepublic highlighted several recent developments in generative AI in their November 2023 articles, including the introduction of 'Generative AI' as a key focus, advancements in AI models such as Llama 2, and the application of generative AI in various fields. They also discussed the importance of AI in enhancing user experience and the potential for generative AI to transform industries.",
         "0.49999999995",
         "0.8571428571428571",
         "0.9192459703082926",
         "0.0"
        ],
        [
         "1",
         "What are the dates and location for CES 2024?",
         "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']",
         "CES 2024 will be held from January 9 to January 12, 2024, in Las Vegas, USA.",
         "CES 2024 will take place from January 9 to January 12, 2024, in Las Vegas, Nevada.",
         "0.9999999999",
         "1.0",
         "0.9571199605936328",
         "1.0"
        ],
        [
         "2",
         "What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?",
         "['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\\n지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\\nn (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교\\n내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과\\n모범사례를 마련\\nn (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을\\n통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\\n∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서\\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of\\nArtificial Intelligence (E.O. 14110), 2023.10.30.', 'SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nKEY Contents\\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\\n채택을 권고하는 AI 국제 행동강령을 마련\\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nn G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록\\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고,\\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화']",
         "The G7's approach to ethical considerations and regulatory frameworks for advanced AI systems, as highlighted in the provided context, emphasizes several key aspects of global cooperation:\n\n1. **International Code of Conduct**: The G7 agreed on an International Code of Conduct for Advanced AI Systems, targeting companies developing advanced AI, including foundation models and generative AI. This code is intended to be adopted voluntarily by companies.\n\n2. **Risk Assessment and Mitigation**: The code requires companies to assess and mitigate risks throughout the entire AI lifecycle, including after deployment, to address vulnerabilities, misuse, and incidents.\n\n3. **Transparency and Accountability**: Companies are expected to disclose the performance and limitations of advanced AI systems, and clearly communicate appropriate and inappropriate use cases to ensure transparency and strengthen accountability.\n\n4. **Information Sharing and Stakeholder Collaboration**: The G7 stresses the importance of information sharing and cooperation among industry, government, civil society, and academia, especially for incident reporting and risk management.\n\n5. **Security Controls**: Strong security measures are required, including physical security, cybersecurity, and protection against insider threats, throughout the AI lifecycle.\n\n6. **Content Authentication**: The development and implementation of technical mechanisms, such as watermarks, are encouraged to help users identify AI-generated content and verify its source.\n\n7. **Social Risk Mitigation and Global Challenges**: The G7 prioritizes research and investment in mitigating social risks and addressing global challenges like climate change, health, and education through advanced AI.\n\n8. **International Standards and Data Protection**: Accelerating the development and adoption of international technical standards, and ensuring data protection and intellectual property safeguards during data collection and input.\n\n9. **Adaptive Governance**: The code is designed to be updated as needed through stakeholder consultations to keep pace with rapidly evolving AI technologies.\n\nThese aspects collectively reflect a commitment to responsible AI development and deployment, emphasizing international collaboration, transparency, risk management, and the protection of fundamental rights.",
         "The key aspects of AI global cooperation highlighted in the G7's approach include the establishment of an international code of conduct for advanced AI systems, the promotion of ethical guidelines, and the development of regulatory frameworks that ensure the safe and trustworthy use of AI. The G7 emphasizes the importance of collaboration among member countries to address the challenges posed by AI technologies and to create a unified approach to governance and oversight.",
         "0.49999999995",
         "0.5",
         "0.9783219635044952",
         "1.0"
        ],
        [
         "3",
         "What measures are suggested to enhance data privacy in the context of advanced AI systems?",
         "['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화\\n∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시\\n신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는\\nAI 거버넌스와 위험 관리 정책을 마련\\n∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로\\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축\\n∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기\\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집\\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.\\n2']",
         "The following measures are suggested to enhance data privacy in the context of advanced AI systems:\n\n- Implementing strong privacy protection policies and risk mitigation measures based on a risk-based approach, including throughout the AI lifecycle (such as physical security, cybersecurity, and insider threat protection).\n- Ensuring appropriate safeguards are in place during data input and collection to protect personal information and intellectual property rights.\n- Developing and adopting international technical standards for privacy protection.\n- Analyzing techniques for identifying biased training data and methods for fine-tuning AI systems that include sensitive information.\n- Establishing clear procedures for reporting harms and vulnerabilities in AI systems, and sharing evaluation results with relevant stakeholders under current privacy and data regulations.\n- Regulatory authorities (such as the FTC) using their legal powers to address privacy violations, including investigating and penalizing companies that misuse personal data for AI training without proper consent.\n\n(Source: G7 Hiroshima Process International Code of Conduct for Advanced AI Systems, Gov.uk, FTC statements, as referenced in the provided context.)",
         "The context suggests several measures to enhance data privacy in advanced AI systems, including the implementation of strict data governance policies, ensuring transparency in data usage, and establishing robust security protocols to protect sensitive information. Additionally, it emphasizes the importance of user consent and the ethical handling of data.",
         "0.9999999999",
         "0.5",
         "0.995700006114793",
         "0.5"
        ],
        [
         "4",
         "What were the main takeaways from the AI Safety Summit on global AI testing?",
         "['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\\nn 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of\\nthe Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한\\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\nn 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며,\\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\\nconcludes, 2023.11.02.']",
         "The main takeaways from the AI Safety Summit on global AI testing were:\n\n1. **Bletchley Declaration and International Cooperation**: Representatives from 28 countries attending the summit at Bletchley Park announced the \"Bletchley Declaration,\" emphasizing the importance of collaboration among countries, international organizations, companies, civil society, and academia to ensure AI safety.\n\n2. **Commitment to Safety Testing**: Countries and companies developing advanced AI systems agreed on plans for safety testing of these systems. The UK’s AI Safety Institute will lead and coordinate these tests in cooperation with other nations.\n\n3. **Government-led External Testing**: There was consensus on the need for government-led external safety testing of advanced AI models, including assessments of national security, public safety, and potential social harms.\n\n4. **Transparency and Information Sharing**: The summit highlighted the need for increased transparency from AI developers, the development of appropriate evaluation metrics and safety testing tools, and the establishment of clear procedures for reporting AI system harms and vulnerabilities.\n\n5. **Public Sector Investment**: Governments committed to investing in public sector capabilities for testing and safety research, and to sharing test results with other countries and research institutions.\n\n6. **Ongoing Collaboration**: Agreements were made for continued collaboration, including follow-up meetings (such as an online mini-summit with the UK and a face-to-face summit with France), and the creation of a \"State of the Science\" report to scientifically assess AI risks and set research priorities.\n\n7. **Inclusive Stakeholder Engagement**: The declaration stressed the responsibility of advanced AI developers to ensure safety and called for the involvement of all stakeholders—governments, industry, academia, and the public—in AI governance and risk management.\n\nIn summary, the summit established a framework for international cooperation, government-led safety testing, transparency, and ongoing collaboration to address the risks and ensure the safe development and deployment of advanced AI systems.",
         "The main takeaways from the AI Safety Summit on global AI testing include the establishment of a plan for safety testing of frontier AI technologies, as discussed by world leaders and top AI companies. The summit emphasized the importance of collaboration among nations to ensure AI safety and the need for ongoing dialogue and regulation in the field of AI.",
         "0.9999999999",
         "0.2972972972972973",
         "0.9999988569970958",
         "0.6666666666666666"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>[SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI...</td>\n",
       "      <td>According to the provided context, TechRepubli...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.919246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>[Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...</td>\n",
       "      <td>CES 2024 will be held from January 9 to Januar...</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>[문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하...</td>\n",
       "      <td>The G7's approach to ethical considerations an...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.978322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>[∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리...</td>\n",
       "      <td>The following measures are suggested to enhanc...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>[관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 ...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI...   \n",
       "1  [Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CT...   \n",
       "2  [문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하...   \n",
       "3  [∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리...   \n",
       "4  [관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  According to the provided context, TechRepubli...   \n",
       "1  CES 2024 will be held from January 9 to Januar...   \n",
       "2  The G7's approach to ethical considerations an...   \n",
       "3  The following measures are suggested to enhanc...   \n",
       "4  The main takeaways from the AI Safety Summit o...   \n",
       "\n",
       "                                           reference  context_precision  \\\n",
       "0  TechRepublic highlighted several recent develo...                0.5   \n",
       "1  CES 2024 will take place from January 9 to Jan...                1.0   \n",
       "2  The key aspects of AI global cooperation highl...                0.5   \n",
       "3  The context suggests several measures to enhan...                1.0   \n",
       "4  The main takeaways from the AI Safety Summit o...                1.0   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_recall  \n",
       "0      0.857143          0.919246        0.000000  \n",
       "1      1.000000          0.957120        1.000000  \n",
       "2      0.500000          0.978322        1.000000  \n",
       "3      0.500000          0.995700        0.500000  \n",
       "4      0.297297          0.999999        0.666667  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result.to_pandas()\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "context_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "faithfulness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "answer_relevancy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "context_recall",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "05b56471-f679-44f8-b18f-8f104eea5837",
       "rows": [
        [
         "0",
         "0.49999999995",
         "0.8571428571428571",
         "0.9192459703082926",
         "0.0"
        ],
        [
         "1",
         "0.9999999999",
         "1.0",
         "0.9571199605936328",
         "1.0"
        ],
        [
         "2",
         "0.49999999995",
         "0.5",
         "0.9783219635044952",
         "1.0"
        ],
        [
         "3",
         "0.9999999999",
         "0.5",
         "0.995700006114793",
         "0.5"
        ],
        [
         "4",
         "0.9999999999",
         "0.2972972972972973",
         "0.9999988569970958",
         "0.6666666666666666"
        ],
        [
         "5",
         "0.0",
         "0.26666666666666666",
         "0.9678278304877962",
         "1.0"
        ],
        [
         "6",
         "0.9999999999",
         "0.3333333333333333",
         "0.9275253610987763",
         "0.6666666666666666"
        ],
        [
         "7",
         "0.9999999999",
         "0.6666666666666666",
         "0.9907267725070369",
         "0.5"
        ],
        [
         "8",
         "0.0",
         "0.6470588235294118",
         "0.9490331416372401",
         "1.0"
        ],
        [
         "9",
         "0.0",
         "0.0",
         "0.9965319418976902",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.919246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.978322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.967828</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.927525</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.990727</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996532</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   context_precision  faithfulness  answer_relevancy  context_recall\n",
       "0                0.5      0.857143          0.919246        0.000000\n",
       "1                1.0      1.000000          0.957120        1.000000\n",
       "2                0.5      0.500000          0.978322        1.000000\n",
       "3                1.0      0.500000          0.995700        0.500000\n",
       "4                1.0      0.297297          0.999999        0.666667\n",
       "5                0.0      0.266667          0.967828        1.000000\n",
       "6                1.0      0.333333          0.927525        0.666667\n",
       "7                1.0      0.666667          0.990727        0.500000\n",
       "8                0.0      0.647059          0.949033        1.000000\n",
       "9                0.0      0.000000          0.996532        0.500000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.loc[:, \"context_precision\":\"context_recall\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "evolution_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metadata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_done",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "a2e5d452-ec71-4f8a-971b-d0a0af176c2f",
       "rows": [
        [
         "0",
         "What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?",
         "['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,', '저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10']",
         "TechRepublic highlighted several recent developments in generative AI in their November 2023 articles, including the introduction of 'Generative AI' as a key focus, advancements in AI models such as Llama 2, and the application of generative AI in various fields. They also discussed the importance of AI in enhancing user experience and the potential for generative AI to transform industries.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "1",
         "What are the dates and location for CES 2024?",
         "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']",
         "CES 2024 will take place from January 9 to January 12, 2024, in Las Vegas, Nevada.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "2",
         "What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?",
         "['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\\n지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\\nn (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교\\n내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과\\n모범사례를 마련\\nn (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을\\n통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\\n∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서\\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of\\nArtificial Intelligence (E.O. 14110), 2023.10.30.', 'SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nKEY Contents\\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\\n채택을 권고하는 AI 국제 행동강령을 마련\\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nn G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록\\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고,\\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화']",
         "The key aspects of AI global cooperation highlighted in the G7's approach include the establishment of an international code of conduct for advanced AI systems, the promotion of ethical guidelines, and the development of regulatory frameworks that ensure the safe and trustworthy use of AI. The G7 emphasizes the importance of collaboration among member countries to address the challenges posed by AI technologies and to create a unified approach to governance and oversight.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 3, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "3",
         "What measures are suggested to enhance data privacy in the context of advanced AI systems?",
         "['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화\\n∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시\\n신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는\\nAI 거버넌스와 위험 관리 정책을 마련\\n∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로\\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축\\n∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기\\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집\\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.\\n2']",
         "The context suggests several measures to enhance data privacy in advanced AI systems, including the implementation of strict data governance policies, ensuring transparency in data usage, and establishing robust security protocols to protect sensitive information. Additionally, it emphasizes the importance of user consent and the ethical handling of data.",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ],
        [
         "4",
         "What were the main takeaways from the AI Safety Summit on global AI testing?",
         "['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\\nn 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of\\nthe Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한\\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\nn 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며,\\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\\nconcludes, 2023.11.02.']",
         "The main takeaways from the AI Safety Summit on global AI testing include the establishment of a plan for safety testing of frontier AI technologies, as discussed by world leaders and top AI companies. The summit emphasized the importance of collaboration among nations to ensure AI safety and the need for ongoing dialogue and regulation in the field of AI.",
         "reasoning",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...   \n",
       "1  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...   \n",
       "2  ['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...   \n",
       "3  ['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...   \n",
       "4  ['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  TechRepublic highlighted several recent develo...         simple   \n",
       "1  CES 2024 will take place from January 9 to Jan...         simple   \n",
       "2  The key aspects of AI global cooperation highl...         simple   \n",
       "3  The context suggests several measures to enhan...         simple   \n",
       "4  The main takeaways from the AI Safety Summit o...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/ragas_synthetic_dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepl in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (1.22.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from deepl) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 만나서 반가워요\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.translate import Translator\n",
    "\n",
    "# api키 설정\n",
    "deepl_api_key = os.getenv(\"DEEPL_API_KEY\")\n",
    "\n",
    "# 객체 생성\n",
    "translator = Translator(deepl_api_key, \"EN\", \"KO\")\n",
    "\n",
    "# 번역 실행\n",
    "translated_text = translator(\"hello, nice to meet you\")\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "번역 진행 중: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 번역\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"번역 진행 중\"):\n",
    "    df.loc[i, \"question_translated\"] = translator(row[\"question\"])\n",
    "    df.loc[i, \"ground_truth_translated\"] = translator(row[\"ground_truth\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "da1c6a3c-703a-488a-9d53-26d69d4f9e97",
       "rows": [
        [
         "0",
         "What specific recent developments in generative AI have been highlighted by TechRepublic in their November 2023 articles?",
         "TechRepublic highlighted several recent developments in generative AI in their November 2023 articles, including the introduction of 'Generative AI' as a key focus, advancements in AI models such as Llama 2, and the application of generative AI in various fields. They also discussed the importance of AI in enhancing user experience and the potential for generative AI to transform industries."
        ],
        [
         "1",
         "What are the dates and location for CES 2024?",
         "CES 2024 will take place from January 9 to January 12, 2024, in Las Vegas, Nevada."
        ],
        [
         "2",
         "What are the key aspects of AI global cooperation highlighted in the G7's approach to ethical considerations and regulatory frameworks for advanced AI systems?",
         "The key aspects of AI global cooperation highlighted in the G7's approach include the establishment of an international code of conduct for advanced AI systems, the promotion of ethical guidelines, and the development of regulatory frameworks that ensure the safe and trustworthy use of AI. The G7 emphasizes the importance of collaboration among member countries to address the challenges posed by AI technologies and to create a unified approach to governance and oversight."
        ],
        [
         "3",
         "What measures are suggested to enhance data privacy in the context of advanced AI systems?",
         "The context suggests several measures to enhance data privacy in advanced AI systems, including the implementation of strict data governance policies, ensuring transparency in data usage, and establishing robust security protocols to protect sensitive information. Additionally, it emphasizes the importance of user consent and the ethical handling of data."
        ],
        [
         "4",
         "What were the main takeaways from the AI Safety Summit on global AI testing?",
         "The main takeaways from the AI Safety Summit on global AI testing include the establishment of a plan for safety testing of frontier AI technologies, as discussed by world leaders and top AI companies. The summit emphasized the importance of collaboration among nations to ensure AI safety and the need for ongoing dialogue and regulation in the field of AI."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What specific recent developments in generativ...</td>\n",
       "      <td>TechRepublic highlighted several recent develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the dates and location for CES 2024?</td>\n",
       "      <td>CES 2024 will take place from January 9 to Jan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the key aspects of AI global cooperat...</td>\n",
       "      <td>The key aspects of AI global cooperation highl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What measures are suggested to enhance data pr...</td>\n",
       "      <td>The context suggests several measures to enhan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What were the main takeaways from the AI Safet...</td>\n",
       "      <td>The main takeaways from the AI Safety Summit o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What specific recent developments in generativ...   \n",
       "1      What are the dates and location for CES 2024?   \n",
       "2  What are the key aspects of AI global cooperat...   \n",
       "3  What measures are suggested to enhance data pr...   \n",
       "4  What were the main takeaways from the AI Safet...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  TechRepublic highlighted several recent develo...  \n",
       "1  CES 2024 will take place from January 9 to Jan...  \n",
       "2  The key aspects of AI global cooperation highl...  \n",
       "3  The context suggests several measures to enhan...  \n",
       "4  The main takeaways from the AI Safety Summit o...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question, ground_truth 열을 확인합니다.\n",
    "df.loc[:, [\"question\", \"ground_truth\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question_translated",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth_translated",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d4e620e2-8656-40ae-9c0b-8488ebf9ea25",
       "rows": [
        [
         "0",
         "테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구체적으로 어떤 것이 있나요?",
         "테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 같은 AI 모델의 발전, 다양한 분야에서의 제너레이티브 AI 적용 등 최근 제너레이티브 AI의 여러 발전상을 집중적으로 조명했습니다. 또한 사용자 경험을 향상시키는 데 있어 AI의 중요성과 산업을 변화시킬 수 있는 제너레이티브 AI의 잠재력에 대해서도 논의했습니다."
        ],
        [
         "1",
         "CES 2024의 날짜와 장소는 언제인가요?",
         "CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서 개최됩니다."
        ],
        [
         "2",
         "첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방식에서 강조하는 AI 글로벌 협력의 핵심 측면은 무엇인가요?",
         "G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에 대한 국제 행동 강령 제정, 윤리적 가이드라인 홍보, 안전하고 신뢰할 수 있는 AI 사용을 보장하는 규제 프레임워크 개발이 포함됩니다. G7은 AI 기술로 인한 문제를 해결하고 거버넌스 및 감독에 대한 통일된 접근 방식을 만들기 위해 회원국 간의 협력이 중요하다는 점을 강조합니다."
        ],
        [
         "3",
         "고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?",
         "이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감한 정보를 보호하기 위한 강력한 보안 프로토콜 구축 등 첨단 AI 시스템에서 데이터 프라이버시를 강화하기 위한 몇 가지 조치를 제안합니다. 또한 사용자 동의와 데이터의 윤리적 취급의 중요성을 강조합니다."
        ],
        [
         "4",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 AI 기업들이 논의한 첨단 AI 기술의 안전 테스트 계획을 수립하는 것입니다. 이번 서밋에서는 AI 안전을 보장하기 위한 국가 간 협력의 중요성과 AI 분야에서 지속적인 대화와 규제의 필요성이 강조되었습니다."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_translated</th>\n",
       "      <th>ground_truth_translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...</td>\n",
       "      <td>테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CES 2024의 날짜와 장소는 언제인가요?</td>\n",
       "      <td>CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...</td>\n",
       "      <td>G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?</td>\n",
       "      <td>이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?</td>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question_translated  \\\n",
       "0  테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...   \n",
       "1                           CES 2024의 날짜와 장소는 언제인가요?   \n",
       "2  첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...   \n",
       "3   고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?   \n",
       "4             글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?   \n",
       "\n",
       "                             ground_truth_translated  \n",
       "0  테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...  \n",
       "1  CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...  \n",
       "2  G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...  \n",
       "3  이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...  \n",
       "4  글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question_translated, ground_truth_translated 열을 확인합니다.\n",
    "df.loc[:, [\"question_translated\", \"ground_truth_translated\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "evolution_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metadata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_done",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fc565d2e-7226-4e45-aaee-d53c0f9dc4aa",
       "rows": [
        [
         "0",
         "['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,', '저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구체적으로 어떤 것이 있나요?",
         "테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 같은 AI 모델의 발전, 다양한 분야에서의 제너레이티브 AI 적용 등 최근 제너레이티브 AI의 여러 발전상을 집중적으로 조명했습니다. 또한 사용자 경험을 향상시키는 데 있어 AI의 중요성과 산업을 변화시킬 수 있는 제너레이티브 AI의 잠재력에 대해서도 논의했습니다."
        ],
        [
         "1",
         "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "CES 2024의 날짜와 장소는 언제인가요?",
         "CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서 개최됩니다."
        ],
        [
         "2",
         "['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\\n지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\\nn (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교\\n내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과\\n모범사례를 마련\\nn (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을\\n통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\\n∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서\\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of\\nArtificial Intelligence (E.O. 14110), 2023.10.30.', 'SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nKEY Contents\\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\\n채택을 권고하는 AI 국제 행동강령을 마련\\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nn G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록\\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고,\\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 3, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방식에서 강조하는 AI 글로벌 협력의 핵심 측면은 무엇인가요?",
         "G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에 대한 국제 행동 강령 제정, 윤리적 가이드라인 홍보, 안전하고 신뢰할 수 있는 AI 사용을 보장하는 규제 프레임워크 개발이 포함됩니다. G7은 AI 기술로 인한 문제를 해결하고 거버넌스 및 감독에 대한 통일된 접근 방식을 만들기 위해 회원국 간의 협력이 중요하다는 점을 강조합니다."
        ],
        [
         "3",
         "['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화\\n∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시\\n신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는\\nAI 거버넌스와 위험 관리 정책을 마련\\n∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로\\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축\\n∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기\\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집\\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.\\n2']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?",
         "이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감한 정보를 보호하기 위한 강력한 보안 프로토콜 구축 등 첨단 AI 시스템에서 데이터 프라이버시를 강화하기 위한 몇 가지 조치를 제안합니다. 또한 사용자 동의와 데이터의 윤리적 취급의 중요성을 강조합니다."
        ],
        [
         "4",
         "['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\\nn 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of\\nthe Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한\\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\nn 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며,\\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\\nconcludes, 2023.11.02.']",
         "reasoning",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 AI 기업들이 논의한 첨단 AI 기술의 안전 테스트 계획을 수립하는 것입니다. 이번 서밋에서는 AI 안전을 보장하기 위한 국가 간 협력의 중요성과 AI 분야에서 지속적인 대화와 규제의 필요성이 강조되었습니다."
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexts</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...</td>\n",
       "      <td>테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>CES 2024의 날짜와 장소는 언제인가요?</td>\n",
       "      <td>CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...</td>\n",
       "      <td>G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?</td>\n",
       "      <td>이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?</td>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contexts evolution_type  \\\n",
       "0  ['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...         simple   \n",
       "1  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...         simple   \n",
       "2  ['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...         simple   \n",
       "3  ['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...         simple   \n",
       "4  ['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \\\n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "\n",
       "                                            question  \\\n",
       "0  테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...   \n",
       "1                           CES 2024의 날짜와 장소는 언제인가요?   \n",
       "2  첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...   \n",
       "3   고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?   \n",
       "4             글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...  \n",
       "1  CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...  \n",
       "2  G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...  \n",
       "3  이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...  \n",
       "4  글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question, ground_truth 열을 삭제하고 question_translated, ground_truth_translated 열의 이름을 변경합니다.\n",
    "df.drop(columns=[\"question\", \"ground_truth\"], inplace=True)\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"question_translated\": \"question\",\n",
    "        \"ground_truth_translated\": \"ground_truth\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역한 데이터셋을 저장합니다.\n",
    "df.to_csv(\"data/ragas_synthetic_dataset_translated.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['contexts', 'evolution_type', 'metadata', 'episode_done', 'question', 'ground_truth'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# pandas DataFrame을 Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 데이터셋 확인\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ba15a43a4f4266b19c9418c9b591c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adff9001b06342babe2092e0f2dea94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07391ad421774dfb8ca54c17b9bd8efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01254dfe11cc41a9ad209881e645ecdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086ccfc3c9a243c2be718cb7615fa8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########| 31.4kB / 31.4kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mypsyche98/rag-synthetic-dataset/commit/217a4ba65991f839e212af7b7400dcf0b299c0c2', commit_message='Upload dataset', commit_description='', oid='217a4ba65991f839e212af7b7400dcf0b299c0c2', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mypsyche98/rag-synthetic-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mypsyche98/rag-synthetic-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "# pandas DataFrame을 Hugging Face Dataset으로 변환\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 데이터셋 이름 설정 (원하는 이름으로 변경하세요)\n",
    "dataset_name = \"mypsyche98/rag-synthetic-dataset\"\n",
    "\n",
    "# 데이터셋 업로드\n",
    "dataset.push_to_hub(\n",
    "    dataset_name,\n",
    "    private=True,  # private=False로 설정하면 공개 데이터셋이 됩니다.\n",
    "    split=\"korean_v1\",  # 데이터셋 split 이름 입력\n",
    "    token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/mypsyche98/rag-synthetic-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04. LangSmith 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "001ab729-598c-4e25-a205-af5a2d7ea8c4",
       "rows": [
        [
         "0",
         "삼성전자가 만든 생성형 AI의 이름은 무엇인가요?",
         "삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다."
        ],
        [
         "1",
         "미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표한 날은 언제인가요?",
         "2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다."
        ],
        [
         "2",
         "코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.",
         "코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스 상태를 추적하고 투명성을 확보하기 위한 플랫폼입니다. 12개 기관과 협력하여 2,000여 개 데이터셋의 출처 정보를 제공하며, 개발자들이 데이터의 구성과 계보를 쉽게 파악할 수 있게 돕습니다."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                        삼성전자가 만든 생성형 AI의 이름은 무엇인가요?   \n",
       "1  미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...   \n",
       "2                    코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.   \n",
       "\n",
       "                                              answer  \n",
       "0                   삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.  \n",
       "1            2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.  \n",
       "2  코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 질문과 답변 목록\n",
    "inputs = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 무엇인가요?\",\n",
    "    \"미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표한 날은 언제인가요?\",\n",
    "    \"코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.\",\n",
    "]\n",
    "\n",
    "# 질문에 대한 답변 목록\n",
    "outputs = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.\",\n",
    "    \"2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.\",\n",
    "    \"코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스 상태를 추적하고 투명성을 확보하기 위한 플랫폼입니다. 12개 기관과 협력하여 2,000여 개 데이터셋의 출처 정보를 제공하며, 개발자들이 데이터의 구성과 계보를 쉽게 파악할 수 있게 돕습니다.\",\n",
    "]\n",
    "\n",
    "# 질문과 답변 쌍 생성\n",
    "qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# 데이터프레임 출력\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.6\n",
      "Uninstalling numpy-2.2.6:\n",
      "  Successfully uninstalled numpy-2.2.6\n",
      "Found existing installation: numba 0.61.2\n",
      "Uninstalling numba-0.61.2:\n",
      "  Successfully uninstalled numba-0.61.2\n",
      "Found existing installation: streamlit 1.43.2\n",
      "Uninstalling streamlit-1.43.2:\n",
      "  Successfully uninstalled streamlit-1.43.2\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from numba) (0.44.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: packaging<26,>=20 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (2.3.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (6.32.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (4.14.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Downloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, numba, streamlit\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [streamlit]━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numba-0.61.2 numpy-2.2.6 streamlit-1.48.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy numba streamlit\n",
    "!pip install numpy numba streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.32.0 which is incompatible.\n",
      "langchain-upstage 0.7.3 requires tokenizers<0.21.0,>=0.20.0, but you have tokenizers 0.21.4 which is incompatible.\n",
      "opentelemetry-proto 1.27.0 requires protobuf<5.0,>=3.19, but you have protobuf 6.32.0 which is incompatible.\n",
      "streamlit 1.43.2 requires protobuf<6,>=3.20, but you have protobuf 6.32.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uq numba transformers onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050f65543d08442ba16f3e326d5c1c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/korean_v1-00000-of-00001.parquet:   0%|          | 0.00/31.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccccec5559a4354a3202f31c722aac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating korean_v1 split:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "contexts",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "evolution_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metadata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "episode_done",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ground_truth",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5b7b732d-1af8-4cb0-a13f-0a51ba652621",
       "rows": [
        [
         "0",
         "['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,', '저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구체적으로 어떤 것이 있나요?",
         "테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 같은 AI 모델의 발전, 다양한 분야에서의 제너레이티브 AI 적용 등 최근 제너레이티브 AI의 여러 발전상을 집중적으로 조명했습니다. 또한 사용자 경험을 향상시키는 데 있어 AI의 중요성과 산업을 변화시킬 수 있는 제너레이티브 AI의 잠재력에 대해서도 논의했습니다."
        ],
        [
         "1",
         "['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등\\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며,\\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한\\nCES 2024\\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간 장소 홈페이지\\n2024.1.9~12 미국, 라스베가스 https://www.ces.tech/\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는\\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한\\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를\\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\nAIMLA 2024\\n야의 최첨단 개발 소식 공유\\n기간 장소 홈페이지\\nhttps://ccnet2024.org/aimla\\n2024.1.27~28 덴마크, 코펜하겐\\n/index\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야\\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사,\\nAAAI Conference\\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\non Artificial\\n로그램 등 진행\\nIntelligence\\n기간 장소 홈페이지\\nhttps://aaai.org/aaai-confere\\n2024.2.20~27 캐나다, 밴쿠버\\nnce/']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 21, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "CES 2024의 날짜와 장소는 언제인가요?",
         "CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서 개최됩니다."
        ],
        [
         "2",
         "['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한\\n지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\\nn (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교\\n내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과\\n모범사례를 마련\\nn (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을\\n통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\\n* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\\n∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서\\n공부하고 취업할 수 있도록 지원\\n☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of\\nArtificial Intelligence (E.O. 14110), 2023.10.30.', 'SPRi AI Brief |\\n2023-12월호\\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\\nKEY Contents\\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\\n채택을 권고하는 AI 국제 행동강령을 마련\\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\\n위험 식별과 완화에 필요한 조치를 포함\\n* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미\\n** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택\\nn G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록\\n이해관계자 협의를 통해 필요에 따라 개정할 예정\\n∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고,\\n첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화\\n∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 3, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방식에서 강조하는 AI 글로벌 협력의 핵심 측면은 무엇인가요?",
         "G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에 대한 국제 행동 강령 제정, 윤리적 가이드라인 홍보, 안전하고 신뢰할 수 있는 AI 사용을 보장하는 규제 프레임워크 개발이 포함됩니다. G7은 AI 기술로 인한 문제를 해결하고 거버넌스 및 감독에 대한 통일된 접근 방식을 만들기 위해 회원국 간의 협력이 중요하다는 점을 강조합니다."
        ],
        [
         "3",
         "['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을\\n보장하고 책임성을 강화\\n∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시\\n신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는\\nAI 거버넌스와 위험 관리 정책을 마련\\n∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현\\n∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로\\n신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축\\n∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기\\n대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발\\n∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집\\n시 적절한 보호 장치 구현\\n☞ 출처: G7, Hiroshima Process International Code of Conduct for Advanced AI Systems, 2023.10.30.\\n2']",
         "simple",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?",
         "이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감한 정보를 보호하기 위한 강력한 보안 프로토콜 구축 등 첨단 AI 시스템에서 데이터 프라이버시를 강화하기 위한 몇 가지 조치를 제안합니다. 또한 사용자 동의와 데이터의 윤리적 취급의 중요성을 강조합니다."
        ],
        [
         "4",
         "['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의\\nn 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of\\nthe Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한\\n기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획\\nn 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며,\\n프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정\\n☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.\\nGov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety Summit\\nconcludes, 2023.11.02.']",
         "reasoning",
         "[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4', 'filename': 'data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",
         "True",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?",
         "글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 AI 기업들이 논의한 첨단 AI 기술의 안전 테스트 계획을 수립하는 것입니다. 이번 서밋에서는 AI 안전을 보장하기 위한 국가 간 협력의 중요성과 AI 분야에서 지속적인 대화와 규제의 필요성이 강조되었습니다."
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexts</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...</td>\n",
       "      <td>테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>CES 2024의 날짜와 장소는 언제인가요?</td>\n",
       "      <td>CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...</td>\n",
       "      <td>G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?</td>\n",
       "      <td>이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...</td>\n",
       "      <td>True</td>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?</td>\n",
       "      <td>글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            contexts evolution_type  \\\n",
       "0  ['SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 A...         simple   \n",
       "1  ['Ⅱ\\n. 주요 행사 일정\\n행사명 행사 주요 개요\\n- 미국 소비자기술 협회(C...         simple   \n",
       "2  ['문제를 방지하는 조치를 확대\\n∙ 형사사법 시스템에서 AI 사용 모범사례를 개발...         simple   \n",
       "3  ['∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알...         simple   \n",
       "4  ['관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \\\n",
       "0  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "1  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "2  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "3  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "4  [{'source': 'data/SPRI_AI_Brief_2023년12월호_F.pd...          True   \n",
       "\n",
       "                                            question  \\\n",
       "0  테크리퍼블릭이 2023년 11월 기사에서 강조한 제너레이티브 AI의 최근 발전은 구...   \n",
       "1                           CES 2024의 날짜와 장소는 언제인가요?   \n",
       "2  첨단 AI 시스템에 대한 윤리적 고려 사항과 규제 프레임워크에 대한 G7의 접근 방...   \n",
       "3   고급 AI 시스템의 맥락에서 데이터 프라이버시를 강화하기 위해 어떤 조치가 제안되나요?   \n",
       "4             글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 무엇인가요?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  테크리퍼블릭은 2023년 11월 기사에서 '제너레이티브 AI'의 도입, 라마 2와 ...  \n",
       "1  CES 2024는 2024년 1월 9일부터 1월 12일까지 네바다주 라스베이거스에서...  \n",
       "2  G7의 접근 방식에서 강조하는 AI 글로벌 협력의 주요 측면에는 첨단 AI 시스템에...  \n",
       "3  이 맥락에서는 엄격한 데이터 거버넌스 정책 시행, 데이터 사용의 투명성 보장, 민감...  \n",
       "4  글로벌 AI 테스트에 관한 AI 안전 서밋의 주요 내용은 세계 지도자들과 최고의 A...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "\n",
    "# huggingface Dataset에서 repo_id로 데이터셋 다운로드\n",
    "dataset = load_dataset(\n",
    "    \"mypsyche98/rag-synthetic-dataset\",  # 데이터셋 이름\n",
    "    token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],  # private 데이터인 경우 필요합니다.\n",
    ")\n",
    "\n",
    "# 데이터셋에서 split 기준으로 조회\n",
    "huggingface_df = dataset[\"korean_v1\"].to_pandas()\n",
    "huggingface_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['2e043f96-3f75-4a52-b65b-dbad66f4e58f',\n",
       "  '2c20a8eb-ea28-4a83-8535-1f602cdcfc57',\n",
       "  '6c99b3e8-92f9-460f-9861-08699eaf317b'],\n",
       " 'count': 3}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def create_dataset(client, dataset_name, description=None):\n",
    "    for dataset in client.list_datasets():\n",
    "        if dataset.name == dataset_name:\n",
    "            return dataset\n",
    "\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=description,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = create_dataset(client, dataset_name)\n",
    "\n",
    "# 생성된 데이터셋에 예제 추가\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in df[\"question\"].tolist()],\n",
    "    outputs=[{\"answer\": a} for a in df[\"answer\"].tolist()],\n",
    "    dataset_id=dataset.id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['f7d94096-7bcb-439b-832e-96d2dbd27169',\n",
       "  '19993858-dd49-44a9-b7d3-529a442eb39a'],\n",
       " 'count': 2}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 질문 목록\n",
    "new_questions = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 무엇인가요?\",\n",
    "    \"구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?\",\n",
    "]\n",
    "\n",
    "# 새로운 답변 목록\n",
    "new_answers = [\n",
    "    \"삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.\",\n",
    "    \"사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억 달러를 우선 투자하고 향후 15억 달러를 추가로 투자하기로 했습니다.\",\n",
    "]\n",
    "\n",
    "# UI에서 업데이트된 버전 확인\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in new_questions],\n",
    "    outputs=[{\"answer\": a} for a in new_answers],\n",
    "    dataset_id=dataset.id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05. LLM-as-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 자체 개발한 생성형 AI의 이름은 ‘삼성 가우스’입니다.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myrag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# PDFRAG 객체 생성\n",
    "rag = PDFRAG(\n",
    "    \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    ChatOpenAI(model=\"gpt-4.1\", temperature=0),\n",
    ")\n",
    "\n",
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "chain.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '삼성전자가 자체 개발한 생성형 AI의 이름은 ‘삼성 가우스’입니다.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 질문 예시\n",
    "llm_answer = ask_question(\n",
    "    {\"question\": \"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\"}\n",
    ")\n",
    "llm_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator prompt 출력을 위한 함수\n",
    "def print_evaluator_prompt(evaluator):\n",
    "    return evaluator.evaluator.prompt.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "STUDENT ANSWER: student's answer here\n",
      "TRUE ANSWER: true answer here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin!\n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "TRUE ANSWER: \u001b[33;1m\u001b[1;3m{answer}\u001b[0m\n",
      "GRADE:\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# qa 평가자 생성\n",
    "qa_evalulator = LangChainStringEvaluator(\"qa\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "print_evaluator_prompt(qa_evalulator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG_EVAL-ee6f095d' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=bd422628-829b-45bf-9010-15ca9e0eb484\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03b9b880baa47acb01571869a419399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[qa_evalulator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"QA Evaluator 를 활용한 평가\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context 를 반환하는 RAG 결과 반환 함수\n",
    "def context_answer_rag_answer(inputs: dict):\n",
    "    context = retriever.invoke(inputs[\"question\"])\n",
    "    return {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in context]),\n",
    "        \"answer\": chain.invoke(inputs[\"question\"]),\n",
    "        \"query\": inputs[\"question\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\\n   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12\\nSPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.',\n",
       " 'answer': '삼성전자가 자체 개발한 생성형 AI의 이름은 ‘삼성 가우스’입니다.',\n",
       " 'query': '삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수 실행\n",
    "context_answer_rag_answer(\n",
    "    {\"question\": \"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a teacher grading a quiz.\n",
      "You are given a question, the context the question is about, and the student's answer. You are asked to score the student's answer as either CORRECT or INCORRECT, based on the context.\n",
      "\n",
      "Example Format:\n",
      "QUESTION: question here\n",
      "CONTEXT: context the question is about here\n",
      "STUDENT ANSWER: student's answer here\n",
      "GRADE: CORRECT or INCORRECT here\n",
      "\n",
      "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin!\n",
      "\n",
      "QUESTION: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n",
      "CONTEXT: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "STUDENT ANSWER: \u001b[33;1m\u001b[1;3m{result}\u001b[0m\n",
      "GRADE:\n"
     ]
    }
   ],
   "source": [
    "# cot_qa 평가자 생성\n",
    "cot_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"cot_qa\",\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],  # LLM 이 생성한 답변\n",
    "        \"reference\": run.outputs[\"context\"],  # Context\n",
    "        \"input\": example.inputs[\"question\"],  # 데이터셋의 질문\n",
    "    },\n",
    ")\n",
    "\n",
    "# context_qa 평가자 생성\n",
    "context_qa_evaluator = LangChainStringEvaluator(\n",
    "    \"context_qa\",\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],  # LLM 이 생성한 답변\n",
    "        \"reference\": run.outputs[\"context\"],  # Context\n",
    "        \"input\": example.inputs[\"question\"],  # 데이터셋의 질문\n",
    "    },\n",
    ")\n",
    "\n",
    "# evaluator prompt 출력\n",
    "print_evaluator_prompt(context_qa_evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'RAG_EVAL-b8523f30' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=0fa3c0f2-6b7e-4cd5-92b2-5f86f5e51dbc\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dced7a9ed647c9aa0bf3e0aea5390a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.context</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.COT Contextual Accuracy</th>\n",
       "      <th>feedback.Contextual Accuracy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>£ 구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\nn 구...</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.632281</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>c410dffd-9889-4e74-87e6-0fecd18962b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.755885</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>342a8f77-35af-46c3-8f21-813a217ef286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.235339</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>089568f5-eec5-4361-811b-e3cae347cc43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>SPRi AI Brief |  \\n2023-12월호\\n8\\n코히어, 데이터 투명성 ...</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.535723</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>fe1ee6e5-7cef-46b1-8b79-f746d5210df4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n미...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.440293</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>fc796fac-aa1e-4cce-805f-12c3f8acdfd4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults RAG_EVAL-b8523f30>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[cot_qa_evaluator, context_qa_evaluator],\n",
    "    experiment_prefix=\"RAG_EVAL\",\n",
    "    metadata={\n",
    "        \"variant\": \"COT_QA & Context_QA Evaluator 를 활용한 평가\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'CRITERIA-EVAL-52c86776' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=c39e84f4-0d9f-48d9-90c8-e7e5746206c4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2486eb23b9fa4685a51729503fadee89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate, LangChainStringEvaluator\n",
    "\n",
    "# 평가자 설정\n",
    "criteria_evaluator = [\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"conciseness\"}),\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"misogyny\"}),\n",
    "    LangChainStringEvaluator(\"criteria\", config={\"criteria\": \"criminality\"}),\n",
    "]\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=criteria_evaluator,\n",
    "    experiment_prefix=\"CRITERIA-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"criteria 를 활용한 평가\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.conciseness</th>\n",
       "      <th>feedback.misogyny</th>\n",
       "      <th>feedback.criminality</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.006998</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>b88bb835-ee29-4630-b09f-d4b10831d722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.439164</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>bf451d9b-42b3-4a1f-a500-bb0ba7114551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.117275</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>1a27b78c-907a-4364-bc80-ec49f569d55d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.105696</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>e6117c07-8a0e-4830-8490-5530fb009f57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.093883</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>6c7c1ccf-5a15-4b46-a309-8fa15cfedb2b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults CRITERIA-EVAL-52c86776>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are assessing a submitted answer on a given task or input based on a set of criteria. Here is the data:\n",
      "[BEGIN DATA]\n",
      "***\n",
      "[Input]: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "***\n",
      "[Submission]: \u001b[33;1m\u001b[1;3m{output}\u001b[0m\n",
      "***\n",
      "[Criteria]: helpfulness: Is this submission helpful to the user, taking into account the correct reference answer?\n",
      "***\n",
      "[Reference]: \u001b[33;1m\u001b[1;3m{reference}\u001b[0m\n",
      "***\n",
      "[END DATA]\n",
      "Does the submission meet the Criteria? First, write out in a step by step manner your reasoning about each criterion to be sure that your conclusion is correct. Avoid simply stating the correct answers at the outset. Then print only the single character \"Y\" or \"N\" (without quotes or punctuation) on its own line corresponding to the correct answer of whether the submission meets all criteria. At the end, repeat just the letter again by itself on a new line.\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# labeled_criteria 평가자 생성\n",
    "labeled_criteria_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\": ChatOpenAI(temperature=0.0, model=\"gpt-4.1\"),\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": example.outputs[\"answer\"],  # 정답 답변\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# evaluator prompt 출력\n",
    "print_evaluator_prompt(labeled_criteria_evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'LABELED-EVAL-d67fa40e' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=df6b4700-e332-4892-a30c-68d71fa480d7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af9a13a85154920922dbfc03ffbaf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.context</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.query</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.relevance</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>£ 구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\nn 구...</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.380211</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>5dc385b1-b8ea-48d4-9762-a1e15b6dbff2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 '삼성 가우스'입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.734427</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>2550e50a-6a5c-4536-bcaa-4a11730e6c93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.268328</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>2690653d-54d2-4c23-8d55-fdee74cddc5c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>SPRi AI Brief |  \\n2023-12월호\\n8\\n코히어, 데이터 투명성 ...</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.529326</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>d06f8807-a763-4f70-a9b5-2130db87e382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n미...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.246260</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>68964b75-8b26-4754-b363-cb53e218031a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults LABELED-EVAL-d67fa40e>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[labeled_criteria_evaluator, relevance_evaluator],\n",
    "    experiment_prefix=\"LABELED-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"labeled_criteria evaluator 활용한 평가\",\n",
    "    },\n",
    ")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "[Instruction]\n",
      "Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. \u001b[33;1m\u001b[1;3m{criteria}\u001b[0m[Ground truth]\n",
      "\u001b[33;1m\u001b[1;3m{reference}\u001b[0m\n",
      "Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \"[[rating]]\", for example: \"Rating: [[5]]\".\n",
      "\n",
      "[Question]\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
      "\n",
      "[The Start of Assistant's Answer]\n",
      "\u001b[33;1m\u001b[1;3m{prediction}\u001b[0m\n",
      "[The End of Assistant's Answer]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "\n",
    "# 점수를 반환하는 평가자 생성\n",
    "labeled_score_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_score_string\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"accuracy\": \"How accurate is this prediction compared to the reference on a scale of 1-10?\"\n",
    "        },\n",
    "        \"normalize_by\": 10,\n",
    "        \"llm\": ChatOpenAI(temperature=0.0, model=\"gpt-4.1\"),\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"answer\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "print_evaluator_prompt(labeled_score_evaluator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'LABELED-SCORE-EVAL-b1351671' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=705bcb31-f669-4d9f-813a-bfdd1efff514\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb3d3f551f54a229d9d583bfcfa8b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.score_string:accuracy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.991753</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>02c48d46-6b47-414a-8da7-7851f83f2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.075399</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>2a0b9f9a-e098-455c-9f4e-ca18fa96f800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898308</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>9addcd6d-fcf1-499d-89aa-6ebb7565f553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.239015</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>5ab915e2-f0ed-4bf7-b595-91dd7f43dfdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.121556</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>c0c73c10-41b0-47a4-ba3b-20f1242847b1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults LABELED-SCORE-EVAL-b1351671>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[labeled_score_evaluator],\n",
    "    experiment_prefix=\"LABELED-SCORE-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"labeled_score 활용한 평가\",\n",
    "    },\n",
    ")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06. 임베딩 기반 평가(embedding_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"삼성전자가 자체 개발한 생성형 AI의 이름은 '삼성 가우스'입니다.\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myrag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# PDFRAG 객체 생성\n",
    "rag = PDFRAG(\n",
    "    \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    ")\n",
    "\n",
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "chain.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"mps\"},  # cuda, cpu\n",
    "    # encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# 임베딩 모델 평가자 생성\n",
    "hf_embedding_evaluator = LangChainStringEvaluator(\n",
    "    \"embedding_distance\",\n",
    "    config={\n",
    "        # OpenAIEmbeddings 가 기본 값으로 설정되어 있으나, 변경이 가능\n",
    "        \"embeddings\": hf_embeddings,\n",
    "        \"distance_metric\": \"cosine\",  # \"cosine\", \"euclidean\", \"chebyshev\", \"hamming\", and \"manhattan\"\n",
    "    },\n",
    ")\n",
    "\n",
    "upstage_embedding_evaluator = LangChainStringEvaluator(\n",
    "    \"embedding_distance\",\n",
    "    config={\n",
    "        # OpenAIEmbeddings 가 기본 값으로 설정되어 있으나, 변경이 가능\n",
    "        \"embeddings\": UpstageEmbeddings(model=\"solar-embedding-1-large-query\"),\n",
    "        \"distance_metric\": \"euclidean\",  # \"cosine\", \"euclidean\", \"chebyshev\", \"hamming\", and \"manhattan\"\n",
    "    },\n",
    ")\n",
    "\n",
    "openai_embedding_evaluator = LangChainStringEvaluator(\n",
    "    \"embedding_distance\",\n",
    "    config={\n",
    "        # OpenAIEmbeddings 가 기본 값으로 설정되어 있으나, 변경이 가능\n",
    "        \"embeddings\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "        \"distance_metric\": \"euclidean\",  # \"cosine\", \"euclidean\", \"chebyshev\", \"hamming\", and \"manhattan\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'EMBEDDING-EVAL-27215bb2' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=ddefd859-af9f-444e-8bd3-827ec5f12f0a\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d04c6f0c0aa41a3aff8e6bd99e7aee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 평가 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        hf_embedding_evaluator,\n",
    "        upstage_embedding_evaluator,\n",
    "        openai_embedding_evaluator,\n",
    "    ],\n",
    "    experiment_prefix=\"EMBEDDING-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"embedding_distance 활용한 평가\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.embedding_cosine_distance</th>\n",
       "      <th>feedback.embedding_euclidean_distance</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>구글이 앤스로픽에 최대 20억 달러를 투자하기로 합의한 것이 사실입니다. 테디노트에...</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>0.146131</td>\n",
       "      <td>0.757220</td>\n",
       "      <td>1.734153</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>bb624ec2-a11a-476e-b8f6-3165d6c96d7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 '삼성 가우스'입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>0.230936</td>\n",
       "      <td>0.764774</td>\n",
       "      <td>3.799084</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>01087f10-75b9-4818-8cc1-d657b065853f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 '삼성 가우스'입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>0.255849</td>\n",
       "      <td>1.572802</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>d8830140-4ef5-4b9d-ab76-3b56e677828f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>코히어는 2023년 10월 25일에 '데이터 출처 탐색기(Data Provenanc...</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>0.785272</td>\n",
       "      <td>3.858580</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>65edf738-d468-42dd-aa1e-6cf1cf396f33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>2023년 10월 30일입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>0.283018</td>\n",
       "      <td>1.053067</td>\n",
       "      <td>1.446268</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>8ba5723e-13be-40bb-a636-a2edb8ba6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults EMBEDDING-EVAL-27215bb2>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07. 사용자 정의(Custom) LLM 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 자체 개발한 생성형 AI의 이름은 ‘삼성 가우스’입니다.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myrag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# PDFRAG 객체 생성\n",
    "rag = PDFRAG(\n",
    "    \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    ChatOpenAI(model=\"gpt-4.1\", temperature=0),\n",
    ")\n",
    "\n",
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "chain.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "import random\n",
    "\n",
    "\n",
    "def random_score_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 랜덤 점수 반환\n",
    "    score = random.randint(1, 11)\n",
    "    return {\"key\": \"random_score\", \"score\": score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'CUSTOM-EVAL-fe6a52b0' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=5eac3d17-d24f-458c-ac8a-4d98523e22f2\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6215aefdd144a578f8672455bf26cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.random_score</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.631312</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>3a0ce64e-cb80-419b-83e0-6e867168d0e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>5</td>\n",
       "      <td>1.088572</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>29c4cd5b-ec4f-447a-899b-b61162588d4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>6</td>\n",
       "      <td>1.008772</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>da1cc65b-be93-4f73-a931-bcc355560720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>9</td>\n",
       "      <td>3.309596</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>a74a1991-65db-44cd-bdc8-bd313145a4f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>2</td>\n",
       "      <td>1.025025</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>c04c3a57-dbe9-47cb-8691-42f5f3331dd6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults CUSTOM-EVAL-fe6a52b0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=[random_score_evaluator],\n",
    "    experiment_prefix=\"CUSTOM-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"랜덤 점수 평가자\",\n",
    "    },\n",
    ")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context 를 반환하는 RAG 결과 반환 함수\n",
    "def context_answer_rag_answer(inputs: dict):\n",
    "    context = retriever.invoke(inputs[\"question\"])\n",
    "    return {\n",
    "        \"context\": \"\\n\".join([doc.page_content for doc in context]),\n",
    "        \"answer\": chain.invoke(inputs[\"question\"]),\n",
    "        \"question\": inputs[\"question\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As an LLM evaluator (judge), please assess the LLM's response to the given question. Evaluate the response's accuracy, comprehensiveness, and context precision based on the provided context. After your evaluation, return only the numerical scores in the following format:\n",
      "Accuracy: [score]\n",
      "Comprehensiveness: [score]\n",
      "Context Precision: [score]\n",
      "Final: [normalized score]\n",
      "Grading rubric:\n",
      "\n",
      "Accuracy (0-10 points):\n",
      "Evaluate how well the answer aligns with the information provided in the given context.\n",
      "\n",
      "0 points: The answer is completely inaccurate or contradicts the provided context\n",
      "4 points: The answer partially aligns with the context but contains significant inaccuracies\n",
      "7 points: The answer mostly aligns with the context but has minor inaccuracies or omissions\n",
      "10 points: The answer fully aligns with the provided context and is completely accurate\n",
      "\n",
      "\n",
      "Comprehensiveness (0-10 points):\n",
      "\n",
      "0 points: The answer is completely inadequate or irrelevant\n",
      "3 points: The answer is accurate but too brief to fully address the question\n",
      "7 points: The answer covers main aspects but lacks detail or misses minor points\n",
      "10 points: The answer comprehensively covers all aspects of the question\n",
      "\n",
      "\n",
      "Context Precision (0-10 points):\n",
      "Evaluate how precisely the answer uses the information from the provided context.\n",
      "\n",
      "0 points: The answer doesn't use any information from the context or uses it entirely incorrectly\n",
      "4 points: The answer uses some information from the context but with significant misinterpretations\n",
      "7 points: The answer uses most of the relevant context information correctly but with minor misinterpretations\n",
      "10 points: The answer precisely and correctly uses all relevant information from the context\n",
      "\n",
      "\n",
      "Final Normalized Score:\n",
      "Calculate by summing the scores for accuracy, comprehensiveness, and context precision, then dividing by 30 to get a score between 0 and 1.\n",
      "Formula: (Accuracy + Comprehensiveness + Context Precision) / 30\n",
      "\n",
      "#Given question:\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "#LLM's response:\n",
      "\u001b[33;1m\u001b[1;3m{answer}\u001b[0m\n",
      "\n",
      "#Provided context:\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "Please evaluate the LLM's response according to the criteria above. \n",
      "\n",
      "In your output, include only the numerical scores for FINAL NORMALIZED SCORE without any additional explanation or reasoning.\n",
      "ex) 0.81\n",
      "\n",
      "#Final Normalized Score(Just the number):\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 평가자 Prompt 가져오기\n",
    "llm_evaluator_prompt = hub.pull(\"teddynote/context-answer-evaluator\")\n",
    "llm_evaluator_prompt.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 평가자 생성\n",
    "custom_llm_evaluator = (\n",
    "    llm_evaluator_prompt\n",
    "    | ChatOpenAI(temperature=0.0, model=\"gpt-4.1\")\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 답변을 생성합니다.\n",
    "output = context_answer_rag_answer(\n",
    "    {\"question\": \"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\"}\n",
    ")\n",
    "\n",
    "# 점수 평가 실행\n",
    "custom_llm_evaluator.invoke(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "\n",
    "\n",
    "def custom_evaluator(run: Run, example: Example) -> dict:\n",
    "    # LLM 생성 답변, 정답 답변 가져오기\n",
    "    llm_answer = run.outputs.get(\"answer\", \"\")\n",
    "    context = run.outputs.get(\"context\", \"\")\n",
    "    question = example.outputs.get(\"question\", \"\")\n",
    "\n",
    "    # 랜덤 점수 반환\n",
    "    score = custom_llm_evaluator.invoke(\n",
    "        {\"question\": question, \"answer\": llm_answer, \"context\": context}\n",
    "    )\n",
    "    return {\"key\": \"custom_score\", \"score\": float(score)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'CUSTOM-LLM-EVAL-e8d5beb1' at:\n",
      "https://smith.langchain.com/o/53db61eb-d386-4c02-9de8-5b28476b0edc/datasets/70f9dcf3-893a-4e50-80a9-35318578ee8c/compare?selectedSessions=d8b61bca-bcbd-4d64-8d72-e4b460e5a7c6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda491c0613743d89e7d23b63c40c9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator custom_evaluator> on run aa0769e5-caca-4eb6-972a-5164f179dd5a: ValueError(\"could not convert string to float: 'Accuracy: 10\\\\nComprehensiveness: 10\\\\nContext Precision: 10\\\\nFinal: 1.0'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/var/folders/sj/3r49bs6178v7nfhcxh7lpzd80000gn/T/ipykernel_57383/3052928486.py\", line 14, in custom_evaluator\n",
      "    return {\"key\": \"custom_score\", \"score\": float(score)}\n",
      "                                            ^^^^^^^^^^^^\n",
      "ValueError: could not convert string to float: 'Accuracy: 10\\nComprehensiveness: 10\\nContext Precision: 10\\nFinal: 1.0'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.context</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.question</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.custom_score</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>£ 구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\nn 구...</td>\n",
       "      <td>아니요, 구글이 20억 달러를 투자한 기업은 테디노트가 아니라 앤스로픽(Anthro...</td>\n",
       "      <td>구글이 테디노트에게 20억달러를 투자한 것이 사실입니까?</td>\n",
       "      <td>None</td>\n",
       "      <td>사실이 아닙니다. 구글은 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.822974</td>\n",
       "      <td>19993858-dd49-44a9-b7d3-529a442eb39a</td>\n",
       "      <td>aa0769e5-caca-4eb6-972a-5164f179dd5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 테디노트 입니다.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.816383</td>\n",
       "      <td>f7d94096-7bcb-439b-832e-96d2dbd27169</td>\n",
       "      <td>8ae902c4-66f4-421d-b7a9-9c40b2dd4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··············...</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’입니다.</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 무엇인가요?</td>\n",
       "      <td>None</td>\n",
       "      <td>삼성전자가 만든 생성형 AI의 이름은 삼성 가우스 입니다.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.807365</td>\n",
       "      <td>2c20a8eb-ea28-4a83-8535-1f602cdcfc57</td>\n",
       "      <td>f1b1780e-42b9-4cf2-80b7-c6ba675ffce2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>SPRi AI Brief |  \\n2023-12월호\\n8\\n코히어, 데이터 투명성 ...</td>\n",
       "      <td>코히어(Cohere)의 데이터 출처 탐색기(Data Provenance Explor...</td>\n",
       "      <td>코히어의 데이터 출처 탐색기에 대해서 간략히 말해주세요.</td>\n",
       "      <td>None</td>\n",
       "      <td>코히어의 데이터 출처 탐색기는 AI 모델 훈련에 사용되는 데이터셋의 출처와 라이선스...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.563904</td>\n",
       "      <td>2e043f96-3f75-4a52-b65b-dbad66f4e58f</td>\n",
       "      <td>76cb6924-41eb-446d-94cb-159124620778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n미...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>미국 바이든 대통령이 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023년 10월 30일 미국 바이든 대통령이 행정명령을 발표했습니다.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.627517</td>\n",
       "      <td>6c99b3e8-92f9-460f-9861-08699eaf317b</td>\n",
       "      <td>761bbc7d-9ee7-4183-8587-1ca9330afab7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults CUSTOM-LLM-EVAL-e8d5beb1>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 실행\n",
    "experiment_results = evaluate(\n",
    "    context_answer_rag_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[custom_evaluator],\n",
    "    experiment_prefix=\"CUSTOM-LLM-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Custom LLM Evaluator 활용한 평가\",\n",
    "    },\n",
    ")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 자체 개발한 생성형 AI의 이름은 ‘삼성 가우스’입니다.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from myrag import PDFRAG\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# PDFRAG 객체 생성\n",
    "rag = PDFRAG(\n",
    "    \"data/SPRI_AI_Brief_2023년12월호_F.pdf\",\n",
    "    ChatOpenAI(model=\"gpt-4.1\", temperature=0),\n",
    ")\n",
    "\n",
    "# 검색기(retriever) 생성\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# 체인(chain) 생성\n",
    "chain = rag.create_chain(retriever)\n",
    "\n",
    "# 질문에 대한 답변 생성\n",
    "chain.invoke(\"삼성전자가 자체 개발한 생성형 AI의 이름은 무엇인가요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변하는 함수를 생성\n",
    "def ask_question(inputs: dict):\n",
    "    return {\"answer\": chain.invoke(inputs[\"question\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕하세요.', '반갑습니다.', '내', '이름은', '테디입니다.']\n",
      "['안녕하세용', '반갑습니다~^^', '내', '이름은', '테디입니다!!']\n",
      "============================================================\n",
      "['안녕', '하', '세요', '.', '반갑', '습니다', '.', '나', '의', '이름', '은', '테디', '이', 'ᆸ니다', '.']\n",
      "['안녕', '하', '세요', 'ᆼ', '반갑', '습니다', '~', '^^', '나', '의', '이름', '은', '테디', '이', 'ᆸ니다', '!!']\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.kiwi_tokenizer import KiwiTokenizer\n",
    "\n",
    "# 토크나이저 선언\n",
    "kiwi_tokenizer = KiwiTokenizer()\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 테디입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\"\n",
    "\n",
    "# 토큰화\n",
    "print(sent1.split())\n",
    "print(sent2.split())\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1))\n",
    "print(kiwi_tokenizer.tokenize(sent2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\n",
      "[rouge1] 0.77419\n",
      "[rouge2] 0.62069\n",
      "[rougeL] 0.77419\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 내 이름은 테디입니다. 안녕하세요. 반갑습니다.\n",
      "[rouge1] 1.00000\n",
      "[rouge2] 0.92857\n",
      "[rougeL] 0.53333\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 테디입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\"\n",
    "sent3 = \"내 이름은 테디입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=False, tokenizer=KiwiTokenizer()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent2}\\n[rouge1] {scorer.score(sent1, sent2)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent2)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent2)['rougeL'].fmeasure:.5f}\"\n",
    ")\n",
    "print(\"===\" * 20)\n",
    "print(\n",
    "    f\"[1] {sent1}\\n[2] {sent3}\\n[rouge1] {scorer.score(sent1, sent3)['rouge1'].fmeasure:.5f}\\n[rouge2] {scorer.score(sent1, sent3)['rouge2'].fmeasure:.5f}\\n[rougeL] {scorer.score(sent1, sent3)['rougeL'].fmeasure:.5f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕 하 세요 . 반갑 습니다 . 나 의 이름 은 테디 이 ᆸ니다 .\n",
      "안녕 하 세요 ᆼ 반갑 습니다 ~ ^^ 나 의 이름 은 테디 이 ᆸ니다 !!\n",
      "나 의 이름 은 테디 이 ᆸ니다 . 안녕 하 세요 . 반갑 습니다 .\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 테디입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\"\n",
    "sent3 = \"내 이름은 테디입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# 토큰화\n",
    "print(kiwi_tokenizer.tokenize(sent1, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent2, type=\"sentence\"))\n",
    "print(kiwi_tokenizer.tokenize(sent3, type=\"sentence\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\n",
      "[score] 0.74879\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 내 이름은 테디입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.95739\n"
     ]
    }
   ],
   "source": [
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {bleu_score:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "bleu_score = sentence_bleu(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"sentence\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"sentence\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {bleu_score:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mypsyche/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wn.ensure_loaded()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\n",
      "[score] 0.78849\n",
      "============================================================\n",
      "[1] 안녕하세요. 반갑습니다. 내 이름은 테디입니다.\n",
      "[2] 내 이름은 테디입니다. 안녕하세요. 반갑습니다.\n",
      "[score] 0.96800\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import meteor_score\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 테디입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\"\n",
    "sent3 = \"내 이름은 테디입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent2, type=\"list\"),\n",
    ")\n",
    "\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {meteor:.5f}\")\n",
    "print(\"===\" * 20)\n",
    "\n",
    "meteor = meteor_score.meteor_score(\n",
    "    [kiwi_tokenizer.tokenize(sent1, type=\"list\")],\n",
    "    kiwi_tokenizer.tokenize(sent3, type=\"list\"),\n",
    ")\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {meteor:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0506d2cc1714e5c9bd10c228e36f3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "sent1 = \"안녕하세요. 반갑습니다. 내 이름은 테디입니다.\"\n",
    "sent2 = \"안녕하세용 반갑습니다~^^ 내 이름은 테디입니다!!\"\n",
    "sent3 = \"내 이름은 테디입니다. 안녕하세요. 반갑습니다.\"\n",
    "\n",
    "# SentenceTransformer 모델 로드\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# 문장들을 인코딩\n",
    "sent1_encoded = model.encode(sent1, convert_to_tensor=True)\n",
    "sent2_encoded = model.encode(sent2, convert_to_tensor=True)\n",
    "sent3_encoded = model.encode(sent3, convert_to_tensor=True)\n",
    "\n",
    "# sent1과 sent2 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent2_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent2}\\n[score] {cosine_similarity:.5f}\")\n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "# sent1과 sent3 사이의 코사인 유사도 계산\n",
    "cosine_similarity = util.pytorch_cos_sim(sent1_encoded, sent3_encoded).item()\n",
    "print(f\"[1] {sent1}\\n[2] {sent3}\\n[score] {cosine_similarity:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Run, Example\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import meteor_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "\n",
    "# 토크나이저 병렬화 설정(HuggingFace 모델 사용)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "def rouge_evaluator(metric: str = \"rouge1\") -> dict:\n",
    "    # wrapper function 정의\n",
    "    def _rouge_evaluator(run: Run, example: Example) -> dict:\n",
    "        # 출력값과 정답 가져오기\n",
    "        student_answer = run.outputs.get(\"answer\", \"\")\n",
    "        reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "        # ROUGE 점수 계산\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True, tokenizer=KiwiTokenizer()\n",
    "        )\n",
    "        scores = scorer.score(reference_answer, student_answer)\n",
    "\n",
    "        # ROUGE 점수 반환\n",
    "        rouge = scores[metric].fmeasure\n",
    "\n",
    "        return {\"key\": \"ROUGE\", \"score\": rouge}\n",
    "\n",
    "    return _rouge_evaluator\n",
    "\n",
    "\n",
    "def bleu_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"sentence\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"sentence\")\n",
    "\n",
    "    # BLEU 점수 계산\n",
    "    bleu_score = sentence_bleu([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"BLEU\", \"score\": bleu_score}\n",
    "\n",
    "\n",
    "def meteor_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # 토큰화\n",
    "    reference_tokens = kiwi_tokenizer.tokenize(reference_answer, type=\"list\")\n",
    "    student_tokens = kiwi_tokenizer.tokenize(student_answer, type=\"list\")\n",
    "\n",
    "    # METEOR 점수 계산\n",
    "    meteor = meteor_score.meteor_score([reference_tokens], student_tokens)\n",
    "\n",
    "    return {\"key\": \"METEOR\", \"score\": meteor}\n",
    "\n",
    "\n",
    "def semscore_evaluator(run: Run, example: Example) -> dict:\n",
    "    # 출력값과 정답 가져오기\n",
    "    student_answer = run.outputs.get(\"answer\", \"\")\n",
    "    reference_answer = example.outputs.get(\"answer\", \"\")\n",
    "\n",
    "    # SentenceTransformer 모델 로드\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "    # 문장 임베딩 생성\n",
    "    student_embedding = model.encode(student_answer, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_answer, convert_to_tensor=True)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    cosine_similarity = util.pytorch_cos_sim(\n",
    "        student_embedding, reference_embedding\n",
    "    ).item()\n",
    "\n",
    "    return {\"key\": \"sem_score\", \"score\": cosine_similarity}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "LangSmithAuthError",
     "evalue": "Authentication failed for /datasets. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets?limit=1&name=RAG_EVAL_DATASET', '{\"detail\":\"Invalid token\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets?limit=1&name=RAG_EVAL_DATASET",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:875\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    869\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    870\u001b[39m         method,\n\u001b[32m    871\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    872\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    873\u001b[39m         **request_kwargs,\n\u001b[32m    874\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets?limit=1&name=RAG_EVAL_DATASET] {\"detail\":\"Invalid token\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithAuthError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33mRAG_EVAL_DATASET\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 실험 실행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m experiment_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mask_question\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheuristic_evalulators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHeuristic-EVAL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 실험 메타데이터 지정\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHeuristic-EVAL (Rouge, BLEU, METEOR, SemScore) 을 사용하여 평가\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m experiment_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1081\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1065\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1066\u001b[39m experiment_, runs = _resolve_experiment(experiment, runs, client)\n\u001b[32m   1068\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir := ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1083\u001b[39m     cache_path = pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1455\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1457\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:5180\u001b[39m, in \u001b[36mClient.list_examples\u001b[39m\u001b[34m(self, dataset_id, dataset_name, example_ids, as_of, splits, inline_s3_urls, offset, limit, metadata, filter, include_attachments, **kwargs)\u001b[39m\n\u001b[32m   5178\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m] = dataset_id\n\u001b[32m   5179\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dataset_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5180\u001b[39m     dataset_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m.id\n\u001b[32m   5181\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m] = dataset_id\n\u001b[32m   5182\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/utils.py:142\u001b[39m, in \u001b[36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m     invalid_group_names = [\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExactly one argument in each of the following\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m groups must be defined:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:3774\u001b[39m, in \u001b[36mClient.read_dataset\u001b[39m\u001b[34m(self, dataset_name, dataset_id)\u001b[39m\n\u001b[32m   3772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3773\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMust provide dataset_name or dataset_id\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3774\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3775\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3778\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3779\u001b[39m result = response.json()\n\u001b[32m   3780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:910\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithRateLimitError(\n\u001b[32m    906\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRate limit exceeded for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    907\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    908\u001b[39m     )\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m401\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithAuthError(\n\u001b[32m    911\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthentication failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    912\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    913\u001b[39m     )\n\u001b[32m    914\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    916\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    917\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    918\u001b[39m     )\n",
      "\u001b[31mLangSmithAuthError\u001b[39m: Authentication failed for /datasets. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/datasets?limit=1&name=RAG_EVAL_DATASET', '{\"detail\":\"Invalid token\"}')"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가자 정의\n",
    "heuristic_evalulators = [\n",
    "    rouge_evaluator(metric=\"rougeL\"),\n",
    "    bleu_evaluator,\n",
    "    meteor_evaluator,\n",
    "    semscore_evaluator,\n",
    "]\n",
    "\n",
    "# 데이터셋 이름 설정\n",
    "dataset_name = \"RAG_EVAL_DATASET\"\n",
    "\n",
    "# 실험 실행\n",
    "experiment_results = evaluate(\n",
    "    ask_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=heuristic_evalulators,\n",
    "    experiment_prefix=\"Heuristic-EVAL\",\n",
    "    # 실험 메타데이터 지정\n",
    "    metadata={\n",
    "        \"variant\": \"Heuristic-EVAL (Rouge, BLEU, METEOR, SemScore) 을 사용하여 평가\",\n",
    "    },\n",
    ")\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMs2OSEsEhI+eP+P38efuYH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
