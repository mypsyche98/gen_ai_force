{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6c7ee468-edd7-4148-ba9a-11bc38c89ebd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc9646d9dd847219ceb5137aff47aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging PEFT from: ./Qwen2-VL-7B-Instruct_LoRA_custom_20250805/checkpoint-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "adapter_path = \"./Qwen2-VL-7B-Instruct_LoRA_custom_20250805/checkpoint-70\"\n",
    "base_model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "merged_path = \"Qwen2-VL-7B-Instruct_LoRA_custom_20250805_merged\"\n",
    "\n",
    "# 베이스 모델 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(base_model_id, low_cpu_mem_usage=True)\n",
    "\n",
    "# LoRA 어댑터 로드 및 병합\n",
    "print(f\"Loading and merging PEFT from: {adapter_path}\")\n",
    "peft_model = PeftModel.from_pretrained(model, adapter_path)\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "merged_model.save_pretrained(merged_path,safe_serialization=True, max_shard_size=\"2GB\")\n",
    "\n",
    "# 토크나이저 로드\n",
    "processor = AutoProcessor.from_pretrained(base_model_id)\n",
    "processor.save_pretrained(merged_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "  with open('20250801_Huggingfacie_Token.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fbb82799-6852-435d-9fd6-c74506919f41"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "username = \"mypsyche98\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c297bafe-2a52-4304-b467-59c64a20df48"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = merged_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "51bc3b1e-ab40-4954-afd4-92c1ca47454f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Provided path: '/workspace/merged' is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_1576/1602430031.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m     repo_id=\u001b[33mf\"{username}/{MODEL_NAME}\"\u001b[39m,\n\u001b[32m      4\u001b[39m     repo_type=\u001b[33m\"model\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m api.upload_folder(\n\u001b[32m      8\u001b[39m     token=get_token(),\n\u001b[32m      9\u001b[39m     repo_id=\u001b[33mf\"{username}/{MODEL_NAME}\"\u001b[39m,\n\u001b[32m     10\u001b[39m     folder_path=\u001b[33m\"merged\"\u001b[39m,\n",
      "\u001b[32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m             kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token, kwargs=kwargs)\n\u001b[32m    113\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1661\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_as_future:\n\u001b[32m   1662\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.run_as_future(fn, self, *args, **kwargs)\n\u001b[32m   1663\u001b[39m \n\u001b[32m   1664\u001b[39m         \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1665\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(self, *args, **kwargs)\n",
      "\u001b[32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, repo_id, folder_path, path_in_repo, commit_message, commit_description, token, repo_type, revision, create_pr, parent_commit, allow_patterns, ignore_patterns, delete_patterns, run_as_future)\u001b[39m\n\u001b[32m   4953\u001b[39m             token=token,\n\u001b[32m   4954\u001b[39m             path_in_repo=path_in_repo,\n\u001b[32m   4955\u001b[39m             delete_patterns=delete_patterns,\n\u001b[32m   4956\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4957\u001b[39m         add_operations = self._prepare_upload_folder_additions(\n\u001b[32m   4958\u001b[39m             folder_path,\n\u001b[32m   4959\u001b[39m             path_in_repo,\n\u001b[32m   4960\u001b[39m             allow_patterns=allow_patterns,\n",
      "\u001b[32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, folder_path, path_in_repo, allow_patterns, ignore_patterns, repo_type, token)\u001b[39m\n\u001b[32m   9613\u001b[39m         \"\"\"\n\u001b[32m   9614\u001b[39m \n\u001b[32m   9615\u001b[39m         folder_path = Path(folder_path).expanduser().resolve()\n\u001b[32m   9616\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m folder_path.is_dir():\n\u001b[32m-> \u001b[39m\u001b[32m9617\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"Provided path: '{folder_path}' is not a directory\"\u001b[39m)\n\u001b[32m   9618\u001b[39m \n\u001b[32m   9619\u001b[39m         \u001b[38;5;66;03m# List files from folder\u001b[39;00m\n\u001b[32m   9620\u001b[39m         relpath_to_abspath = {\n",
      "\u001b[31mValueError\u001b[39m: Provided path: '/workspace/merged' is not a directory"
     ]
    }
   ],
   "source": [
    "api.create_repo(\n",
    "    token=get_token(),\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    repo_type=\"model\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dba3d360d5e4fd8b2fd7b7243e806d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca88c3e4e1c946c38522a0f25b81c04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42913583ba10446592b31b69ed2e9644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00002-of-00018.safetensors:   2%|1         | 41.9MB / 2.18GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1be53687234d3389caafc784efa2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...stom_20250805_merged/tokenizer.json:   0%|          | 26.1kB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b3fed6fcdd43f2bf96371a05e80496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00017-of-00018.safetensors:   2%|1         | 33.5MB / 2.18GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b0ff6e7a44801a3e367f86eea81c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00001-of-00018.safetensors:   2%|1         | 33.5MB / 1.99GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ae1f92d485406a808c181ffdce8ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00004-of-00018.safetensors:   0%|          | 3.75MB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b31f8280eb4d369bc25dca7a036517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00014-of-00018.safetensors:   0%|          | 2.23MB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f347b516e440018e89e8ca223304d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00016-of-00018.safetensors:   0%|          | 3.34MB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0502e55bb27405d8d6626d4a0eb4455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00009-of-00018.safetensors:   0%|          |  556kB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d250089e07d4b0aae9494d98fe8b556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00006-of-00018.safetensors:   0%|          | 6.12MB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9496268ffc9f48e8af7d9569adc7d3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ed/model-00005-of-00018.safetensors:   0%|          | 3.89MB / 1.86GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mypsyche98/Qwen2-VL-7B-Instruct_LoRA_custom_20250805_merged/commit/e404aeb5a1b37037f3b42c640a2b297dc2fcefed', commit_message='Upload folder using huggingface_hub', commit_description='', oid='e404aeb5a1b37037f3b42c640a2b297dc2fcefed', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mypsyche98/Qwen2-VL-7B-Instruct_LoRA_custom_20250805_merged', endpoint='https://huggingface.co', repo_type='model', repo_id='mypsyche98/Qwen2-VL-7B-Instruct_LoRA_custom_20250805_merged'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "api.upload_folder(\n",
    "    token=get_token(),\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    folder_path=merged_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNUXjxNCHeN8F4m8ecmRMx9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
