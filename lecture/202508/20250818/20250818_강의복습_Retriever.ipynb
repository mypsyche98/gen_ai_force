{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9238,
     "status": "ok",
     "timestamp": 1755476228365,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "Eh-q59qaiSd9",
    "outputId": "47478fb8-ccf9-4e9e-b213-81409aa74ed1"
   },
   "outputs": [],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25630,
     "status": "ok",
     "timestamp": 1755476282286,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "yga-_OwGiZXh",
    "outputId": "ebd5894c-4d38-41e5-86b8-64f3ec55845e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 링크를 복사하여 웹 브라우저에 붙여넣으세요.\n",
      "https://accounts.google.com/o/oauth2/auth?client_id=35726703810-4v13dfqmilhgv6shlc3cv9i3ktuh73j1.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mykeys\n",
    "\n",
    "project_name = 'CH10_Retriever'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"OPENAI_API_KEY\"] = mykeys.get_key('GPT')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = mykeys.get_key('GOO')\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = mykeys.get_key('HF')\n",
    "os.environ[\"UPSTAGE_API_KEY\"] = mykeys.get_key('UP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8262,
     "status": "ok",
     "timestamp": 1755476320378,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "q1l30lhMirUU",
    "outputId": "85deabac-429a-4935-c7f9-9292cccb24b3"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "error",
     "timestamp": 1755476297112,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "ZIWiW7JqimXQ",
    "outputId": "f0c6d903-9697-4432-e2b1-a2b8a3973ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH10_Retriever\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gmLNFK1imRF"
   },
   "outputs": [],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6g4jP9yviAUw"
   },
   "source": [
    "벡터스토어 기반 검색기(VectorStore-backed Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749969541203,
     "user": {
      "displayName": "김광무",
      "userId": "03808645168826839149"
     },
     "user_tz": -540
    },
    "id": "DHjzPvyRefj3",
    "outputId": "5fcb0662-3ac4-4078-deb4-9cf89c6c2c21"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# TextLoader를 사용하여 파일을 로드합니다.\n",
    "loader = TextLoader(\"./appendix-keywords.txt\")\n",
    "\n",
    "# 문서를 로드합니다.\n",
    "documents = loader.load()\n",
    "\n",
    "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "\n",
    "# 로드된 문서를 분할합니다.\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# OpenAI 임베딩을 생성합니다.\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\n",
    "db = FAISS.from_documents(split_docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oJWRnk7DRWsm"
   },
   "outputs": [],
   "source": [
    "# 데이터베이스를 검색기로 사용하기 위해 retriever 변수에 할당\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "=========================================================\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "=========================================================\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "=========================================================\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "=========================================================\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# MMR(Maximal Marginal Relevance) 검색 유형을 지정\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.6}\n",
    ")\n",
    "\n",
    "# 관련 문서를 검색합니다.\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    # 검색 유형을 \"similarity_score_threshold 으로 설정\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    # 임계값 설정\n",
    "    search_kwargs={\"score_threshold\": 0.8},\n",
    ")\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in retriever.invoke(\"Word2Vec 은 무엇인가요?\"):\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# k 설정\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "# k 설정\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1}).configurable_fields(\n",
    "    search_type=ConfigurableField(\n",
    "        id=\"search_type\",\n",
    "        name=\"Search Type\",\n",
    "        description=\"The search type to use\",\n",
    "    ),\n",
    "    search_kwargs=ConfigurableField(\n",
    "        # 검색 매개변수의 고유 식별자를 설정\n",
    "        id=\"search_kwargs\",\n",
    "        # 검색 매개변수의 이름을 설정\n",
    "        name=\"Search Kwargs\",\n",
    "        # 검색 매개변수에 대한 설명을 작성\n",
    "        description=\"The search kwargs to use\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\n",
      "예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\n",
      "연관키워드: 자연어 처리, 벡터화, 딥러닝\n",
      "\n",
      "Token\n",
      "=========================================================\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "=========================================================\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# 검색 설정을 지정. Faiss 검색에서 k=3로 설정하여 가장 유사한 문서 3개를 반환\n",
    "config = {\"configurable\": {\"search_kwargs\": {\"k\": 3}}}\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"임베딩(Embedding)은 무엇인가요?\", config=config)\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# 검색 설정을 지정. score_threshold 0.8 이상의 점수를 가진 문서만 반환\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"search_type\": \"similarity_score_threshold\",\n",
    "        \"search_kwargs\": {\n",
    "            \"score_threshold\": 0.8,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"Word2Vec 은 무엇인가요?\", config=config)\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "=========================================================\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# 검색 설정을 지정. mmr 검색 설정.\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"search_type\": \"mmr\",\n",
    "        \"search_kwargs\": {\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.6},\n",
    "    }\n",
    "}\n",
    "\n",
    "# 관련 문서를 검색\n",
    "docs = retriever.invoke(\"Word2Vec 은 무엇인가요?\", config=config)\n",
    "\n",
    "# 관련 문서를 검색\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_upstage\n",
      "  Downloading langchain_upstage-0.7.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain_upstage) (0.3.74)\n",
      "Requirement already satisfied: langchain-openai<0.4,>=0.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain_upstage) (0.3.30)\n",
      "Collecting pypdf<5.0.0,>=4.2.0 (from langchain_upstage)\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain_upstage) (2.32.4)\n",
      "Collecting tokenizers<0.21.0,>=0.20.0 (from langchain_upstage)\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (0.4.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain_upstage) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (3.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-openai<0.4,>=0.3->langchain_upstage) (1.99.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-openai<0.4,>=0.3->langchain_upstage) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain_upstage) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->langchain_upstage) (2.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain_upstage) (2025.7.34)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from tokenizers<0.21.0,>=0.20.0->langchain_upstage) (0.34.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (1.1.7)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.29->langchain_upstage) (0.23.0)\n",
      "Downloading langchain_upstage-0.7.1-py3-none-any.whl (20 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf, tokenizers, langchain_upstage\n",
      "\u001b[2K  Attempting uninstall: pypdf\n",
      "\u001b[2K    Found existing installation: pypdf 6.0.0\n",
      "\u001b[2K    Uninstalling pypdf-6.0.0:\n",
      "\u001b[2K      Successfully uninstalled pypdf-6.0.0\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
      "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain_upstage]\u001b[0m \u001b[32m2/3\u001b[0m [langchain_upstage]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.50.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain_upstage-0.7.1 pypdf-4.3.1 tokenizers-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# TextLoader를 사용하여 파일을 로드합니다.\n",
    "loader = TextLoader(\"./appendix-keywords.txt\")\n",
    "\n",
    "# 문서를 로드합니다.\n",
    "documents = loader.load()\n",
    "\n",
    "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "\n",
    "# 로드된 문서를 분할합니다.\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Upstage 임베딩을 생성합니다. 문서용 모델을 사용합니다.\n",
    "doc_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "\n",
    "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\n",
    "db = FAISS.from_documents(split_docs, doc_embedder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0e1aae66-8b4f-490c-8204-ccda7136849b', metadata={'source': './appendix-keywords.txt'}, page_content='정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken'),\n",
       " Document(id='ba26bcbb-b39e-4839-aab3-668950cfd299', metadata={'source': './appendix-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리용 Upstage 임베딩을 생성합니다. 쿼리용 모델을 사용합니다.\n",
    "query_embedder = UpstageEmbeddings(model=\"solar-embedding-1-large-query\")\n",
    "\n",
    "# 쿼리 문장을 벡터로 변환합니다.\n",
    "query_vector = query_embedder.embed_query(\"임베딩(Embedding)은 무엇인가요?\")\n",
    "\n",
    "# 벡터 유사도 검색을 수행하여 가장 유사한 2개의 문서를 반환합니다.\n",
    "db.similarity_search_by_vector(query_vector, k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문맥 압축 검색기(ContextualCompressionRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 예쁘게 출력하기 위한 도우미 함수\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"문서 {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 2:\n",
      "\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
      "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
      "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
      "\n",
      "Page Rank\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 3:\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 4:\n",
      "\n",
      "정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\n",
      "예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\n",
      "연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\n",
      "\n",
      "데이터 마이닝\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# TextLoader를 사용하여 \"appendix-keywords.txt\" 파일에서 문서를 로드합니다.\n",
    "loader = TextLoader(\"./appendix-keywords.txt\")\n",
    "\n",
    "# CharacterTextSplitter를 사용하여 문서를 청크 크기 300자와 청크 간 중복 0으로 분할합니다.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "texts = loader.load_and_split(text_splitter)\n",
    "\n",
    "# OpenAIEmbeddings를 사용하여 FAISS 벡터 저장소를 생성하고 검색기로 변환합니다.\n",
    "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    "\n",
    "# 쿼리에 질문을 정의하고 관련 문서를 검색합니다.\n",
    "docs = retriever.invoke(\"Semantic Search 에 대해서 알려줘.\")\n",
    "\n",
    "# 검색된 문서를 예쁘게 출력합니다.\n",
    "pretty_print_docs(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 2:\n",
      "\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
      "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
      "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
      "\n",
      "Page Rank\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 3:\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 4:\n",
      "\n",
      "정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\n",
      "예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\n",
      "연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\n",
      "\n",
      "데이터 마이닝\n",
      "=========================================================\n",
      "============== LLMChainExtractor 적용 후 ==================\n",
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 2:\n",
      "\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
      "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
      "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 3:\n",
      "\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-5-mini\")  # OpenAI 언어 모델 초기화\n",
    "\n",
    "# LLM을 사용하여 문서 압축기 생성\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    # 문서 압축기와 리트리버를 사용하여 컨텍스트 압축 리트리버 생성\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "pretty_print_docs(retriever.invoke(\"Semantic Search 에 대해서 알려줘.\"))\n",
    "\n",
    "print(\"=========================================================\")\n",
    "print(\"============== LLMChainExtractor 적용 후 ==================\")\n",
    "\n",
    "compressed_docs = (\n",
    "    compression_retriever.invoke(  # 컨텍스트 압축 리트리버를 사용하여 관련 문서 검색\n",
    "        \"Semantic Search 에 대해서 알려줘.\"\n",
    "    )\n",
    ")\n",
    "pretty_print_docs(compressed_docs)  # 검색된 문서를 예쁘게 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 2:\n",
      "\n",
      "정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\n",
      "예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\n",
      "연관키워드: 검색 엔진, 데이터 검색, 정보 검색\n",
      "\n",
      "Page Rank\n",
      "----------------------------------------------------------------------------------------------------\n",
      "문서 3:\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.document_compressors import LLMChainFilter\n",
    "\n",
    "# LLM을 사용하여 LLMChainFilter 객체를 생성합니다.\n",
    "_filter = LLMChainFilter.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    # LLMChainFilter와 retriever를 사용하여 ContextualCompressionRetriever 객체를 생성합니다.\n",
    "    base_compressor=_filter,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    # 쿼리\n",
    "    \"Semantic Search 에 대해서 알려줘.\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)  # 압축된 문서를 예쁘게 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "Embedding\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 유사도 임계값이 0.76인 EmbeddingsFilter 객체를 생성합니다.\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.86)\n",
    "\n",
    "# 기본 압축기로 embeddings_filter를, 기본 검색기로 retriever를 사용하여 ContextualCompressionRetriever 객체를 생성합니다.\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter, base_retriever=retriever\n",
    ")\n",
    "\n",
    "# ContextualCompressionRetriever 객체를 사용하여 관련 문서를 검색합니다.\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    # 쿼리\n",
    "    \"Semantic Search 에 대해서 알려줘.\"\n",
    ")\n",
    "# 압축된 문서를 예쁘게 출력합니다.\n",
    "pretty_print_docs(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 문자 기반 텍스트 분할기를 생성하고, 청크 크기를 300으로, 청크 간 중복을 0으로 설정합니다.\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "\n",
    "# 임베딩을 사용하여 중복 필터를 생성합니다.\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "\n",
    "# 임베딩을 사용하여 관련성 필터를 생성하고, 유사도 임계값을 0.86으로 설정합니다.\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.86)\n",
    "\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    # 문서 압축 파이프라인을 생성하고, 분할기, 중복 필터, 관련성 필터, LLMChainExtractor를 변환기로 설정합니다.\n",
    "    transformers=[\n",
    "        splitter,\n",
    "        redundant_filter,\n",
    "        relevant_filter,\n",
    "        LLMChainExtractor.from_llm(llm),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1:\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\n",
      "예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\n",
      "연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    # 기본 압축기로 pipeline_compressor를 사용하고, 기본 검색기로 retriever를 사용하여 ContextualCompressionRetriever를 초기화합니다.\n",
    "    base_compressor=pipeline_compressor,\n",
    "    base_retriever=retriever,\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    # 쿼리\n",
    "    \"Semantic Search 에 대해서 알려줘.\"\n",
    ")\n",
    "# 압축된 문서를 예쁘게 출력합니다.\n",
    "pretty_print_docs(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 검색기(Ensemble Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 샘플 문서 리스트\n",
    "doc_list = [\n",
    "    \"I like apples\",\n",
    "    \"I like apple company\",\n",
    "    \"I like apple's iphone\",\n",
    "    \"Apple is my favorite company\",\n",
    "    \"I like apple's ipad\",\n",
    "    \"I like apple's macbook\",\n",
    "]\n",
    "\n",
    "\n",
    "# bm25 retriever와 faiss retriever를 초기화합니다.\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    doc_list,\n",
    ")\n",
    "bm25_retriever.k = 1  # BM25Retriever의 검색 결과 개수를 1로 설정합니다.\n",
    "\n",
    "embedding = OpenAIEmbeddings()  # OpenAI 임베딩을 사용합니다.\n",
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    doc_list,\n",
    "    embedding,\n",
    ")\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 앙상블 retriever를 초기화합니다.\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.7, 0.3],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ensemble Retriever]\n",
      "Content: Apple is my favorite company\n",
      "\n",
      "Content: I like apples\n",
      "\n",
      "[BM25 Retriever]\n",
      "Content: Apple is my favorite company\n",
      "\n",
      "[FAISS Retriever]\n",
      "Content: I like apples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"my favorite fruit is apple\"\n",
    "ensemble_result = ensemble_retriever.invoke(query)\n",
    "bm25_result = bm25_retriever.invoke(query)\n",
    "faiss_result = faiss_retriever.invoke(query)\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[Ensemble Retriever]\")\n",
    "for doc in ensemble_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[BM25 Retriever]\")\n",
    "for doc in bm25_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[FAISS Retriever]\")\n",
    "for doc in faiss_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ensemble Retriever]\n",
      "Content: Apple is my favorite company\n",
      "\n",
      "Content: I like apple's iphone\n",
      "\n",
      "[BM25 Retriever]\n",
      "Content: Apple is my favorite company\n",
      "\n",
      "[FAISS Retriever]\n",
      "Content: I like apple's iphone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"Apple company makes my favorite iphone\"\n",
    "ensemble_result = ensemble_retriever.invoke(query)\n",
    "bm25_result = bm25_retriever.invoke(query)\n",
    "faiss_result = faiss_retriever.invoke(query)\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[Ensemble Retriever]\")\n",
    "for doc in ensemble_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[BM25 Retriever]\")\n",
    "for doc in bm25_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[FAISS Retriever]\")\n",
    "for doc in faiss_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    # 리트리버 목록을 설정합니다. 여기서는 bm25_retriever와 faiss_retriever를 사용합니다.\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    ").configurable_fields(\n",
    "    weights=ConfigurableField(\n",
    "        # 검색 매개변수의 고유 식별자를 설정합니다.\n",
    "        id=\"ensemble_weights\",\n",
    "        # 검색 매개변수의 이름을 설정합니다.\n",
    "        name=\"Ensemble Weights\",\n",
    "        # 검색 매개변수에 대한 설명을 작성합니다.\n",
    "        description=\"Ensemble Weights\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Apple is my favorite company'),\n",
       " Document(id='123886c7-d5f0-4532-83bc-8f66dd1a8761', metadata={}, page_content='I like apples')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"ensemble_weights\": [1, 0]}}\n",
    "\n",
    "# config 매개변수를 사용하여 검색 설정을 지정합니다.\n",
    "docs = ensemble_retriever.invoke(\"my favorite fruit is apple\", config=config)\n",
    "docs  # 검색 결과인 docs를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='123886c7-d5f0-4532-83bc-8f66dd1a8761', metadata={}, page_content='I like apples'),\n",
       " Document(metadata={}, page_content='Apple is my favorite company')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"ensemble_weights\": [0, 1]}}\n",
    "\n",
    "# config 매개변수를 사용하여 검색 설정을 지정합니다.\n",
    "docs = ensemble_retriever.invoke(\"my favorite fruit is apple\", config=config)\n",
    "docs  # 검색 결과인 docs를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긴 문맥 재정렬(LongContextReorder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# 임베딩을 가져옵니다.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "texts = [\n",
    "    \"이건 그냥 내가 아무렇게나 적어본 글입니다.\",\n",
    "    \"사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.\",\n",
    "    \"아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.\",\n",
    "    \"챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.\",\n",
    "    \"챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.\",\n",
    "    \"애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.\",\n",
    "    \"ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.\",\n",
    "    \"비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.\",\n",
    "    \"ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.\",\n",
    "    \"FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.\",\n",
    "]\n",
    "\n",
    "\n",
    "# 검색기를 생성합니다. (K는 10으로 설정합니다)\n",
    "retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.'),\n",
       " Document(metadata={}, page_content='ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.'),\n",
       " Document(metadata={}, page_content='사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.'),\n",
       " Document(metadata={}, page_content='챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.'),\n",
       " Document(metadata={}, page_content='이건 그냥 내가 아무렇게나 적어본 글입니다.'),\n",
       " Document(metadata={}, page_content='챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.'),\n",
       " Document(metadata={}, page_content='비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.'),\n",
       " Document(metadata={}, page_content='아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.'),\n",
       " Document(metadata={}, page_content='애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.'),\n",
       " Document(metadata={}, page_content='FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"ChatGPT에 대해 무엇을 말해줄 수 있나요?\"\n",
    "\n",
    "# 관련성 점수에 따라 정렬된 관련 문서를 가져옵니다.\n",
    "docs = retriever.invoke(query)\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.'),\n",
       " Document(metadata={}, page_content='챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.'),\n",
       " Document(metadata={}, page_content='챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.'),\n",
       " Document(metadata={}, page_content='아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.'),\n",
       " Document(metadata={}, page_content='FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.'),\n",
       " Document(metadata={}, page_content='애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.'),\n",
       " Document(metadata={}, page_content='비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.'),\n",
       " Document(metadata={}, page_content='이건 그냥 내가 아무렇게나 적어본 글입니다.'),\n",
       " Document(metadata={}, page_content='사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.'),\n",
       " Document(metadata={}, page_content='ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서를 재정렬합니다\n",
    "# 덜 관련된 문서는 목록의 중간에 위치하고 더 관련된 요소는 시작/끝에 위치합니다.\n",
    "reordering = LongContextReorder()\n",
    "reordered_docs = reordering.transform_documents(docs)\n",
    "\n",
    "# 4개의 관련 문서가 시작과 끝에 위치하는지 확인합니다.\n",
    "reordered_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join([doc.page_content for i, doc in enumerate(docs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.\n",
      "ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.\n",
      "사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.\n",
      "챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.\n",
      "이건 그냥 내가 아무렇게나 적어본 글입니다.\n",
      "챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.\n",
      "비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.\n",
      "아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.\n",
      "애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.\n",
      "FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.\n"
     ]
    }
   ],
   "source": [
    "print(format_docs(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"[{i}] {doc.page_content} [source: mypsyche98@gmail.com]\"\n",
    "            for i, doc in enumerate(docs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def reorder_documents(docs):\n",
    "    # 재정렬\n",
    "    reordering = LongContextReorder()\n",
    "    reordered_docs = reordering.transform_documents(docs)\n",
    "    combined = format_docs(reordered_docs)\n",
    "    print(combined)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[1] 챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[2] 챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다. [source: mypsyche98@gmail.com]\n",
      "[3] 아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다. [source: mypsyche98@gmail.com]\n",
      "[4] FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다. [source: mypsyche98@gmail.com]\n",
      "[5] 애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다. [source: mypsyche98@gmail.com]\n",
      "[6] 비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[7] 이건 그냥 내가 아무렇게나 적어본 글입니다. [source: mypsyche98@gmail.com]\n",
      "[8] 사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다. [source: mypsyche98@gmail.com]\n",
      "[9] ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다. [source: mypsyche98@gmail.com]\n"
     ]
    }
   ],
   "source": [
    "# 재정렬된 문서를 출력\n",
    "_ = reorder_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "template = \"\"\"Given this text extracts:\n",
    "{context}\n",
    "\n",
    "-----\n",
    "Please answer the following question:\n",
    "{question}\n",
    "\n",
    "Answer in the following languages: {language}\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 정의\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Chain 정의\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\")\n",
    "        | retriever\n",
    "        | RunnableLambda(reorder_documents),  # 질문을 기반으로 문맥을 검색합니다.\n",
    "        \"question\": itemgetter(\"question\"),  # 질문을 추출합니다.\n",
    "        \"language\": itemgetter(\"language\"),  # 답변 언어를 추출합니다.\n",
    "    }\n",
    "    | prompt  # 프롬프트 템플릿에 값을 전달합니다.\n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\")  # 언어 모델에 프롬프트를 전달합니다.\n",
    "    | StrOutputParser()  # 모델의 출력을 문자열로 파싱합니다.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[1] 챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[2] 챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다. [source: mypsyche98@gmail.com]\n",
      "[3] 아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다. [source: mypsyche98@gmail.com]\n",
      "[4] FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다. [source: mypsyche98@gmail.com]\n",
      "[5] 애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다. [source: mypsyche98@gmail.com]\n",
      "[6] 비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다. [source: mypsyche98@gmail.com]\n",
      "[7] 이건 그냥 내가 아무렇게나 적어본 글입니다. [source: mypsyche98@gmail.com]\n",
      "[8] 사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다. [source: mypsyche98@gmail.com]\n",
      "[9] ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다. [source: mypsyche98@gmail.com]\n"
     ]
    }
   ],
   "source": [
    "answer = chain.invoke(\n",
    "    {\"question\": \"ChatGPT에 대해 무엇을 말해줄 수 있나요?\", \"language\": \"KOREAN\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT는 OpenAI에 의해 개발된 인공지능으로, 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다. 계속해서 지속적인 학습과 업데이트를 통해 더욱 발전하고 있으며, 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다. 또한, 사용자와 대화하는 것처럼 설계되어 다양한 질문에 답할 수 있는 능력을 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상위 문서 검색기(ParentDocumentRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    # 파일을 로드합니다.\n",
    "    TextLoader(\"./appendix-keywords.txt\"),\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    # 로더를 사용하여 문서를 로드하고 docs 리스트에 추가합니다.\n",
    "    docs.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 자식 분할기를 생성합니다.\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "\n",
    "# DB를 생성합니다.\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Retriever 를 생성합니다.\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 검색기에 추가합니다. docs는 문서 목록이고, ids는 문서의 고유 식별자 목록입니다.\n",
    "retriever.add_documents(docs, ids=None, add_to_docstore=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6d47849e-5c4d-4df6-8bec-c8fababb5b7e']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장소의 모든 키를 리스트로 반환합니다.\n",
    "list(store.yield_keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "sub_docs = vectorstore.similarity_search(\"Word2Vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
     ]
    }
   ],
   "source": [
    "# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
    "print(sub_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"Word2Vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 길이: 5733\n",
      "\n",
      "=====================\n",
      "\n",
      " 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
      "연관키워드: 혁신, 기술, 비즈니스 모델\n",
      "\n",
      "Crawling\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n",
      "\n",
      "정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을\n"
     ]
    }
   ],
   "source": [
    "# 검색된 문서의 문서의 페이지 내용의 길이를 출력합니다.\n",
    "print(\n",
    "    f\"문서의 길이: {len(retrieved_docs[0].page_content)}\",\n",
    "    end=\"\\n\\n=====================\\n\\n\",\n",
    ")\n",
    "\n",
    "# 문서의 일부를 출력합니다.\n",
    "print(retrieved_docs[0].page_content[2000:2500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 부모 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "# 자식 문서를 생성하는 데 사용되는 텍스트 분할기입니다.\n",
    "# 부모보다 작은 문서를 생성해야 합니다.\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소입니다.\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장 계층입니다.\n",
    "store = InMemoryStore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    # 벡터 저장소를 지정합니다.\n",
    "    vectorstore=vectorstore,\n",
    "    # 문서 저장소를 지정합니다.\n",
    "    docstore=store,\n",
    "    # 하위 문서 분할기를 지정합니다.\n",
    "    child_splitter=child_splitter,\n",
    "    # 상위 문서 분할기를 지정합니다.\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs)  # 문서를 retriever에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "sub_docs = vectorstore.similarity_search(\"Word2Vec\")\n",
    "# sub_docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
    "print(sub_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\n",
      "예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\n",
      "연관키워드: 딥러닝, 자연어 처리, Attention\n",
      "\n",
      "HuggingFace\n",
      "\n",
      "정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\n",
      "예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\n",
      "연관키워드: 자연어 처리, 딥러닝, 라이브러리\n",
      "\n",
      "Digital Transformation\n",
      "\n",
      "정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\n",
      "예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\n",
      "연관키워드: 혁신, 기술, 비즈니스 모델\n",
      "\n",
      "Crawling\n",
      "\n",
      "정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\n",
      "예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\n",
      "연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\n",
      "\n",
      "Word2Vec\n",
      "\n",
      "정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\n",
      "예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\n",
      "연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\n",
      "LLM (Large Language Model)\n"
     ]
    }
   ],
   "source": [
    "# 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"Word2Vec\")\n",
    "\n",
    "# 검색된 문서의 첫 번째 문서의 페이지 내용의 길이를 반환합니다.\n",
    "print(retrieved_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 쿼리 검색기(MultiQueryRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 벡터DB 구축\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 블로그 포스트 로드\n",
    "loader = WebBaseLoader(\n",
    "    \"https://teddylee777.github.io/openai/openai-assistant-tutorial/\", encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 임베딩 정의\n",
    "openai_embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 벡터DB 생성\n",
    "db = FAISS.from_documents(docs, openai_embedding)\n",
    "\n",
    "# retriever 생성\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# 문서 검색\n",
    "query = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "# 검색된 문서의 개수 출력\n",
    "len(relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 강력한 도구로서, Assistant에게 사용자 정의 함수를 지정할 수 있습니다. 이는 Chat Completions API에서의 함수 호출과 매우 유사합니다.\n",
      "\n",
      "\n",
      "Function calling(함수 호출) 도구를 사용하면 Assistant 에게 사용자 정의 함수 를 설명하여 호출해야 하는 함수를 인자와 함께 지능적으로 반환하도록 할 수 있습니다.\n",
      "\n",
      "\n",
      "Assistant API는 실행 중에 함수를 호출할 때 실행을 일시 중지하며, 함수 호출 결과를 다시 제공하여 Run 실행을 계속할 수 있습니다. (이는 사용자 피드백을 받아 재게할 수 있는 의미이기도 합니다. 아래 튜토리얼에서 상세히 다룹니다).\n"
     ]
    }
   ],
   "source": [
    "# 1번 문서를 출력합니다.\n",
    "print(relevant_docs[1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ChatOpenAI 언어 모델을 초기화합니다. temperature는 0으로 설정합니다.\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-5-mini\")\n",
    "\n",
    "multiquery_retriever = MultiQueryRetriever.from_llm(  # MultiQueryRetriever를 언어 모델을 사용하여 초기화합니다.\n",
    "    # 벡터 데이터베이스의 retriever와 언어 모델을 전달합니다.\n",
    "    retriever=db.as_retriever(),\n",
    "    llm=llm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리에 대한 로깅 설정\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant API의 Functions 기능 사용법(설정 방법, 함수 정의, 호출 흐름)과 간단한 예제를 설명해 주세요.', 'Functions를 OpenAI Assistant API에 통합하는 방법: JSON 스키마로 파라미터 정의, 응답 분기 처리, 에러 처리 및 베스트 프랙티스를 Python/Node.js 예제와 함께 알려주세요.', 'OpenAI Assistant API의 Functions 사용 시 인증, 요청 형식, 권한·보안 고려사항, 제한사항(토큰/비용) 및 실제 코드 샘플을 포함한 단계별 가이드를 제공해 주세요.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "검색된 문서 개수: 7\n",
      "===============\n",
      "OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n",
      "\n",
      "\n",
      "\n",
      "주요내용\n"
     ]
    }
   ],
   "source": [
    "# 질문을 정의합니다.\n",
    "question = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n",
    "# 문서 검색\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# 검색된 고유한 문서의 개수를 반환합니다.\n",
    "print(\n",
    "    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# 검색된 문서의 내용을 출력합니다.\n",
    "print(relevant_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI Assistant API의 Functions 기능을 단계별로 설정하고 사용하는 방법을 알려주세요.\\nOpenAI Assistant API에서 Functions를 정의하고 호출하는 예제 코드(Python/Node.js)와 사용법을 보여주세요.\\nOpenAI Assistant API Functions의 파라미터, 응답 처리, 에러 핸들링 등 실무 사용법을 설명해 주세요.\\nOpenAI Assistant API의 Functions 연동 시 필요한 설정, 권한, 보안 주의사항과 베스트 프랙티스를 알려주세요.\\nOpenAI Assistant API에서 Functions를 이용해 외부 API를 연동하는 전체 워크플로(등록·테스트·디버깅) 예시를 보여주세요.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿을 정의합니다.(5개의 질문을 생성하도록 프롬프트를 작성하였습니다)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language model assistant. \n",
    "Your task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. \n",
    "By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \n",
    "Your response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n",
    "\n",
    "#ORIGINAL QUESTION: \n",
    "{question}\n",
    "\n",
    "#Answer in Korean:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 언어 모델 인스턴스를 생성합니다.\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-5-mini\")\n",
    "\n",
    "# LLMChain을 생성합니다.\n",
    "custom_multiquery_chain = (\n",
    "    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 질문을 정의합니다.\n",
    "question = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n",
    "\n",
    "# 체인을 실행하여 생성된 다중 쿼리를 확인합니다.\n",
    "multi_queries = custom_multiquery_chain.invoke(question)\n",
    "# 결과를 확인합니다.(5개 질문 생성)\n",
    "multi_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=custom_multiquery_chain, retriever=db.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant API의 Functions 기능 사용법과 기본 개념을 설명해 주세요.', 'OpenAI Assistant API에서 functions를 정의하고 호출하는 방법(예: JSON 스키마, 이름, 매개변수 등)과 예제를 보여 주세요.', 'Python 또는 JavaScript에서 OpenAI Assistant API의 Functions를 구현하는 구체적인 코드 예제와 단계별 가이드를 알려 주세요.', 'OpenAI Assistant API의 Functions 사용 시 발생할 수 있는 오류 처리 방법, 권한 설정 및 보안 모범 사례는 무엇인가요?', 'OpenAI Assistant API의 Functions와 기존 Chat/REST 방식의 차이점, 성능·비용 영향 및 언제 Functions를 사용하는 것이 적절한지 설명해 주세요.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "검색된 문서 개수: 7\n",
      "===============\n",
      "OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n",
      "\n",
      "\n",
      "\n",
      "주요내용\n"
     ]
    }
   ],
   "source": [
    "# 결과\n",
    "relevant_docs = multiquery_retriever.invoke(question)\n",
    "\n",
    "# 검색된 고유한 문서의 개수를 반환합니다.\n",
    "print(\n",
    "    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n",
    "    end=\"\\n===============\\n\",\n",
    ")\n",
    "\n",
    "# 검색된 문서의 내용을 출력합니다.\n",
    "print(relevant_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 벡터저장소 검색기(MultiVectorRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"./SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\n",
      "n 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을 \n",
      "위한 협력 방안을 담은 블레츨리 선언을 발표\n",
      "n 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, \n",
      "영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정 \n",
      "KEY Contents\n",
      "£ AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\n",
      "n 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에 \n",
      "참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 \n",
      "∙선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이 \n",
      "중요하다고 강조했으며,\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b32ca2f5-b9bf-4382-aa6a-bdd7ca7b4075',\n",
       " 'e6b75145-6184-4480-b479-1be1b9fdbbb9',\n",
       " '1808c339-749f-45bc-97be-505ca809450c',\n",
       " 'efd0b6f5-bfcd-4b51-8c80-f7c84c4c05c4',\n",
       " '8b1e4b81-52ea-4fb3-8334-6e20854731ae',\n",
       " 'c388a8c4-01eb-4202-8de8-4066cdb2cf5d',\n",
       " '29f4f637-5031-4747-97bd-7267a11dc846',\n",
       " '07d8a37a-736d-4549-89e7-d82e8d23acba',\n",
       " '13ef5ff3-c970-4bb2-bdab-f3f757a3cbcd',\n",
       " '91813403-e4da-4462-901d-783832203fe8',\n",
       " 'e363031a-7b18-4a43-a8ec-dae5a130e14c',\n",
       " 'bc6481d1-4c7f-452d-8322-dc982feaafd2',\n",
       " 'dccf1233-bbdc-424b-ab64-51bf75ad5650',\n",
       " '39f18124-3ba4-4675-b557-6d6e82466fd3',\n",
       " '0e63f644-a6db-426f-9929-06c48f64e2d3',\n",
       " '2004a684-943e-43c0-b60c-8efbd9d1471c',\n",
       " '125c0b8c-770c-47e4-8cf2-8c8ca1eb38dd',\n",
       " '44bf35d9-7bac-4e3e-9e9b-77d4aebf2dcd',\n",
       " '0486e5d1-878f-433f-9dee-9f703e230d06',\n",
       " 'cf6a5c18-adb1-433d-9c67-990ecee9cc8d',\n",
       " 'c09425d3-9d8c-4ad1-82e3-10bdd02fc683',\n",
       " '42c33037-1950-4f74-b2ca-38ec60da9b1c',\n",
       " 'c66f8597-ef22-4ec0-aad9-4324c9445848']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 두개의 생성된 id를 확인합니다.\n",
    "doc_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체를 생성합니다.\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# 더 작은 청크를 생성하는 데 사용할 분할기\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Hancom PDF 1.3.0.542',\n",
       " 'creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'creationdate': '2023-12-08T13:28:38+09:00',\n",
       " 'source': './SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': './SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'dj',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-12-08T13:28:38+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20231208132838+09'00'\",\n",
       " 'creationDate': \"D:20231208132838+09'00'\",\n",
       " 'page': 0,\n",
       " 'doc_id': 'b32ca2f5-b9bf-4382-aa6a-bdd7ca7b4075'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 Parent 문서의 메타데이터를 확인합니다.\n",
    "parent_docs[0].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Hancom PDF 1.3.0.542',\n",
       " 'creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'creationdate': '2023-12-08T13:28:38+09:00',\n",
       " 'source': './SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': './SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'dj',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-12-08T13:28:38+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20231208132838+09'00'\",\n",
       " 'creationDate': \"D:20231208132838+09'00'\",\n",
       " 'page': 0,\n",
       " 'doc_id': 'b32ca2f5-b9bf-4382-aa6a-bdd7ca7b4075'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 Child 문서의 메타데이터를 확인합니다.\n",
    "child_docs[0].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 parent_docs의 개수: 73\n",
      "분할된 child_docs의 개수: 440\n"
     ]
    }
   ],
   "source": [
    "print(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\n",
    "print(f\"분할된 child_docs의 개수: {len(child_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 parent + child 문서를 추가\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# docstore 에 원본 문서를 저장\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서의 개수: 4\n"
     ]
    }
   ],
   "source": [
    "# vectorstore의 유사도 검색을 수행합니다.\n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서의 개수: 2\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "∙코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며 \n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며 \n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며, \n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity_score_threshold로 설정\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity로 설정, k값을 1로 설정\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(len(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 문서의 개수: 61\n"
     ]
    }
   ],
   "source": [
    "# PDF 파일을 로드하고 텍스트를 분할하기 위한 라이브러리 임포트\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 로더 초기화\n",
    "loader = PyMuPDFLoader(\"./SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# PDF 파일 로드 및 텍스트 분할 실행\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 분할된 문서의 개수 출력\n",
    "print(f\"분할된 문서의 개수: {len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 문서 요약을 위한 프롬프트 템플릿 생성\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # OpenAI의 ChatGPT 모델을 사용하여 요약 생성\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 배치 처리\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "\n",
      "[요약]\n",
      "- 삼성전자가 자체 개발한 생성 AI 모델 '삼성 가우스'를 공개하였으며, 이 모델은 언어, 코드, 이미지의 3개 모델로 구성되어 온디바이스에서 작동 가능하다.\n",
      "- '삼성 가우스'는 정규분포 이론을 정립한 수학자 가우스의 이름을 따왔으며, 다양한 상황에 최적화된 모델 선택이 가능하고, 안전한 데이터로 학습되어 개인정보 유출 위험이 없다.\n",
      "- 삼성전자는 이 AI 기술을 다양한 제품에 단계적으로 탑재할 계획을 세우고 있다.\n"
     ]
    }
   ],
   "source": [
    "# 원본 문서의 내용을 출력합니다.\n",
    "print(split_docs[33].page_content, end=\"\\n\\n\")\n",
    "# 요약을 출력합니다.\n",
    "print(\"[요약]\")\n",
    "print(summaries[33])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# 요약 정보를 저장할 벡터 저장소를 생성합니다.\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# 부모 문서를 저장할 저장소를 생성합니다.\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 문서 ID를 저장할 키 이름을 지정합니다.\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기를 초기화합니다. (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=summary_vectorstore,  # 벡터 저장소\n",
    "    byte_store=store,  # 바이트 저장소\n",
    "    id_key=id_key,  # 문서 ID 키\n",
    ")\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # 요약된 내용을 페이지 콘텐츠로 하고, 문서 ID를 메타데이터로 포함하는 Document 객체를 생성합니다.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약본의 문서의 개수\n",
    "len(summary_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # 요약된 문서를 벡터 저장소에 추가합니다.\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 삼성전자가 자체 개발한 생성 AI 모델 '삼성 가우스'를 공개하였으며, 이 모델은 언어, 코드, 이미지의 3개 모델로 구성되어 온디바이스에서 작동 가능하다.\n",
      "- '삼성 가우스'는 정규분포 이론을 정립한 수학자 가우스의 이름을 따왔으며, 다양한 상황에 최적화된 모델 선택이 가능하고, 안전한 데이터로 학습되어 개인정보 유출 위험이 없다.\n",
      "- 삼성전자는 이 AI 기술을 다양한 제품에 단계적으로 탑재할 계획을 세우고 있다.\n"
     ]
    }
   ],
   "source": [
    "# 1개의 결과 문서를 출력합니다.\n",
    "print(result_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n"
     ]
    }
   ],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(retrieved_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # 함수의 이름을 지정합니다.\n",
    "        \"description\": \"Generate hypothetical questions\",  # 함수에 대한 설명을 작성합니다.\n",
    "        \"parameters\": {  # 함수의 매개변수를 정의합니다.\n",
    "            \"type\": \"object\",  # 매개변수의 타입을 객체로 지정합니다.\n",
    "            \"properties\": {  # 객체의 속성을 정의합니다.\n",
    "                \"questions\": {  # 'questions' 속성을 정의합니다.\n",
    "                    \"type\": \"array\",  # 'questions'의 타입을 배열로 지정합니다.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # 배열의 요소 타입을 문자열로 지정합니다.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # 필수 매개변수로 'questions'를 지정합니다.\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청합니다. 이 숫자는 조정될 수 있습니다.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-5-mini\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # 출력에서 \"questions\" 키에 해당하는 값을 추출합니다.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼성 가우스의 온디바이스 작동 방식이 사용자 개인정보 보호, 보안, 및 규제 준수에 어떤 영향을 미치며 이를 통해 삼성전자가 경쟁우위를 확보할 수 있는가?',\n",
       " '언어·코드·이미지의 3개 모델로 구성된 삼성 가우스는 기술적 구조, 학습 데이터 및 성능 면에서 OpenAI·Google·Meta 등 기존 대형 모델과 어떻게 차별화되는가?',\n",
       " '삼성 가우스의 온디바이스 배포 전략이 반도체·모바일 생태계, AI 칩 수요 및 개발자·기업용 에코시스템에 미치는 산업적 파급효과는 무엇인가?']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 문서에 대해 체인을 실행합니다.\n",
    "hypothetical_query_chain.invoke(split_docs[33])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 목록에 대해 가설 질문을 배치 생성\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['삼성 가우스의 온디바이스 실행 능력이 기업의 데이터 프라이버시·규제 준수 전략과 고객 신뢰에 어떤 영향을 미칠까?',\n",
       " '언어·코드·이미지 3개 모델을 갖춘 삼성 가우스가 클라우드 기반 생성 AI(예: OpenAI, Google)의 시장 점유율과 제품 통합 경쟁에 어떤 영향을 줄까?',\n",
       " '삼성 가우스의 경량화 모델 선택 및 다양한 제품 탑재 계획이 모바일·가전·IoT 기기에서 성능, 전력 효율, 개발자 생태계에 미치는 영향은 무엇일까?']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_questions[33]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]  # 문서 ID 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# hypothetical_questions 저장\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하고, 메타데이터에 해당 질문의 문서 ID를 포함시킵니다.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical_questions 문서를 벡터 저장소에 추가합니다.\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# 유사한 문서를 벡터 저장소에서 검색합니다.\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성 개발자 콘퍼런스 코리아 2023에서 발표된 삼성의 AI 전략과 향후 로드맵은 무엇인가?\n",
      "{'doc_id': 'a9dd5d2a-4945-4fd9-91c0-361e97a8869c'}\n",
      "TechRepublic 기사에 소개된 삼성의 생성형 AI ‘Gauss’의 주요 기능, 적용 분야, 기술적 차별점은 무엇인가?\n",
      "{'doc_id': 'a9dd5d2a-4945-4fd9-91c0-361e97a8869c'}\n",
      "삼성의 콘퍼런스 발표와 Gauss 공개가 국내외 AI 생태계(시장·산업·연구)에 미칠 영향은 무엇인가?\n",
      "{'doc_id': 'a9dd5d2a-4945-4fd9-91c0-361e97a8869c'}\n",
      "언어·코드·이미지 3개 모델을 갖춘 삼성 가우스가 클라우드 기반 생성 AI(예: OpenAI, Google)의 시장 점유율과 제품 통합 경쟁에 어떤 영향을 줄까?\n",
      "{'doc_id': 'a99ee32e-5143-4957-86af-f8aff9a5ae2e'}\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색 결과를 출력합니다.\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n"
     ]
    }
   ],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "# 검색된 문서를 출력합니다.\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셀프 쿼리 검색기(SelfQueryRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 화장품 상품의 설명과 메타데이터 생성\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"수분 가득한 히알루론산 세럼으로 피부 속 깊은 곳까지 수분을 공급합니다.\",\n",
    "        metadata={\"year\": 2024, \"category\": \"스킨케어\", \"user_rating\": 4.7},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.\",\n",
    "        metadata={\"year\": 2023, \"category\": \"메이크업\", \"user_rating\": 4.5},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"식물성 성분으로 만든 저자극 클렌징 오일, 메이크업과 노폐물을 부드럽게 제거합니다.\",\n",
    "        metadata={\"year\": 2023, \"category\": \"클렌징\", \"user_rating\": 4.8},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.\",\n",
    "        metadata={\"year\": 2023, \"category\": \"스킨케어\", \"user_rating\": 4.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"롱래스팅 립스틱, 선명한 발색과 촉촉한 사용감으로 하루종일 편안하게 사용 가능합니다.\",\n",
    "        metadata={\"year\": 2024, \"category\": \"메이크업\", \"user_rating\": 4.4},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"자외선 차단 기능이 있는 톤업 선크림, SPF50+/PA++++ 높은 자외선 차단 지수로 피부를 보호합니다.\",\n",
    "        metadata={\"year\": 2024, \"category\": \"선케어\", \"user_rating\": 4.9},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs, OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "\n",
    "# 메타데이터 필드 정보 생성\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"The category of the cosmetic product. One of ['스킨케어', '메이크업', '클렌징', '선케어']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the cosmetic product was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"user_rating\",\n",
    "        description=\"A user rating for the cosmetic product, ranging from 1 to 5\",\n",
    "        type=\"float\",\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# SelfQueryRetriever 생성\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=\"Brief summary of a cosmetic product\",\n",
    "    metadata_field_info=metadata_field_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6a65dce7-e467-4a0e-ab1c-c64fc03f1a70', metadata={'category': '선케어', 'user_rating': 4.9, 'year': 2024}, page_content='자외선 차단 기능이 있는 톤업 선크림, SPF50+/PA++++ 높은 자외선 차단 지수로 피부를 보호합니다.'),\n",
       " Document(id='9a80dd48-5de8-4851-ad41-d26edd8d899d', metadata={'category': '클렌징', 'user_rating': 4.8, 'year': 2023}, page_content='식물성 성분으로 만든 저자극 클렌징 오일, 메이크업과 노폐물을 부드럽게 제거합니다.')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\"평점이 4.8 이상인 제품을 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1aaa1169-69d8-404f-96b2-493e919fccac', metadata={'category': '메이크업', 'user_rating': 4.5, 'year': 2023}, page_content='24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.'),\n",
       " Document(id='b8fe4498-a119-4c7f-a3b9-6ff1a7567df4', metadata={'category': '스킨케어', 'user_rating': 4.6, 'year': 2023}, page_content='비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.'),\n",
       " Document(id='9a80dd48-5de8-4851-ad41-d26edd8d899d', metadata={'category': '클렌징', 'user_rating': 4.8, 'year': 2023}, page_content='식물성 성분으로 만든 저자극 클렌징 오일, 메이크업과 노폐물을 부드럽게 제거합니다.')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\"2023년에 출시된 상품을 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6a65dce7-e467-4a0e-ab1c-c64fc03f1a70', metadata={'category': '선케어', 'user_rating': 4.9, 'year': 2024}, page_content='자외선 차단 기능이 있는 톤업 선크림, SPF50+/PA++++ 높은 자외선 차단 지수로 피부를 보호합니다.')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\"카테고리가 선케어인 상품을 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1aaa1169-69d8-404f-96b2-493e919fccac', metadata={'category': '메이크업', 'user_rating': 4.5, 'year': 2023}, page_content='24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\n",
    "    \"카테고리가 메이크업인 상품 중에서 평점이 4.5 이상인 상품을 추천해주세요\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=\"Brief summary of a cosmetic product\",\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    enable_limit=True,  # 검색 결과 제한 기능을 활성화합니다.\n",
    "    search_kwargs={\"k\": 2},  # k 의 값을 2로 지정하여 검색 결과를 2개로 제한합니다.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1aaa1169-69d8-404f-96b2-493e919fccac', metadata={'category': '메이크업', 'user_rating': 4.5, 'year': 2023}, page_content='24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.'),\n",
       " Document(id='b8fe4498-a119-4c7f-a3b9-6ff1a7567df4', metadata={'category': '스킨케어', 'user_rating': 4.6, 'year': 2023}, page_content='비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\"2023년에 출시된 상품을 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1aaa1169-69d8-404f-96b2-493e919fccac', metadata={'category': '메이크업', 'user_rating': 4.5, 'year': 2023}, page_content='24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=\"Brief summary of a cosmetic product\",\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    enable_limit=True,  # 검색 결과 제한 기능을 활성화합니다.\n",
    ")\n",
    "\n",
    "# Self-query 검색\n",
    "retriever.invoke(\"2023년에 출시된 상품 1개를 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1aaa1169-69d8-404f-96b2-493e919fccac', metadata={'category': '메이크업', 'user_rating': 4.5, 'year': 2023}, page_content='24시간 지속되는 매트한 피니시의 파운데이션, 모공을 커버하고 자연스러운 피부 표현이 가능합니다.'),\n",
       " Document(id='b8fe4498-a119-4c7f-a3b9-6ff1a7567df4', metadata={'category': '스킨케어', 'user_rating': 4.6, 'year': 2023}, page_content='비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self-query 검색\n",
    "retriever.invoke(\"2023년에 출시된 상품 2개를 추천해주세요\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt,\n",
    ")\n",
    "\n",
    "# 문서 내용 설명과 메타데이터 필드 정보를 사용하여 쿼리 생성기 프롬프트를 가져옵니다.\n",
    "prompt = get_query_constructor_prompt(\n",
    "    \"Brief summary of a cosmetic product\",  # 문서 내용 설명\n",
    "    metadata_field_info,  # 메타데이터 필드 정보\n",
    ")\n",
    "\n",
    "# StructuredQueryOutputParser 를 생성\n",
    "output_parser = StructuredQueryOutputParser.from_components()\n",
    "\n",
    "# query_constructor chain 을 생성\n",
    "query_constructor = prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_output = query_constructor.invoke(\n",
    "    {\n",
    "        # 쿼리 생성기를 호출하여 주어진 질문에 대한 쿼리를 생성합니다.\n",
    "        \"query\": \"2023년도에 출시한 상품 중 평점이 4.5 이상인 상품중에서 스킨케어 제품을 추천해주세요\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='year', value=2023),\n",
       " Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='user_rating', value=4.5),\n",
       " Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='category', value='스킨케어')]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쿼리 출력\n",
    "query_output.filter.arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "retriever = SelfQueryRetriever(\n",
    "    query_constructor=query_constructor,  # 이전에 생성한 query_constructor chain 을 지정\n",
    "    vectorstore=vectorstore,  # 벡터 저장소를 지정\n",
    "    structured_query_translator=ChromaTranslator(),  # 쿼리 변환기\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b8fe4498-a119-4c7f-a3b9-6ff1a7567df4', metadata={'category': '스킨케어', 'user_rating': 4.6, 'year': 2023}, page_content='비타민 C 함유 브라이트닝 크림, 칙칙한 피부톤을 환하게 밝혀줍니다.'),\n",
       " Document(id='a6d22820-2ecf-4685-a7ac-ed28a8e9a458', metadata={'category': '스킨케어', 'user_rating': 4.7, 'year': 2024}, page_content='수분 가득한 히알루론산 세럼으로 피부 속 깊은 곳까지 수분을 공급합니다.')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\n",
    "    # 질문\n",
    "    \"2023년도에 출시한 상품 중 평점이 4.5 이상인 상품중에서 스킨케어 제품을 추천해주세요\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간 가중 벡터저장소 리트리버(TimeWeightedVectorStoreRetriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import faiss\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 정의합니다.\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터 저장소를 빈 상태로 초기화합니다.\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n",
    "\n",
    "# 시간 가중치가 적용된 벡터 저장소 검색기를 초기화합니다. (여기서는, 낮은 감쇠율을 적용합니다)\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore, decay_rate=0.0000000000000000000000001, k=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b3285e22-9566-44b8-8a48-9a5be9ec5cbe']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어제 날짜를 계산합니다.\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "retriever.add_documents(\n",
    "    # 문서를 추가하고, metadata에 어제 날짜를 설정합니다.\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"테디노트 구독해 주세요.\",\n",
    "            metadata={\"last_accessed_at\": yesterday},\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 다른 문서를 추가합니다. metadata는 별도로 설정하지 않았습니다.\n",
    "retriever.add_documents([Document(page_content=\"테디노트 구독 해주실꺼죠? Please!\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'last_accessed_at': datetime.datetime(2025, 8, 18, 10, 33, 7, 13686), 'created_at': datetime.datetime(2025, 8, 18, 10, 33, 5, 964215), 'buffer_idx': 0}, page_content='테디노트 구독해 주세요.')]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"테디노트 구독해 주세요.\" 가 가장 먼저 반환되는 이유는 가장 두드러지기 때문이며\n",
    "# 감쇠율이 0에 가깝기 때문에 여전히 최신 상태를 유지하고 있음을 의미합니다.\n",
    "retriever.invoke(\"테디노트\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델을 정의합니다.\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 벡터 저장소를 빈 상태로 초기화합니다.\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n",
    "\n",
    "# 시간 가중치가 적용된 벡터 저장소 검색기를 초기화합니다.\n",
    "retriever = TimeWeightedVectorStoreRetriever(\n",
    "    vectorstore=vectorstore, decay_rate=0.999, k=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eaea5e47-03b2-4f49-8041-61c522dbeda9']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어제 날짜를 계산합니다.\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "retriever.add_documents(\n",
    "    # 문서를 추가하고, metadata에 어제 날짜를 설정합니다.\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"테디노트 구독해 주세요.\",\n",
    "            metadata={\"last_accessed_at\": yesterday},\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 다른 문서를 추가합니다. metadata는 별도로 설정하지 않았습니다.\n",
    "retriever.add_documents([Document(page_content=\"테디노트 구독 해주실꺼죠? Please!\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'last_accessed_at': datetime.datetime(2025, 8, 18, 10, 33, 8, 979026), 'created_at': datetime.datetime(2025, 8, 18, 10, 33, 8, 302131), 'buffer_idx': 1}, page_content='테디노트 구독 해주실꺼죠? Please!')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 후 결과확인\n",
    "retriever.invoke(\"테디노트\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-18 10:33:10.038295\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "from langchain.utils import mock_now\n",
    "\n",
    "# 현재 시간을 특정 시점으로 설정\n",
    "mock_now(datetime.datetime(2025, 8, 17, 00, 00))\n",
    "\n",
    "# 현재 시간 출력\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'last_accessed_at': MockDateTime(2025, 8, 19, 0, 0), 'created_at': datetime.datetime(2025, 8, 18, 10, 33, 7, 841742), 'buffer_idx': 0}, page_content='테디노트 구독해 주세요.')]\n"
     ]
    }
   ],
   "source": [
    "# 현재 시간을 임의의 시간으로 변경합니다.\n",
    "with mock_now(datetime.datetime(2025, 8, 19, 00, 00)):\n",
    "    # 변경된 시점에서 문서를 검색합니다.\n",
    "    print(retriever.invoke(\"테디노트\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        if \"score\" in doc.metadata:\n",
    "            print(f\"[{i+1}] {doc.page_content} ({doc.metadata['score']:.4f})\")\n",
    "        else:\n",
    "            print(f\"[{i+1}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kiwipiepy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (0.20.4)\n",
      "Collecting kiwipiepy\n",
      "  Downloading kiwipiepy-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: konlpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-teddynote in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (0.3.45)\n",
      "Collecting langchain-teddynote\n",
      "  Downloading langchain_teddynote-0.4.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting kiwipiepy-model<0.22,>=0.21 (from kiwipiepy)\n",
      "  Downloading kiwipiepy_model-0.21.0.tar.gz (35.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from kiwipiepy) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from kiwipiepy) (2.3.2)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from konlpy) (5.3.1)\n",
      "Collecting anthropic>=0.64.0 (from langchain-teddynote)\n",
      "  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting deepl>=1.22.0 (from langchain-teddynote)\n",
      "  Downloading deepl-1.22.0-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: feedparser>=6.0.11 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (6.0.11)\n",
      "Requirement already satisfied: langchain-openai>=0.3.30 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.3.30)\n",
      "Requirement already satisfied: langchain>=0.3.27 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.3.27)\n",
      "Collecting langgraph>=0.6.5 (from langchain-teddynote)\n",
      "  Downloading langgraph-0.6.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: olefile>=0.47 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: openai>=1.99.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (1.99.9)\n",
      "Collecting pandas>=2.3.1 (from langchain-teddynote)\n",
      "  Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: pdf2image>=1.17.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (1.17.0)\n",
      "Collecting pinecone-client>=6.0.0 (from langchain-teddynote)\n",
      "  Using cached pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pinecone-text>=0.11.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.11.0)\n",
      "Collecting python-dotenv>=1.1.1 (from langchain-teddynote)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: rank-bm25>=0.2.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: tavily-python>=0.7.10 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-teddynote) (0.7.10)\n",
      "Collecting twine>=6.1.0 (from langchain-teddynote)\n",
      "  Using cached twine-6.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anthropic>=0.64.0->langchain-teddynote) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic>=0.64.0->langchain-teddynote) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic>=0.64.0->langchain-teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic>=0.64.0->langchain-teddynote) (2.27.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from deepl>=1.22.0->langchain-teddynote) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl>=1.22.0->langchain-teddynote) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from requests<3,>=2->deepl>=1.22.0->langchain-teddynote) (2.5.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from feedparser>=6.0.11->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain>=0.3.27->langchain-teddynote) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain>=0.3.27->langchain-teddynote) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain>=0.3.27->langchain-teddynote) (0.4.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain>=0.3.27->langchain-teddynote) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain>=0.3.27->langchain-teddynote) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (3.0.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langchain-openai>=0.3.30->langchain-teddynote) (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.30->langchain-teddynote) (2025.7.34)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph>=0.6.5->langchain-teddynote) (2.1.1)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph>=0.6.5->langchain-teddynote)\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph>=0.6.5->langchain-teddynote)\n",
      "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph>=0.6.5->langchain-teddynote) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph>=0.6.5->langchain-teddynote) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph>=0.6.5->langchain-teddynote) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain>=0.3.27->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain>=0.3.27->langchain-teddynote) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas>=2.3.1->langchain-teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas>=2.3.1->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pandas>=2.3.1->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdf2image>=1.17.0->langchain-teddynote) (11.3.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-client>=6.0.0->langchain-teddynote) (0.0.7)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (2.32.4.20250809)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.11.0->langchain-teddynote) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.11.0->langchain-teddynote) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.3.1->langchain-teddynote) (1.17.0)\n",
      "Collecting readme-renderer>=35.0 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting keyring>=15.1 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting rfc3986>=1.4.0 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from twine>=6.1.0->langchain-teddynote) (14.1.0)\n",
      "Collecting id (from twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: importlib_metadata>=4.11.4 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from keyring>=15.1->twine>=6.1.0->langchain-teddynote) (8.4.0)\n",
      "Collecting jaraco.classes (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.functools (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading jaraco_functools-4.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jaraco.context (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from importlib_metadata>=4.11.4->keyring>=15.1->twine>=6.1.0->langchain-teddynote) (3.23.0)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading nh3-0.3.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (2.0 kB)\n",
      "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading docutils-0.22-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from rich>=12.0.0->twine>=6.1.0->langchain-teddynote) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine>=6.1.0->langchain-teddynote) (0.1.2)\n",
      "Collecting more-itertools (from jaraco.classes->keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting backports.tarfile (from jaraco.context->keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading kiwipiepy-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_teddynote-0.4.4-py3-none-any.whl (59 kB)\n",
      "Downloading anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
      "Downloading deepl-1.22.0-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph-0.6.5-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached twine-6.1.0-py3-none-any.whl (40 kB)\n",
      "Using cached keyring-25.6.0-py3-none-any.whl (39 kB)\n",
      "Using cached readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
      "Downloading docutils-0.22-py3-none-any.whl (630 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.7/630.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nh3-0.3.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Using cached id-1.5.0-py3-none-any.whl (13 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading jaraco_functools-4.2.1-py3-none-any.whl (10 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: kiwipiepy-model\n",
      "\u001b[33m  DEPRECATION: Building 'kiwipiepy-model' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kiwipiepy-model'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for kiwipiepy-model (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kiwipiepy-model: filename=kiwipiepy_model-0.21.0-py3-none-any.whl size=35593240 sha256=07f2c2675f38b92dfdead976d471df2df2eb93912c8b04c9c68e3681ebc2065d\n",
      "  Stored in directory: /Users/mypsyche/Library/Caches/pip/wheels/b0/16/3d/95053ab5298f0f0f22ffea6de0200b6f24bffb73cab4c1a828\n",
      "Successfully built kiwipiepy-model\n",
      "Installing collected packages: kiwipiepy-model, rfc3986, python-dotenv, nh3, more-itertools, kiwipiepy, docutils, backports.tarfile, readme-renderer, pinecone-client, pandas, jaraco.functools, jaraco.context, jaraco.classes, id, deepl, langgraph-sdk, keyring, anthropic, twine, langgraph-prebuilt, langgraph, langchain-teddynote\n",
      "\u001b[2K  Attempting uninstall: kiwipiepy-model\n",
      "\u001b[2K    Found existing installation: kiwipiepy_model 0.20.0\n",
      "\u001b[2K    Uninstalling kiwipiepy_model-0.20.0:\n",
      "\u001b[2K      Successfully uninstalled kiwipiepy_model-0.20.0\n",
      "\u001b[2K  Attempting uninstall: python-dotenv━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K    Found existing installation: python-dotenv 1.0.10m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K    Uninstalling python-dotenv-1.0.1:━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K      Successfully uninstalled python-dotenv-1.0.1\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K  Attempting uninstall: kiwipiepy━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K    Found existing installation: kiwipiepy 0.20.4━\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K    Uninstalling kiwipiepy-0.20.4:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [kiwipiepy-model]\n",
      "\u001b[2K      Successfully uninstalled kiwipiepy-0.20.4114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [kiwipiepy]\n",
      "\u001b[2K  Attempting uninstall: pinecone-client;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]wipiepy]\n",
      "\u001b[2K    Found existing installation: pinecone-client 3.2.2237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K    Uninstalling pinecone-client-3.2.2:37m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K      Successfully uninstalled pinecone-client-3.2.25;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K  Attempting uninstall: pandasm\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.30m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K    Uninstalling pandas-2.2.3:m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [docutils]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.3[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: deepl━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Found existing installation: deepl 1.21.138;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Uninstalling deepl-1.21.1:━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K      Successfully uninstalled deepl-1.21.1\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K  Attempting uninstall: langgraph-sdk━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Found existing installation: langgraph-sdk 0.1.74;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Uninstalling langgraph-sdk-0.1.74:━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K      Successfully uninstalled langgraph-sdk-0.1.7449;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K  Attempting uninstall: anthropic━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Found existing installation: anthropic 0.62.0;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K    Uninstalling anthropic-0.62.0:━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K      Successfully uninstalled anthropic-0.62.0;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/23\u001b[0m [jaraco.classes]\n",
      "\u001b[2K  Attempting uninstall: langgraph-prebuilt━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]classes]\n",
      "\u001b[2K    Found existing installation: langgraph-prebuilt 0.1.85;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K    Uninstalling langgraph-prebuilt-0.1.8:━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K      Successfully uninstalled langgraph-prebuilt-0.1.88;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K  Attempting uninstall: langgraph━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K    Found existing installation: langgraph 0.3.18[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K    Uninstalling langgraph-0.3.18:━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K      Successfully uninstalled langgraph-0.3.18━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [anthropic]\n",
      "\u001b[2K  Attempting uninstall: langchain-teddynote━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m21/23\u001b[0m [langgraph]\n",
      "\u001b[2K    Found existing installation: langchain-teddynote 0.3.4538;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m21/23\u001b[0m [langgraph]\n",
      "\u001b[2K    Uninstalling langchain-teddynote-0.3.45:━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m21/23\u001b[0m [langgraph]\n",
      "\u001b[2K      Successfully uninstalled langchain-teddynote-0.3.45\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m21/23\u001b[0m [langgraph]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [langchain-teddynote]2m21/23\u001b[0m [langgraph]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anthropic-0.64.0 backports.tarfile-1.2.0 deepl-1.22.0 docutils-0.22 id-1.5.0 jaraco.classes-3.4.0 jaraco.context-6.0.1 jaraco.functools-4.2.1 keyring-25.6.0 kiwipiepy-0.21.0 kiwipiepy-model-0.21.0 langchain-teddynote-0.4.4 langgraph-0.6.5 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 more-itertools-10.7.0 nh3-0.3.0 pandas-2.3.1 pinecone-client-6.0.0 python-dotenv-1.1.1 readme-renderer-44.0 rfc3986-2.0.0 twine-6.1.0\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install -U kiwipiepy konlpy langchain-teddynote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비교를 위한 BM25Retriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# 커스텀 구현한 한국어 형태소 분석기(Kiwi)를 사용한 BM25Retriever\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "\n",
    "sample_texts = [\n",
    "    \"금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\",\n",
    "    \"금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\",\n",
    "    \"금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\",\n",
    "    \"금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리트리버를 생성합니다.\n",
    "kiwi = KiwiBM25Retriever.from_texts(sample_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n",
      "[2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다.\n",
      "[3] 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\n",
      "[4] 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요.\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "pretty_print(kiwi.invoke(\"금융보험\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다. (0.2673)\n",
      "[2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다. (0.2616)\n",
      "[3] 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다. (0.2463)\n",
      "[4] 금융보씨 험한말 좀 하지마시고, 저축이나 좀 하시던가요. 뭐가 그리 급하신지 모르겠네요. (0.2248)\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "pretty_print(kiwi.search_with_score(\"금융보험\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiwi:  \t 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다.\n",
      "BM25:  \t 금융단폭격보험은 저축은 커녕 위험 대비에 초점을 맞춘 상품입니다. 높은 위험을 감수하고자 하는 고객에게 적합합니다.\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25Retriever.from_texts(sample_texts)\n",
    "\n",
    "# BM25 KiwiBM25 비교\n",
    "print(f'Kiwi:  \\t {kiwi.invoke(\"금융보험\")[0].page_content}')\n",
    "print(f'BM25:  \\t {bm25.invoke(\"금융보험\")[0].page_content}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 금융보험은 장기적인 자산 관리와 위험 대비를 목적으로 고안된 금융 상품입니다. (0.2673)\n",
      "[2] 금융저축산물보험은 장기적인 저축 목적과 더불어, 축산물 제공 기능을 갖추고 있는 특별 금융 상품입니다. (0.2616)\n"
     ]
    }
   ],
   "source": [
    "# 리트리버를 생성합니다.\n",
    "kiwi = KiwiBM25Retriever.from_texts(sample_texts)\n",
    "kiwi.k = 2\n",
    "# 유사도 검색을 수행합니다.\n",
    "pretty_print(kiwi.search_with_score(\"금융보험\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'KkmaBM25Retriever' from 'langchain_teddynote.retrievers' (/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_teddynote/retrievers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 커스텀 구현한 한국어 형태소 분석기를 사용한 BM25Retriever\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_teddynote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     KkmaBM25Retriever,\n\u001b[32m      4\u001b[39m     OktBM25Retriever,\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'KkmaBM25Retriever' from 'langchain_teddynote.retrievers' (/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_teddynote/retrievers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# 커스텀 구현한 한국어 형태소 분석기를 사용한 BM25Retriever\n",
    "from langchain_teddynote.retrievers import (\n",
    "    KkmaBM25Retriever,\n",
    "    OktBM25Retriever,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Retriever가 없어졌습니다\n",
    "https://github.com/teddylee777/langchain-teddynote/tree/main/langchain_teddynote/retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pdfplumber 0.11.7\n",
      "Uninstalling pdfplumber-0.11.7:\n",
      "  Successfully uninstalled pdfplumber-0.11.7\n",
      "Found existing installation: pdfminer.six 20250506\n",
      "Uninstalling pdfminer.six-20250506:\n",
      "  Successfully uninstalled pdfminer.six-20250506\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y pdfplumber pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber==0.10.3\n",
      "  Downloading pdfplumber-0.10.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pdfminer.six==20221105 (from pdfplumber==0.10.3)\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfplumber==0.10.3) (11.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfplumber==0.10.3) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six==20221105->pdfplumber==0.10.3) (3.4.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six==20221105->pdfplumber==0.10.3) (45.0.6)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.10.3) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber==0.10.3) (2.22)\n",
      "Downloading pdfplumber-0.10.3-py3-none-any.whl (48 kB)\n",
      "Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pdfminer.six, pdfplumber\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pdfplumber]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pdfminer.six-20221105 pdfplumber-0.10.3\n",
      "Requirement already satisfied: pdfminer.six==20221105 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (20221105)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six==20221105) (3.4.3)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from pdfminer.six==20221105) (45.0.6)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/LangChain/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20221105) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber==0.10.3\n",
    "!pip install pdfminer.six==20221105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "pdfplumber package not found, please install it with `pip install pdfplumber`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:1022\u001b[39m, in \u001b[36mPDFPlumberLoader.__init__\u001b[39m\u001b[34m(self, file_path, text_kwargs, dedupe, headers, extract_images)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfplumber\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/pdfplumber/__init__.py:15\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDF\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrepair\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m repair\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/pdfplumber/pdf.py:17\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Container\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Page\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrepair\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _repair\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/pdfplumber/page.py:25\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     LTChar,\n\u001b[32m     19\u001b[39m     LTComponent,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     LTTextContainer,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfinterp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPageInterpreter, PDFStackT\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPage\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PDFStackT' from 'pdfminer.pdfinterp' (/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/pdfminer/pdfinterp.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[157]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_teddynote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KiwiBM25Retriever\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 문서 로드(Load Documents)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m loader = \u001b[43mPDFPlumberLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./디지털정부혁신 추진계획.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 문서 분할(Split Documents): 테스트를 위하여 작은 Chunk Size로 설정\u001b[39;00m\n\u001b[32m     12\u001b[39m text_splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m100\u001b[39m, chunk_overlap=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:1024\u001b[39m, in \u001b[36mPDFPlumberLoader.__init__\u001b[39m\u001b[34m(self, file_path, text_kwargs, dedupe, headers, extract_images)\u001b[39m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfplumber\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpdfplumber package not found, please install it with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`pip install pdfplumber`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1027\u001b[39m     )\n\u001b[32m   1029\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(file_path, headers=headers)\n\u001b[32m   1030\u001b[39m \u001b[38;5;28mself\u001b[39m.text_kwargs = text_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[31mImportError\u001b[39m: pdfplumber package not found, please install it with `pip install pdfplumber`"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever as OriginalEnsembleRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_teddynote.retrievers import KiwiBM25Retriever\n",
    "\n",
    "# 문서 로드(Load Documents)\n",
    "loader = PDFPlumberLoader(\"./디지털정부혁신 추진계획.pdf\")\n",
    "\n",
    "# 문서 분할(Split Documents): 테스트를 위하여 작은 Chunk Size로 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "split_documents = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 임베딩(Embedding) 생성\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# FaissRetriever 생성\n",
    "faiss = FAISS.from_documents(\n",
    "    documents=split_documents, embedding=embeddings\n",
    ").as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# KiwiBM25Retriever 생성(한글 형태소 분석기 + BM25 알고리즘)\n",
    "bm25 = KiwiBM25Retriever.from_documents(documents=split_documents, embedding=embeddings)\n",
    "bm25.k = 5\n",
    "\n",
    "# LangChain 버전의 EnsembleRetriever\n",
    "original_ensemble_retriever = OriginalEnsembleRetriever(retrievers=[faiss, bm25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdfplumber 버전 호환성 문제로 실습을 완료하지 못했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM//8UhCpxyR8kxJ6c/BF+V",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
