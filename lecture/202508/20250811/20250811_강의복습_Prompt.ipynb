{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHjzPvyRefj3",
    "outputId": "6a95054f-2b46-425d-f493-d94e0af0927f"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"API Key:\", os.getenv(\"LANGCHAIN_API_KEY\"))\n",
    "print(\"LANGCHAIN_TRACING_V2:\", os.getenv(\"LANGCHAIN_TRACING_V2\"))\n",
    "print(\"LANGCHAIN_ENDPOINT:\", os.getenv(\"LANGCHAIN_ENDPOINT\"))\n",
    "print(\"LANGCHAIN_PROJECT:\", os.getenv(\"LANGCHAIN_PROJECT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mypsyche/Downloads/20250811\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oJWRnk7DRWsm"
   },
   "outputs": [],
   "source": [
    "def get_langchain():\n",
    "  with open('20250812_LangChain_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai():\n",
    "  with open('20250723_OpenAI_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_name = 'CH02_PROMPT'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = get_langchain()\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = get_langchain()\n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_TRACING_V2=true\n",
      "LANGCHAIN_API_KEY=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\n",
      "LANGCHAIN_PROJECT=CH02_PROMPT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/mypsyche/Downloads/20250811/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH02_PROMPT\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의. {country}는 변수로, 이후에 값이 들어갈 자리를 의미\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인도네시아의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성. format 메소드를 이용하여 변수에 값을 넣어줌\n",
    "prompt = prompt.format(country=\"인도네시아\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# chain 생성\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미얀마의 수도는 나피도르입니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# country 변수에 입력된 값이 자동으로 치환되어 수행됨\n",
    "chain.invoke(\"미얀마\").content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# PromptTemplate 객체를 활용하여 prompt_template 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'적도기니의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt.format(country=\"적도기니\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': '미국'}, template='{country1}과 {country2}의 수도는 각각 어디인가요?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country1}과 {country2}의 수도는 각각 어디인가요?\"\n",
    "\n",
    "# PromptTemplate 객체를 활용하여 prompt_template 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"미국\"  # dictionary 형태로 partial_variables를 전달\n",
    "    },\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우간다과 미국의 수도는 각각 어디인가요?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country1=\"우간다\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': '록셈브루크'}, template='{country1}과 {country2}의 수도는 각각 어디인가요?')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(country2=\"록셈브루크\")\n",
    "prompt_partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'남아프리카공화국과 록셈브루크의 수도는 각각 어디인가요?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.format(country1=\"남아프리카공화국\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_partial | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'크로아티아의 수도는 자그레브이며, 록셈부르크의 수도는 록셈부르크 시티입니다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"크로아티아\").content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'베트남의 수도는 하노이이고, 베넹의 수도는 자카르타입니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country1\": \"베트남\", \"country2\": \"베넹\"}).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'August 12'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 오늘 날짜를 출력\n",
    "datetime.now().strftime(\"%B %d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 반환하는 함수 정의\n",
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요. 생년월일을 표기해주세요.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\": get_today  # dictionary 형태로 partial_variables를 전달\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘의 날짜는 August 12 입니다. 오늘이 생일인 유명인 3명을 나열해 주세요. 생년월일을 표기해주세요.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt.format(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 생성합니다.\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 영화 배우 박보검 (1993년 6월 16일)\n",
      "2. 뮤지션 포터 로빈슨 (1992년 8월 12일)\n",
      "3. 배우 사이먼 센베크 (1973년 8월 12일)\n"
     ]
    }
   ],
   "source": [
    "# chain 을 실행 후 결과를 확인합니다.\n",
    "print(chain.invoke(3).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. KIM JONG KOOK - 1976년 4월 25일\n",
      "2. KATE BOSWORTH - 1983년 1월 2일\n",
      "3. TAYE DIGGS - 1971년 1월 2일\n"
     ]
    }
   ],
   "source": [
    "# chain 을 실행 후 결과를 확인합니다.\n",
    "print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], input_types={}, partial_variables={}, template='{fruit}의 색깔이 뭐야?')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./20250811_prompts_fruit_color.yaml\", encoding=\"UTF-8\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사과의 색깔이 뭐야?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(fruit=\"사과\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그리스의 수도에 대해서 알려주세요.\n",
      "수도의 특징을 다음의 양식에 맞게 정리해 주세요.\n",
      "300자 내외로 작성해 주세요.\n",
      "한글로 작성해 주세요.\n",
      "----\n",
      "[양식]\n",
      "1. 면적\n",
      "2. 인구\n",
      "3. 역사적 장소\n",
      "4. 특산품\n",
      "\n",
      "#Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"./20250811_prompts_capital.yaml\")\n",
    "print(prompt2.format(country=\"그리스\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"{country}의 수도는 어디인가요?\")\n",
    "chat_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(country=\"대한민국\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 테디 입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='반가워요!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='당신의 이름은 무엇입니까?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name} 입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 챗 message 를 생성합니다.\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"테디\", user_input=\"당신의 이름은 무엇입니까?\"\n",
    ")\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 테디입니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제 이름은 Teddy입니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\": \"Teddy\", \"user_input\": \"당신의 이름은 무엇입니까?\"}).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113ad8400>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='지금까지의 대화를 {word_count} 단어로 요약합니다.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약합니다.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\n",
      "Human: 안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\n",
      "AI: 반가워요! 앞으로 잘 부탁 드립니다.\n",
      "Human: 지금까지의 대화를 5 단어로 요약합니다.\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = chat_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신입사원 테디의 인사 및 환영.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 실행 및 결과확인\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,\n",
    "        \"conversation\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"안녕하세요! 저는 오늘 새로 입사한 테디 입니다. 만나서 반갑습니다.\",\n",
    "            ),\n",
    "            (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다.\"),\n",
    "        ],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울입니다."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성\n",
    "    model_name=\"gpt-4-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "\n",
    "# 질의\n",
    "answer = llm.stream(question)\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
    "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
    "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
    "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
    "최종 답변은: 아인슈타인\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"네이버의 창립자는 언제 태어났나요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 네이버의 창립자는 누구인가요?\n",
    "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
    "추가 질문: 이해진은 언제 태어났나요?\n",
    "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
    "최종 답변은: 1967년 6월 22일\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
    "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
    "추가 질문: 신사임당은 언제 태어났나요?\n",
    "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
    "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
    "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
    "최종 답변은: 연산군\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"올드보이와 기생충의 감독이 같은 나라 출신인가요?\",\n",
    "        \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n",
    "추가 질문: 올드보이의 감독은 누구인가요?\n",
    "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
    "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
    "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
    "추가 질문: 기생충의 감독은 누구인가요?\n",
    "중간 답변: 기생충의 감독은 봉준호입니다.\n",
    "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
    "중간 답변: 봉준호는 대한민국 출신입니다.\n",
    "최종 답변은: 예\n",
    "\"\"\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"Question:\\n{question}\\nAnswer:\\n{answer}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n",
      "중간 답변: 스티브 잡스는 56세에 사망했습니다.\n",
      "추가 질문: 아인슈타인은 몇 살에 사망했나요?\n",
      "중간 답변: 아인슈타인은 76세에 사망했습니다.\n",
      "최종 답변은: 아인슈타인\n",
      "\n",
      "\n",
      "Question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n",
      "\n",
      "Question:\n",
      "율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 율곡 이이의 어머니는 누구인가요?\n",
      "중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n",
      "추가 질문: 신사임당은 언제 태어났나요?\n",
      "중간 답변: 신사임당은 1504년에 태어났습니다.\n",
      "추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n",
      "중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n",
      "최종 답변은: 연산군\n",
      "\n",
      "\n",
      "Question:\n",
      "올드보이와 기생충의 감독이 같은 나라 출신인가요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 올드보이의 감독은 누구인가요?\n",
      "중간 답변: 올드보이의 감독은 박찬욱입니다.\n",
      "추가 질문: 박찬욱은 어느 나라 출신인가요?\n",
      "중간 답변: 박찬욱은 대한민국 출신입니다.\n",
      "추가 질문: 기생충의 감독은 누구인가요?\n",
      "중간 답변: 기생충의 감독은 봉준호입니다.\n",
      "추가 질문: 봉준호는 어느 나라 출신인가요?\n",
      "중간 답변: 봉준호는 대한민국 출신입니다.\n",
      "최종 답변은: 예\n",
      "\n",
      "\n",
      "Question:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "final_prompt = prompt.format(question=question)\n",
    "print(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: Google은 언제 창립되었나요?\n",
      "중간 답변: Google은 1998년에 창립되었습니다.\n",
      "추가 질문: Bill Gates는 언제 태어났나요?\n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.\n",
      "최종 답변은: 1998년에 Bill Gates의 나이는 43세입니다."
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "answer = llm.stream(final_prompt)\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력에 가장 유사한 예시:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "\n",
      "question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Vector DB 생성 (저장소 이름, 임베딩 클래스)\n",
    "chroma = Chroma(\"example_selector\", OpenAIEmbeddings())\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 여기에는 선택 가능한 예시 목록이 있습니다.\n",
    "    examples,\n",
    "    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n",
    "    Chroma,\n",
    "    # 이것은 생성할 예시의 수입니다.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# 입력과 가장 유사한 예시를 선택합니다.\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "print(f\"입력에 가장 유사한 예시:\\n{question}\\n\")\n",
    "for example in selected_examples:\n",
    "    print(f'question:\\n{example[\"question\"]}')\n",
    "    print(f'answer:\\n{example[\"answer\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "네이버의 창립자는 언제 태어났나요?\n",
      "Answer:\n",
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: 네이버의 창립자는 누구인가요?\n",
      "중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n",
      "추가 질문: 이해진은 언제 태어났나요?\n",
      "중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n",
      "최종 답변은: 1967년 6월 22일\n",
      "\n",
      "\n",
      "Question:\n",
      "Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question = \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"\n",
    "example_selector_prompt = prompt.format(question=question)\n",
    "print(example_selector_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question:\\n{question}\\nAnswer:\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 질문에 추가 질문이 필요한가요: 예.\n",
      "추가 질문: Google이 창립된 연도는 언제인가요?\n",
      "중간 답변: Google은 1998년에 창립되었습니다.\n",
      "추가 질문: Bill Gates는 언제 태어났나요?\n",
      "중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.\n",
      "최종 답변 계산: 1998년 - 1955년 = 43살\n",
      "최종 답변은: 43살"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "answer = chain.stream(\n",
    "    {\"question\": \"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"}\n",
    ")\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"instruction\": \"당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요\",\n",
    "        \"input\": \"2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.\",\n",
    "        \"answer\": \"\"\"\n",
    "회의록: XYZ 회사 마케팅 전략 회의\n",
    "일시: 2023년 12월 25일\n",
    "장소: XYZ 회사 회의실\n",
    "참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\n",
    "\n",
    "1. 개회\n",
    "   - 회의는 김수진 팀장의 개회사로 시작됨.\n",
    "   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\n",
    "\n",
    "2. 시장 동향 개요 (김수진)\n",
    "   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\n",
    "   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\n",
    "\n",
    "3. 디지털 마케팅 전략 (박지민)\n",
    "   - 박지민은 디지털 마케팅 전략에 대해 발표.\n",
    "   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\n",
    "\n",
    "4. 소셜 미디어 캠페인 (이준호)\n",
    "   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\n",
    "   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\n",
    "\n",
    "5. 종합 논의\n",
    "   - 팀원들 간의 아이디어 공유 및 토론.\n",
    "   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\n",
    "\n",
    "6. 마무리\n",
    "   - 다음 회의 날짜 및 시간 확정.\n",
    "   - 회의록 정리 및 배포는 박지민 담당.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 요약 전문가 입니다. 다음 주어진 정보를 바탕으로 내용을 요약해 주세요\",\n",
    "        \"input\": \"이 문서는 '지속 가능한 도시 개발을 위한 전략'에 대한 20페이지 분량의 보고서입니다. 보고서는 지속 가능한 도시 개발의 중요성, 현재 도시화의 문제점, 그리고 도시 개발을 지속 가능하게 만들기 위한 다양한 전략을 포괄적으로 다루고 있습니다. 이 보고서는 또한 성공적인 지속 가능한 도시 개발 사례를 여러 국가에서 소개하고, 이러한 사례들을 통해 얻은 교훈을 요약하고 있습니다.\",\n",
    "        \"answer\": \"\"\"\n",
    "문서 요약: 지속 가능한 도시 개발을 위한 전략 보고서\n",
    "\n",
    "- 중요성: 지속 가능한 도시 개발이 필수적인 이유와 그에 따른 사회적, 경제적, 환경적 이익을 강조.\n",
    "- 현 문제점: 현재의 도시화 과정에서 발생하는 주요 문제점들, 예를 들어 환경 오염, 자원 고갈, 불평등 증가 등을 분석.\n",
    "- 전략: 지속 가능한 도시 개발을 달성하기 위한 다양한 전략 제시. 이에는 친환경 건축, 대중교통 개선, 에너지 효율성 증대, 지역사회 참여 강화 등이 포함됨.\n",
    "- 사례 연구: 전 세계 여러 도시의 성공적인 지속 가능한 개발 사례를 소개. 예를 들어, 덴마크의 코펜하겐, 일본의 요코하마 등의 사례를 통해 실현 가능한 전략들을 설명.\n",
    "- 교훈: 이러한 사례들에서 얻은 주요 교훈을 요약. 강조된 교훈에는 다각적 접근의 중요성, 지역사회와의 협력, 장기적 계획의 필요성 등이 포함됨.\n",
    "\n",
    "이 보고서는 지속 가능한 도시 개발이 어떻게 현실적이고 효과적인 형태로 이루어질 수 있는지에 대한 심도 있는 분석을 제공합니다.\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요\",\n",
    "        \"input\": \"우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.\",\n",
    "        \"answer\": \"본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma = Chroma(\"fewshot_chat\", OpenAIEmbeddings())\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 여기에는 선택 가능한 예시 목록이 있습니다.\n",
    "    examples,\n",
    "    # 여기에는 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스가 있습니다.\n",
    "    OpenAIEmbeddings(),\n",
    "    # 여기에는 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스가 있습니다.\n",
    "    chroma,\n",
    "    # 이것은 생성할 예시의 수입니다.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '\\n회의록: XYZ 회사 마케팅 전략 회의\\n일시: 2023년 12월 25일\\n장소: XYZ 회사 회의실\\n참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\\n\\n1. 개회\\n   - 회의는 김수진 팀장의 개회사로 시작됨.\\n   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\\n\\n2. 시장 동향 개요 (김수진)\\n   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\\n   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\\n\\n3. 디지털 마케팅 전략 (박지민)\\n   - 박지민은 디지털 마케팅 전략에 대해 발표.\\n   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\\n\\n4. 소셜 미디어 캠페인 (이준호)\\n   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\\n   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\\n\\n5. 종합 논의\\n   - 팀원들 간의 아이디어 공유 및 토론.\\n   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\\n\\n6. 마무리\\n   - 다음 회의 날짜 및 시간 확정.\\n   - 회의록 정리 및 배포는 박지민 담당.\\n',\n",
       "  'input': '2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.',\n",
       "  'instruction': '당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "\n",
    "example_selector.select_examples(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{instruction}\\n{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의록: ABC 기술 회사 제품 개발 팀 주간 진행 상황 회의\n",
      "일시: 2023년 12월 26일\n",
      "장소: ABC 기술 회사 회의실\n",
      "참석자: 최현수 (프로젝트 매니저), 황지연 (주요 개발자), 김태영 (UI/UX 디자이너)\n",
      "\n",
      "1. 개회\n",
      "   - 최현수 프로젝트 매니저가 회의를 개회하고, 회의의 목적을 설명함.\n",
      "   - 목적: 프로젝트의 현재 진행 상황 검토 및 다가오는 마일스톤에 대한 계획 수립.\n",
      "\n",
      "2. 프로젝트 진행 상황 보고\n",
      "   - 황지연 개발자가 개발 진행 상황에 대해 보고.\n",
      "     - 현재 개발 중인 기능들의 상태와 최근 해결된 문제점들에 대해 설명.\n",
      "     - 다음 주까지 완료 목표로 설정된 기능들을 공유.\n",
      "   - 김태영 디자이너가 UI/UX 디자인 진행 상황에 대해 보고.\n",
      "     - 최근 완성된 디자인 요소들과 사용자 피드백을 바탕으로 한 개선 사항들을 공유.\n",
      "     - 다음 단계의 디자인 작업 계획을 발표.\n",
      "\n",
      "3. 마일스톤 계획 논의\n",
      "   - 최현수가 다가오는 마일스톤에 대한 전체적인 계획을 제시.\n",
      "   - 팀원들과 함께 다음 주까지의 구체적인 목표와 업무 분담에 대해 논의.\n",
      "\n",
      "4. 문제점 및 해결 방안 논의\n",
      "   - 팀원들이 현재 직면한 문제점들을 공유하고, 해결 방안에 대해 토론.\n",
      "   - 필요한 자원과 지원에 대해 논의.\n",
      "\n",
      "5. 다음 회의 일정 및 기타 사항\n",
      "   - 다음 주간 진행 상황 회의 일정을 확정.\n",
      "   - 기타 필요한 사항들에 대해 논의.\n",
      "\n",
      "6. 마무리\n",
      "   - 최현수 매니저가 회의를 마무리하며, 각자의 업무에 최선을 다할 것을 당부.\n",
      "\n",
      "회의록 작성자: 최현수\n",
      "회의록 승인: 최현수 (프로젝트 매니저)"
     ]
    }
   ],
   "source": [
    "# chain 생성\n",
    "chain = final_prompt | llm\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "answer = chain.stream(question)\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Selector 의 유사도 검색 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.',\n",
       "  'input': '우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.',\n",
       "  'instruction': '당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "}\n",
    "\n",
    "example_selector.select_examples(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': '본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.',\n",
       "  'input': '우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.',\n",
       "  'instruction': '당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 커스텀 하지 않은 기본 예제 선택기를 사용했을 때 결과\n",
    "example_selector.select_examples({\"instruction\": \"다음 문장을 요약해 주세요\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': '당신은 문장 교정 전문가 입니다. 다음 주어진 문장을 교정해 주세요',\n",
       "  'input': '우리 회사는 새로운 마케팅 전략을 도입하려고 한다. 이를 통해 고객과의 소통이 더 효과적이 될 것이다.',\n",
       "  'answer': '본 회사는 새로운 마케팅 전략을 도입함으로써, 고객과의 소통을 보다 효과적으로 개선할 수 있을 것으로 기대된다.'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.prompts import CustomExampleSelector\n",
    "\n",
    "# 커스텀 예제 선택기 생성\n",
    "custom_selector = CustomExampleSelector(examples, OpenAIEmbeddings())\n",
    "\n",
    "# 커스텀 예제 선택기를 사용했을 때 결과\n",
    "custom_selector.select_examples({\"instruction\": \"다음 문장을 교정 작성해 주세요\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{instruction}:\\n{input}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "custom_fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=custom_selector,  # 커스텀 예제 선택기 사용\n",
    "    example_prompt=example_prompt,  # 예제 프롬프트 사용\n",
    ")\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant.\",\n",
    "        ),\n",
    "        custom_fewshot_prompt,\n",
    "        (\"human\", \"{instruction}\\n{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 생성합니다.\n",
    "chain = custom_prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회의록: ABC 기술 회사 제품 개발 팀 주간 진행 상황 회의\n",
      "일시: 2023년 12월 26일\n",
      "장소: ABC 기술 회사 회의실\n",
      "참석자: 최현수 (프로젝트 매니저), 황지연 (주요 개발자), 김태영 (UI/UX 디자이너)\n",
      "\n",
      "1. 개회\n",
      "   - 최현수 프로젝트 매니저가 회의를 개회하고, 회의의 목적을 설명함.\n",
      "   - 목적: 프로젝트의 현재 진행 상황 검토 및 다가오는 마일스톤에 대한 계획 수립.\n",
      "\n",
      "2. 프로젝트 진행 상황 보고\n",
      "   - 황지연 개발자가 개발 진행 상황에 대해 보고.\n",
      "     - 현재 개발 중인 기능들의 상태와 최근 해결된 문제점들을 공유.\n",
      "     - 다음 주까지 완료 목표로 설정된 기능들을 명시.\n",
      "   - 김태영 디자이너가 UI/UX 디자인 진행 상황에 대해 보고.\n",
      "     - 최근 완성된 디자인 요소들과 사용자 피드백을 바탕으로 한 개선 사항들을 공유.\n",
      "     - 다음 단계의 디자인 작업 계획을 설명.\n",
      "\n",
      "3. 마일스톤 계획\n",
      "   - 최현수가 다가오는 마일스톤에 대한 전체적인 계획을 제시.\n",
      "     - 중요 마일스톤의 날짜와 각 팀원이 달성해야 할 주요 목표들을 정리.\n",
      "     - 리소스 배분과 시간 관리에 대한 전략 논의.\n",
      "\n",
      "4. 문제점 및 해결 방안 논의\n",
      "   - 팀원들이 현재 직면한 문제점들을 공유하고, 해결책을 모색.\n",
      "   - 필요한 추가 자원이나 지원에 대해 논의.\n",
      "\n",
      "5. 다음 주 목표 설정\n",
      "   - 각 팀원이 다음 주까지 달성해야 할 구체적인 목표들을 설정.\n",
      "   - 최현수가 목표 달성을 위한 체크포인트와 기대 결과를 명확히 함.\n",
      "\n",
      "6. 마무리\n",
      "   - 다음 회의 날짜 및 시간 확정.\n",
      "   - 회의록 정리 및 배포는 최현수 매니저가 담당.\n",
      "\n",
      "회의는 모든 안건이 충분히 논의되고 목표가 설정된 후 종료됨."
     ]
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"회의록을 작성해 주세요\",\n",
    "    \"input\": \"2023년 12월 26일, ABC 기술 회사의 제품 개발 팀은 새로운 모바일 애플리케이션 프로젝트에 대한 주간 진행 상황 회의를 가졌다. 이 회의에는 프로젝트 매니저인 최현수, 주요 개발자인 황지연, UI/UX 디자이너인 김태영이 참석했다. 회의의 주요 목적은 프로젝트의 현재 진행 상황을 검토하고, 다가오는 마일스톤에 대한 계획을 수립하는 것이었다. 각 팀원은 자신의 작업 영역에 대한 업데이트를 제공했고, 팀은 다음 주까지의 목표를 설정했다.\",\n",
    "}\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "stream_response(chain.stream(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 요약: 2023년 글로벌 경제 전망 보고서\n",
      "\n",
      "- 현재 상태: 세계 경제의 현재 상황에 대한 분석을 제공하며, 경제 회복의 진행 상황과 주요 도전 과제를 설명.\n",
      "- 경제 성장률: 주요 국가들의 경제 성장률을 검토하고, 각 국가의 경제 상황에 대한 상세한 정보를 제공.\n",
      "- 글로벌 무역 동향: 전 세계적인 무역 패턴과 동향을 분석하고, 무역이 경제 성장에 미치는 영향을 평가.\n",
      "- 경제 예측: 2023년도에 대한 경제 예측을 제시하며, 예상되는 성장률과 주요 경제 지표들을 다룸.\n",
      "- 영향 요인 분석: 경제적, 정치적, 환경적 요인들이 세계 경제에 미칠 영향을 심층 분석.\n",
      "\n",
      "이 보고서는 다가오는 해의 글로벌 경제 상황에 대한 포괄적인 이해를 제공하며, 다양한 요인들이 경제에 미치는 복합적인 영향을 평가합니다."
     ]
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"문서를 요약해 주세요\",\n",
    "    \"input\": \"이 문서는 '2023년 글로벌 경제 전망'에 관한 30페이지에 달하는 상세한 보고서입니다. 보고서는 세계 경제의 현재 상태, 주요 국가들의 경제 성장률, 글로벌 무역 동향, 그리고 다가오는 해에 대한 경제 예측을 다룹니다. 이 보고서는 또한 다양한 경제적, 정치적, 환경적 요인들이 세계 경제에 미칠 영향을 분석하고 있습니다.\",\n",
    "}\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "stream_response(chain.stream(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사는 올해 매출이 증가할 것으로 예상하고 있다. 새로운 전략이 효과적으로 작동하고 있기 때문이다."
     ]
    }
   ],
   "source": [
    "question = {\n",
    "    \"instruction\": \"문장을 교정해 주세요\",\n",
    "    \"input\": \"회사는 올해 매출이 증가할 것으로 예상한다. 새로운 전략이 잘 작동하고 있다.\",\n",
    "}\n",
    "\n",
    "# 실행 및 결과 출력\n",
    "stream_response(chain.stream(question))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 가장 최신 버전의 프롬프트를 가져옵니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 내용 출력\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 버전의 프롬프트를 가져오려면 버전 해시를 지정하세요\n",
    "prompt = hub.pull(\"rlm/rag-prompt:50442af1\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\"\n",
    ")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /commits/-/simple-summary-korean_mypsyche98. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/simple-summary-korean_mypsyche98', '{\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"template\":\"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\\\n\\\\nCONTEXT: {context}\\\\n\\\\nSUMMARY:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"78W44S9qY5dPgSWctCiz7rnLrM3/sKEOmKxbi7/p54g=\",\"example_run_ids\":null,\"parent_commit_hash\":\"de93adb6bb86de943383a02bd60acdcaa6a5d6f7876d2901439bbb30a5e90918\",\"repo_id\":\"b045ac85-577b-4c58-b973-458dbb6b972b\",\"parent_id\":\"2e121024-bfee-429f-90b7-a619f5e8efb3\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"김광무\"}}\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/simple-summary-korean_mypsyche98",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:837\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    831\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    832\u001b[39m         method,\n\u001b[32m    833\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    834\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    835\u001b[39m         **request_kwargs,\n\u001b[32m    836\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/simple-summary-korean_mypsyche98] {\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"template\":\"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"78W44S9qY5dPgSWctCiz7rnLrM3/sKEOmKxbi7/p54g=\",\"example_run_ids\":null,\"parent_commit_hash\":\"de93adb6bb86de943383a02bd60acdcaa6a5d6f7876d2901439bbb30a5e90918\",\"repo_id\":\"b045ac85-577b-4c58-b973-458dbb6b972b\",\"parent_id\":\"2e121024-bfee-429f-90b7-a619f5e8efb3\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"김광무\"}}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 프롬프트를 허브에 업로드합니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msimple-summary-korean_mypsyche98\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langchain/hub.py:72\u001b[39m, in \u001b[36mpush\u001b[39m\u001b[34m(repo_full_name, object, api_url, api_key, parent_commit_hash, new_repo_is_public, new_repo_description, readme, tags)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Then it's langsmith\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(client, \u001b[33m\"\u001b[39m\u001b[33mpush_prompt\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpush_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_full_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_public\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_repo_is_public\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_repo_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreadme\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreadme\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Then it's langchainhub\u001b[39;00m\n\u001b[32m     83\u001b[39m manifest_json = dumps(\u001b[38;5;28mobject\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:7410\u001b[39m, in \u001b[36mClient.push_prompt\u001b[39m\u001b[34m(self, prompt_identifier, object, parent_commit_hash, is_public, description, readme, tags)\u001b[39m\n\u001b[32m   7407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_prompt_url(prompt_identifier=prompt_identifier)\n\u001b[32m   7409\u001b[39m \u001b[38;5;66;03m# Create a commit with the new manifest\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m7410\u001b[39m url = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7412\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   7413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparent_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7414\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:7077\u001b[39m, in \u001b[36mClient.create_commit\u001b[39m\u001b[34m(self, prompt_identifier, object, parent_commit_hash)\u001b[39m\n\u001b[32m   7074\u001b[39m     parent_commit_hash = \u001b[38;5;28mself\u001b[39m._get_latest_commit_hash(prompt_owner_and_name)\n\u001b[32m   7076\u001b[39m request_dict = {\u001b[33m\"\u001b[39m\u001b[33mparent_commit\u001b[39m\u001b[33m\"\u001b[39m: parent_commit_hash, \u001b[33m\"\u001b[39m\u001b[33mmanifest\u001b[39m\u001b[33m\"\u001b[39m: manifest_dict}\n\u001b[32m-> \u001b[39m\u001b[32m7077\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7078\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/commits/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_owner_and_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_dict\u001b[49m\n\u001b[32m   7079\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7081\u001b[39m commit_hash = response.json()[\u001b[33m\"\u001b[39m\u001b[33mcommit\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcommit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   7083\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_prompt_url(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_owner_and_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommit_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/LangChain/lib/python3.11/site-packages/langsmith/client.py:882\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    877\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    878\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    879\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     )\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    883\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    884\u001b[39m     )\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    887\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    888\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    889\u001b[39m     )\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for /commits/-/simple-summary-korean_mypsyche98. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/commits/-/simple-summary-korean_mypsyche98', '{\"error\":\"Nothing to commit: prompt has not changed since latest commit\"}\\n{\"commit\":{\"commit_hash\":\"\",\"manifest\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"ChatPromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"messages\":[{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"chat\",\"HumanMessagePromptTemplate\"],\"kwargs\":{\"prompt\":{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"prompts\",\"prompt\",\"PromptTemplate\"],\"kwargs\":{\"input_variables\":[\"context\"],\"template\":\"주어진 내용을 바탕으로 다음 문장을 요약하세요. 답변은 반드시 한글로 작성하세요\\\\n\\\\nCONTEXT: {context}\\\\n\\\\nSUMMARY:\",\"template_format\":\"f-string\"},\"name\":\"PromptTemplate\"}}}]},\"name\":\"ChatPromptTemplate\"},\"id\":\"00000000-0000-0000-0000-000000000000\",\"manifest_sha\":\"78W44S9qY5dPgSWctCiz7rnLrM3/sKEOmKxbi7/p54g=\",\"example_run_ids\":null,\"parent_commit_hash\":\"de93adb6bb86de943383a02bd60acdcaa6a5d6f7876d2901439bbb30a5e90918\",\"repo_id\":\"b045ac85-577b-4c58-b973-458dbb6b972b\",\"parent_id\":\"2e121024-bfee-429f-90b7-a619f5e8efb3\",\"created_at\":\"0001-01-01T00:00:00Z\",\"updated_at\":\"0001-01-01T00:00:00Z\",\"num_downloads\":0,\"num_views\":0,\"full_name\":\"김광무\"}}\\n')"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 프롬프트를 허브에 업로드합니다.\n",
    "hub.push(\"simple-summary-korean_mypsyche98\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 프롬프트를 허브로부터 가져옵니다.\n",
    "pulled_prompt = hub.pull(\"mypsyche98/simple-summary-korean_mypsyche98\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Owner 지정\n",
    "PROMPT_OWNER = \"mypsyche98\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\n{context}\\n\\nSUMMARY:\"\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_title = \"summary-stuff-documents\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt_template = \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "REQUEST:\n",
    "1. Summarize the main points in bullet points.\n",
    "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
    "3. Use various emojis to make the summary more interesting.\n",
    "4. DO NOT include any unnecessary information.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "SUMMARY:\"\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/summary-stuff-documents/ccf1dc3e?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['docs'], input_types={}, partial_variables={}, template='You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\\nPlease provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format. \\nThe summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format. \\nPlease ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition. \\nThe length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\\n\\nGIVEN DOCUMENTS:\\n{docs}\\n\\nFORMAT:\\n1. main theme 1\\n2. main theme 2\\n3. main theme 3\\n...\\n\\nCAUTION:\\n- DO NOT list more than 5 main themes.\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_title = \"map-prompt\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt_template = \"\"\"You are a helpful expert journalist in extracting the main themes from a GIVEN DOCUMENTS below.\n",
    "Please provide a comprehensive summary of the GIVEN DOCUMENTS in numbered list format. \n",
    "The summary should cover all the key points and main ideas presented in the original text, while also condensing the information into a concise and easy-to-understand format. \n",
    "Please ensure that the summary includes relevant details and examples that support the main ideas, while avoiding any unnecessary information or repetition. \n",
    "The length of the summary should be appropriate for the length and complexity of the original text, providing a clear and accurate overview without omitting any important information.\n",
    "\n",
    "GIVEN DOCUMENTS:\n",
    "{docs}\n",
    "\n",
    "FORMAT:\n",
    "1. main theme 1\n",
    "2. main theme 2\n",
    "3. main theme 3\n",
    "...\n",
    "\n",
    "CAUTION:\n",
    "- DO NOT list more than 5 main themes.\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/map-prompt/28669aaf?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['doc_summaries'], input_types={}, partial_variables={}, template='You are a helpful expert in summary writing.\\nYou are given numbered lists of summaries.\\nExtract top 10 most important insights from the summaries.\\nThen, write a summary of the insights in KOREAN.\\n\\nLIST OF SUMMARIES:\\n{doc_summaries}\\n\\nHelpful Answer:\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_title = \"reduce-prompt\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt_template = \"\"\"You are a helpful expert in summary writing.\n",
    "You are given numbered lists of summaries.\n",
    "Extract top 10 most important insights from the summaries.\n",
    "Then, write a summary of the insights in KOREAN.\n",
    "\n",
    "LIST OF SUMMARIES:\n",
    "{doc_summaries}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/reduce-prompt/5c5d853c?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['doc_summaries'], input_types={}, partial_variables={}, template='You are a helpful expert in summary writing. You are given lists of summaries.\\nPlease sum up previously summarized sentences according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points in KOREAN.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. MOST IMPORTANT points should be organized at the top of the list.\\n5. DO NOT include any unnecessary information.\\n\\nLIST OF SUMMARIES:\\n{doc_summaries}\\n\\nHelpful Answer: ')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_title = \"chain-of-density-reduce-korean\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt_template = \"\"\"You are a helpful expert in summary writing. You are given lists of summaries.\n",
    "Please sum up previously summarized sentences according to the following REQUEST.\n",
    "REQUEST:\n",
    "1. Summarize the main points in bullet points in KOREAN.\n",
    "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
    "3. Use various emojis to make the summary more interesting.\n",
    "4. MOST IMPORTANT points should be organized at the top of the list.\n",
    "5. DO NOT include any unnecessary information.\n",
    "\n",
    "LIST OF SUMMARIES:\n",
    "{doc_summaries}\n",
    "\n",
    "Helpful Answer: \"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/chain-of-density-reduce-korean/45d0ab93?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template=\"Given the following product review, conduct a comprehensive analysis to extract key aspects mentioned by the customer, with a focus on evaluating the product's design and distinguishing between positive aspects and areas for improvement. \\nIdentify primary features or attributes of the product that the customer appreciated or highlighted, specifically looking for mentions related to the feel of the keys, sound produced by the keys, overall user experience, charging aspect, and the design of the product, etc. \\nAssess the overall tone of the review (positive, neutral, or negative) based on the sentiment expressed about these attributes. \\nAdditionally, provide a detailed evaluation of the design, outline the positive aspects that the customer enjoyed, and note any areas of improvement or disappointment mentioned. \\nExtract the customer's rating of the product on a scale of 1 to 5, as indicated at the beginning of the review. \\nSummarize your findings in a structured JSON format, including an array of keywords, evaluations for design, satisfaction points, improvement areas, the assessed tone, and the numerical rating. \\n\\nINPUT:\\n{input}\\n\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_title = \"metadata-tagger\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt_template = \"\"\"Given the following product review, conduct a comprehensive analysis to extract key aspects mentioned by the customer, with a focus on evaluating the product's design and distinguishing between positive aspects and areas for improvement. \n",
    "Identify primary features or attributes of the product that the customer appreciated or highlighted, specifically looking for mentions related to the feel of the keys, sound produced by the keys, overall user experience, charging aspect, and the design of the product, etc. \n",
    "Assess the overall tone of the review (positive, neutral, or negative) based on the sentiment expressed about these attributes. \n",
    "Additionally, provide a detailed evaluation of the design, outline the positive aspects that the customer enjoyed, and note any areas of improvement or disappointment mentioned. \n",
    "Extract the customer's rating of the product on a scale of 1 to 5, as indicated at the beginning of the review. \n",
    "Summarize your findings in a structured JSON format, including an array of keywords, evaluations for design, satisfaction points, improvement areas, the assessed tone, and the numerical rating. \n",
    "\n",
    "INPUT:\n",
    "{input}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/metadata-tagger/d5031809?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_title = \"chain-of-density-korean\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 5 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (100 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/chain-of-density-korean/2d444953?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_title = \"chain-of-density-map-korean\"\n",
    "\n",
    "# 요약문을 작성하기 위한 프롬프트 정의 (직접 프롬프트를 작성하는 경우)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Article: {ARTICLE}\n",
    "You will generate increasingly concise, entity-dense summaries of the above article. \n",
    "\n",
    "Repeat the following 2 steps 3 times. \n",
    "\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n",
    "\n",
    "A missing entity is:\n",
    "- relevant to the main story, \n",
    "- specific yet concise (100 words or fewer), \n",
    "- novel (not in the previous summary), \n",
    "- faithful (present in the article), \n",
    "- anywhere (can be located anywhere in the article).\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n",
    "\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer \"Missing Entities\" and \"Denser_Summary\" as in TEXT format.\n",
    "Use only KOREAN language to reply.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/chain-of-density-map-korean/0b372530?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_title = \"rag-prompt-korean\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
    "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\n",
    "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요. Don't narrate the answer, just answer the question. Let's think step-by-step.\"\"\"\n",
    "\n",
    "human = \"\"\"#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/rag-prompt-korean/cbfb554c?organizationId=53db61eb-d386-4c02-9de8-5b28476b0edc'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(f\"{PROMPT_OWNER}/{prompt_title}\", prompt, parent_commit_hash=\"latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMs2OSEsEhI+eP+P38efuYH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
