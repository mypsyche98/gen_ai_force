{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHjzPvyRefj3",
    "outputId": "6a95054f-2b46-425d-f493-d94e0af0927f"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oJWRnk7DRWsm"
   },
   "outputs": [],
   "source": [
    "def get_langchain():\n",
    "  with open('20250812_LangChain_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai():\n",
    "  with open('20250723_OpenAI_API.key', 'r', encoding='utf-8') as file:\n",
    "    return file.readline().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_name = 'CH01_LCEL'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = get_langchain()\n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01_LCEL\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'가봉의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"가봉\")\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아 내부의 가중치(weight)와 편향(bias)을 조정하면서 원하는 출력을 만들어내는 과정입니다. 모델은 입력 데이터와 실제 출력 사이의 차이를 최소화하는 방향으로 계속해서 학습을 진행하며, 이를 위해 손실 함수(loss function)를 사용합니다.\\n\\n학습 과정에서 모델은 입력 데이터를 받아 다양한 계층(layer)을 거쳐 출력을 생성하고, 이를 실제 출력과 비교하여 오차를 계산합니다. 이 오차를 최소화하기 위해 역전파(backpropagation) 알고리즘을 사용하여 가중치와 편향을 조절하며 모델을 계속 향상시킵니다.\\n\\n이러한 과정을 반복하면 모델은 입력 데이터에 대한 패턴을 학습하고, 새로운 데이터가 들어왔을 때 정확한 출력을 예측할 수 있게 됩니다. 이렇게 학습된 인공지능 모델은 다양한 작업을 수행하거나 문제를 해결하는 데 활용됩니다. \\n\\n요약하자면, 인공지능 모델의 학습 원리는 입력 데이터와 실제 출력 사이의 오차를 최소화하기 위해 가중치와 편향을 조정하는 과정으로, 이를 위해 손실 함수와 역전파 알고리즘이 사용됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 434, 'prompt_tokens': 33, 'total_tokens': 467, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3Xzud9HWJUA01YHca4sy62v6ST8h', 'finish_reason': 'stop', 'logprobs': None}, id='run-b571298a-0317-4d48-b8b9-0b89b2589ba7-0', usage_metadata={'input_tokens': 33, 'output_tokens': 434, 'total_tokens': 467, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 사용하여 패턴을 학습하는 과정입니다. 먼저 모델이 입력 데이터를 받아들이고, 이 데이터와 관련된 출력을 예측합니다. 그리고 이 예측값과 실제 정답(라벨)을 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 모델을 업데이트합니다. 이 과정을 반복하여 모델이 더 정확한 결과를 예측하도록 학습하게 됩니다. 이러한 과정을 통해 모델은 데이터에 내재된 패턴을 학습하고, 이를 토대로 새로운 입력 데이터에 대한 예측을 수행할 수 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "response = llm_with_logprob.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 내부에서 패턴을 학습하는 과정입니다. 모델은 입력된 데이터와 원하는 결과를 비교하여 오차를 줄이는 방향으로 학습을 진행합니다. 이 과정은 주로 두 가지 방법으로 이루어집니다.\\n\\n하나는 지도 학습으로, 모델에게 입력된 데이터와 그에 대한 정확한 결과가 함께 제공되어 모델이 이를 학습하도록 하는 방법입니다. 다른 하나는 비지도 학습으로, 모델이 입력 데이터만을 바탕으로 내재된 패턴이나 구조를 발견하고 학습하는 방법입니다.\\n\\n이러한 학습을 통해 인공지능 모델은 새로운 데이터가 주어졌을 때 그에 대한 예측을 할 수 있게 됩니다. 학습에 사용된 데이터의 양과 질, 모델의 구조 및 하이퍼파라미터 설정 등이 결과에 영향을 미치므로 이러한 요소들을 적절히 설정해주는 것이 중요합니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴을 학습하고 이를 기반으로 예측이나 결정을 내리는 과정입니다. 일반적으로 인공지능 모델은 데이터를 입력받아 가중치를 조절하며 학습을 진행하고, 이를 바탕으로 정확한 예측을 할 수 있도록 합니다.\n",
      "\n",
      "인공지능 모델은 입력 데이터를 받아들여 내부의 가중치와 편향을 조절하면서 출력을 생성합니다. 이때, 입력 데이터와 출력 데이터 사이의 차이를 줄여나가는 방향으로 학습이 이루어집니다. 이 과정을 반복하면서 모델은 입력 데이터의 패턴을 파악하고, 새로운 데이터에 대해서도 정확한 예측을 할 수 있도록 합니다.\n",
      "\n",
      "즉, 인공지능 모델의 학습 원리는 주어진 데이터를 바탕으로 패턴을 학습하여 예측이나 결정을 내리는 과정을 말합니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4.1\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:  \n",
      "A: Hello! Welcome to our restaurant. How many people are in your party?  \n",
      "B: Hi! It’s just me today.  \n",
      "A: Great. Here’s the menu. Are you ready to order, or do you need a few more minutes?  \n",
      "B: I’m ready to order. I’d like to have the grilled chicken sandwich, please.  \n",
      "A: Would you like anything to drink?  \n",
      "B: Yes, I’ll have an iced tea.  \n",
      "A: Perfect. Your order will be out shortly.  \n",
      "\n",
      "- 한글 해석:  \n",
      "A: 안녕하세요! 저희 식당에 오신 것을 환영합니다. 몇 분이세요?  \n",
      "B: 안녕하세요! 오늘은 저 혼자입니다.  \n",
      "A: 알겠습니다. 여기 메뉴판입니다. 주문하시겠어요, 아니면 좀 더 시간이 필요하세요?  \n",
      "B: 주문할게요. 그릴 치킨 샌드위치 하나 주세요.  \n",
      "A: 음료는 무엇으로 드릴까요?  \n",
      "B: 네, 아이스티로 주세요.  \n",
      "A: 알겠습니다. 곧 음식 가져다드릴게요."
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상황: 미국에서 피자 주문\n",
      "\n",
      "- 영어 회화:\n",
      "A: Hi, I'd like to order a pizza for delivery, please.  \n",
      "B: Sure! What size pizza would you like?  \n",
      "A: I'll have a large, please.  \n",
      "B: Great. What kind of crust do you prefer?  \n",
      "A: Thin crust, please.  \n",
      "B: And what toppings would you like?  \n",
      "A: Could I get pepperoni, mushrooms, and olives?  \n",
      "B: Absolutely. Anything else?  \n",
      "A: No, that's all.  \n",
      "B: May I have your address and phone number?  \n",
      "A: Yes, it's 123 Maple Street, and my number is 555-1234.  \n",
      "B: Thank you. Your total is $18.99. It should arrive in about 40 minutes.  \n",
      "A: Perfect, thank you!  \n",
      "B: You're welcome. Have a great day!\n",
      "\n",
      "- 한글 해석:\n",
      "A: 안녕하세요, 배달로 피자를 주문하고 싶어요.  \n",
      "B: 네! 어떤 사이즈의 피자를 원하시나요?  \n",
      "A: 라지로 주세요.  \n",
      "B: 알겠습니다. 어떤 도우를 원하세요?  \n",
      "A: 얇은 도우로 주세요.  \n",
      "B: 토핑은 무엇으로 드릴까요?  \n",
      "A: 페퍼로니, 버섯, 올리브 넣어주세요.  \n",
      "B: 네, 알겠습니다. 더 추가하실 건 있으신가요?  \n",
      "A: 아니요, 그게 다예요.  \n",
      "B: 주소와 전화번호 알려주세요.  \n",
      "A: 네, 주소는 123 메이플 스트리트이고, 제 번호는 555-1234예요.  \n",
      "B: 감사합니다. 총 금액은 $18.99입니다. 약 40분 후에 도착할 거예요.  \n",
      "A: 네, 감사합니다!  \n",
      "B: 천만에요. 좋은 하루 되세요!"
     ]
    }
   ],
   "source": [
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ChatOpenAI 모델을 인스턴스화합니다.\n",
    "model = ChatOpenAI()\n",
    "# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
    "chain = prompt | model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "멀티모달은 여러 가지 다양한 형태의 통신 수단과 매체를 결합하여 효율적으로 정보를 전달하는 방식을 말합니다. 이는 텍스트, 음성, 이미지, 동영상 등의 다양한 매체를 조합하여 사용자에게 다양한 경험을 제공하며, 상호작용성과 직관성을 향상시킵니다. 멀티모달은 정보의 이해와 전달을 보다 효과적으로 도와주는 기술로, 현대 디지털 환경에서 많이 활용되고 있습니다."
     ]
    }
   ],
   "source": [
    "# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\n",
    "for token in chain.stream({\"topic\": \"멀티모달\"}):\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChatGPT는 OpenAI가 개발한 자연어 처리 기술을 이용한 대화형 인공지능 챗봇이다. 이 기술은 사용자와의 대화를 통해 자연스럽고 유익한 상호작용을 제공한다. ChatGPT는 문장 생성, 응답 및 대화 흐름을 자동화하여 효율적인 커뮤니케이션을 돕는다.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\n",
    "chain.invoke({\"topic\": \"ChatGPT\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 엘론 머스크의 OpenAI에서 만들어진 자연어 처리 모델로, 대화형 인공지능 서비스를 제공합니다. 이 모델은 다양한 주제에 대한 대화를 이해하고 응답하여 사용자의 질문에 답변하거나 대화를 이어나갈 수 있습니다. ChatGPT는 실시간 대화나 텍스트 기반 작업에 유용하게 활용되고 있습니다.',\n",
       " 'Instagram은 사진과 동영상을 공유하고 소셜 네트워크 서비스를 제공하는 앱이다. 사용자들은 자신의 일상을 올리고 팔로워들과 소통하며 콘텐츠를 공유할 수 있다. 또한 인기 있는 해시태그를 활용해 다양한 주제의 게시물을 찾아볼 수 있다.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
    "chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChatGPT는 대화형 AI 모델로, 사람과 자연스럽게 대화를 나눌 수 있습니다. 최신 기술을 이용하여 다양한 주제에 대해 대화를 이어나가며 질문에 답변을 해줍니다. 사용자들은 ChatGPT를 통해 정보를 얻거나 챗봇으로 활용할 수 있습니다.',\n",
       " 'Instagram은 사진이나 동영상을 공유하여 다른 사용자들과 소통하는 소셜 미디어 애플리케이션입니다. 사용자는 팔로워를 얻고 일상을 공유하며, 좋아요나 댓글을 통해 소통할 수 있습니다. 또한 인플루언서나 기업들이 광고나 마케팅 활동을 통해 홍보하는데에도 활용됩니다.',\n",
       " '멀티모달은 여러 개의 다양한 형태의 수단을 결합하여 이용자에게 최적의 이동 경로나 정보를 제공하는 시스템이다. 이를 통해 이용자는 보다 스마트하고 편리한 이동 및 정보 검색 서비스를 이용할 수 있다. 대중교통, 자전거, 자동차 등 다양한 수단을 연계하여 효율적인 이동 및 정보 검색이 가능하다.',\n",
       " '프로그래밍은 컴퓨터에게 작업을 지시하기 위해 코드를 작성하는 과정입니다. 코드는 특정 언어로 작성되며, 컴퓨터가 이해할 수 있는 명령어로 이루어져 있습니다. 프로그래밍을 통해 원하는 기능을 가진 소프트웨어나 애플리케이션을 만들 수 있습니다.',\n",
       " '머신러닝은 컴퓨터가 자동적으로 학습하고 패턴을 발견하는 인공지능의 한 분야이다. 이를 통해 컴퓨터는 데이터를 분석하고 예측을 하며 문제를 해결할 수 있다. 머신러닝은 다양한 분야에서 활용되며 인간의 업무를 자동화하고 효율적으로 처리할 수 있게 도와준다.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch(\n",
    "    [\n",
    "        {\"topic\": \"ChatGPT\"},\n",
    "        {\"topic\": \"Instagram\"},\n",
    "        {\"topic\": \"멀티모달\"},\n",
    "        {\"topic\": \"프로그래밍\"},\n",
    "        {\"topic\": \"머신러닝\"},\n",
    "    ],\n",
    "    config={\"max_concurrency\": 3},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube는 동영상 공유 플랫폼으로, 사용자들이 영상을 업로드하고 시청할 수 있는 서비스이다. 누구나 쉽게 접근하여 다양한 주제의 영상을 시청하고 즐길 수 있다. 유명한 크리에이터나 기업들이 영상을 통해 광고를 홍보하거나 수익을 창출하는 것도 가능하다."
     ]
    }
   ],
   "source": [
    "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
    "async for token in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(token, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\n",
    "my_process = chain.ainvoke({\"topic\": \"NVDA\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVDA는 전 세계적으로 가장 널리 사용되는 스크린 리더 소프트웨어로, 시각 장애인을 위해 컴퓨터 사용을 돕는 역할을 합니다. 사용자가 키보드를 통해 컴퓨터 화면에 표시되는 텍스트를 읽어주고 명령을 수행할 수 있도록 지원합니다. 최신 기술과 개발자들의 지속적인 노력으로 계속 발전하고 있습니다.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.\n",
    "await my_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\n",
    "my_abatch_process = chain.abatch(\n",
    "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YouTube는 세계적으로 인기 있는 동영상 공유 플랫폼으로, 사용자들은 다양한 주제의 동영상을 시청하고 업로드할 수 있습니다. 광고 수익과 스트리밍 서비스를 통해 수익을 창출하며, 유명한 크리에이터들은 수백만 명의 구독자를 보유하고 있습니다. 사용자들은 댓글을 통해 소통하고, 좋아요나 싫어요로 동영상을 평가할 수 있습니다.',\n",
       " 'Instagram은 사진과 동영상을 공유하고 소셜 네트워크를 형성할 수 있는 앱이다. 사용자들은 팔로우와 좋아요를 통해 서로 소통하고 콘텐츠를 공유한다. 또한, 스토리 기능을 이용하여 임시로 사진과 동영상을 업로드할 수도 있다.',\n",
       " 'Facebook은 사람들끼리 소통하고 정보를 공유하는 소셜 네트워크 서비스이다. 사용자는 친구를 추가하고 메시지를 주고받으며 사진과 동영상을 공유할 수 있다. 또한 개인 블로그나 비즈니스 페이지를 운영할 수 있는 기능도 제공된다.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.\n",
    "await my_abatch_process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
    "chain1 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
    "chain2 = (\n",
    "    PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
    "combined = RunnableParallel(capital=chain1, area=chain2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'리우데자네이루와 브라질리아 2개의 수도가 있다.리우데자네이루는 브라질의 여러 가지 문화와 관광 명소로 유명한 도시 중 하나이다.브라질리아는 1960년에 완전히 새롭게 설립된 수도로, 정부와 행정의 중심지로서의 역할을 하고 있다.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain1 를 실행합니다.\n",
    "chain1.invoke({\"country\": \"브라질\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아르헨티나의 면적은 약 2,780,400km² 입니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain2 를 실행합니다.\n",
    "chain2.invoke({\"country\": \"아르헨티나\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': '짐바브웨의 수도는 하라레입니다.', 'area': '짐바브웨의 면적은 약 390,757 제곱 킬로미터 입니다.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 병렬 실행 체인을 실행합니다.\n",
    "combined.invoke({\"country\": \"짐바브웨\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['모잠비크의 수도는 마푸투(Máputo)입니다.', '조지아의 수도는 티빌리시입니다.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 처리를 수행합니다.\n",
    "chain1.batch([{\"country\": \"모잠비크\"}, {\"country\": \"조지아\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['모나코 공국의 면적은 2.02km² 입니다. 작은 국가 중 하나로, 세계에서 네 번째로 작은 국가입니다.',\n",
       " '바티칸시국의 면적은 약 0.44km² 입니다.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 처리를 수행합니다.\n",
    "chain2.batch([{\"country\": \"모나코공국\"}, {\"country\": \"바티칸시국\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'capital': '파푸아뉴기니의 수도는 포트모르즈비이다.',\n",
       "  'area': '파푸아뉴기니의 면적은 약 46만 50만 제곱 킬로미터 입니다.'},\n",
       " {'capital': '콩고민주공화국의 수도는 킨샤사입니다.',\n",
       "  'area': '콩고민주공화국의 면적은 약 2,345,410 km² 입니다.'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 데이터를 배치로 처리합니다.\n",
    "combined.batch([{\"country\": \"파푸아뉴기니\"}, {\"country\": \"콩고민주공화국\"}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# prompt 와 llm 을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='50입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3YoxcMIOjaQnqzy08Z0VnsbEP4zd', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c92a9f1-afe8-418e-bf8c-4a3c6fb30fc1-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 을 실행합니다.\n",
    "chain.invoke({\"num\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='50입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3Yp7ECjafW25txEbg4dug8ji3HYV', 'finish_reason': 'stop', 'logprobs': None}, id='run-7ae9ecbe-e174-4a7f-bf8f-3fddc25211f4-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 을 실행합니다.\n",
    "chain.invoke(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 10}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# runnable\n",
    "RunnablePassthrough().invoke({\"num\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10의 10배는 100입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 16, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3YpTEB7uK8wkEGjL2JkQUQiPObuj', 'finish_reason': 'stop', 'logprobs': None}, id='run-fbb1806c-6b6b-480d-b7da-27eb65d4c1b5-0', usage_metadata={'input_tokens': 16, 'output_tokens': 11, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
    "\n",
    "# dict 값이 RunnablePassthrough() 로 변경되었습니다.\n",
    "runnable_chain.invoke(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"num\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 키: num, 할당(assign) 키: new_num\n",
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# RunnableParallel 인스턴스를 생성합니다. 이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다.\n",
    "runnable = RunnableParallel(\n",
    "    # RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달합니다. 이는 입력된 데이터를 그대로 통과시키는 역할을 합니다.\n",
    "    passed=RunnablePassthrough(),\n",
    "    # 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용하여, 'mult' 람다 함수를 할당합니다. 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값을 3배로 증가시킵니다.\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    # 'modified' 키워드 인자로 람다 함수를 전달합니다. 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값에 1을 더합니다.\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "# runnable 인스턴스에 {'num': 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출합니다.\n",
    "runnable.invoke({\"num\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} 의 수도는?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "chain2 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} 의 면적은?\")\n",
    "    | ChatOpenAI()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': AIMessage(content='앵카라(Ancara)입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 21, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3Yqt0HBRVHdGd3LoDanvbfwBAYAS', 'finish_reason': 'stop', 'logprobs': None}, id='run-62ba466e-09fb-47e7-b88d-c2d928892065-0', usage_metadata={'input_tokens': 21, 'output_tokens': 11, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'area': AIMessage(content='투르키의 면적은 약 783,356 제곱킬로미터입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 22, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3YqtFtQxItHTM36MvlXP7WfCQeck', 'finish_reason': 'stop', 'logprobs': None}, id='run-1a01256d-9e24-4368-9993-f207dbef3bc5-0', usage_metadata={'input_tokens': 22, 'output_tokens': 28, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
    "combined_chain.invoke(\"튀르키예\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aug-12'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    # 오늘 날짜를 가져오기\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "\n",
    "# 오늘 날짜를 출력\n",
    "get_today(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# prompt 와 llm 을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{today} 가 생일인 유명인 {n} 명을 나열하세요. 생년월일을 표기해 주세요.\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1\")\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 8월 12일(8월 12일)이 생일인 유명인 3명을 생년월일과 함께 나열해 드리겠습니다.\n",
      "\n",
      "1. **마리안느(마릴린) 해리스(Marion Harris)**  \n",
      "   - 생년월일: 1896년 8월 12일  \n",
      "   - 미국의 재즈 가수\n",
      "\n",
      "2. **타이슨 퓨리(Tyson Fury)**  \n",
      "   - 생년월일: 1988년 8월 12일  \n",
      "   - 영국의 프로 복서, 헤비급 세계 챔피언\n",
      "\n",
      "3. **케이시 애플렉(Casey Affleck)**  \n",
      "   - 생년월일: 1975년 8월 12일  \n",
      "   - 미국의 배우, 아카데미상 수상자\n",
      "\n",
      "궁금한 점이 있으면 언제든 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 출력\n",
    "print(chain.invoke(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# prompt 와 llm 을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"{today} 가 생일인 한국인 여성 유명인 {n} 명을 나열하세요. 생년월일을 표기해 주세요.\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4.1\")\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 8월 12일이 생일인 한국인 여성 유명인 3명을 생년월일과 함께 나열해 드리겠습니다.\n",
      "\n",
      "1. **이하이 (Lee Hi, 이하이)**\n",
      "   - 생년월일: 1996년 8월 12일\n",
      "   - 가수\n",
      "\n",
      "2. **이유비 (Lee Yu-bi, 이유비)**\n",
      "   - 생년월일: 1990년 8월 12일\n",
      "   - 배우\n",
      "\n",
      "3. **이수정 (Lee Soo-jung, 크리스탈 클리어의 수정)**\n",
      "   - 생년월일: 1997년 8월 12일\n",
      "   - 가수, 그룹 크리스탈 클리어(CLC) 멤버\n",
      "\n",
      "참고: 공개된 프로필 기준으로 작성하였습니다.\n"
     ]
    }
   ],
   "source": [
    "# 출력\n",
    "print(chain.invoke(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 문장의 길이를 반환하는 함수입니다.\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "# 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5 + 25 = 30', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 22, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C3YskPBvJiycE63Hy1TrCLDbiFWwe', 'finish_reason': 'stop', 'logprobs': None}, id='run-07d5b58d-f6c4-4d1e-b089-dbea8250d055-0', usage_metadata={'input_tokens': 22, 'output_tokens': 7, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMs2OSEsEhI+eP+P38efuYH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
