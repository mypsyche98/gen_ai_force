{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHjzPvyRefj3",
    "outputId": "6a95054f-2b46-425d-f493-d94e0af0927f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.21 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 1))\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core==0.3.46 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 2))\n",
      "  Downloading langchain_core-0.3.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-experimental==0.3.4 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 3))\n",
      "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community==0.3.20 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-openai==0.3.9 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 5))\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-anthropic==0.3.10 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 6))\n",
      "  Downloading langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-text-splitters==0.3.7 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 7))\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-elasticsearch==0.3.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 8))\n",
      "  Downloading langchain_elasticsearch-0.3.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-chroma==0.2.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 9))\n",
      "  Downloading langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-cohere==0.4.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 10))\n",
      "  Downloading langchain_cohere-0.4.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-milvus==0.1.8 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 11))\n",
      "  Downloading langchain_milvus-0.1.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-google-genai==2.1.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-huggingface==0.1.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 13))\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-azure-ai==0.1.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading langchain_azure_ai-0.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-teddynote==0.3.44 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading langchain_teddynote-0.3.44-py3-none-any.whl.metadata (867 bytes)\n",
      "Collecting langchainhub==0.1.21 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 16))\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting langgraph==0.3.18 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 17))\n",
      "  Downloading langgraph-0.3.18-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting langsmith==0.3.18 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18))\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting huggingface-hub==0.29.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 19))\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai==1.67.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20))\n",
      "  Downloading openai-1.67.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting deepl==1.21.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 21))\n",
      "  Downloading deepl-1.21.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting kiwipiepy==0.20.4 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 22))\n",
      "  Downloading kiwipiepy-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting konlpy==0.6.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 23))\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pandas==2.2.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 25))\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting rank-bm25==0.2.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 26))\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting redis==5.2.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 28))\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting chromadb==0.6.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pymupdf==1.25.4 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 31))\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pypdf==4.3.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 32))\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pdfplumber==0.11.5 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 33))\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer-six==20231228 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 34))\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pymupdf4llm==0.0.17 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 35))\n",
      "  Downloading pymupdf4llm-0.0.17-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting matplotlib==3.10.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37))\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting streamlit==1.43.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting jupyter==1.1.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39))\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: notebook==7.3.3 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (7.3.3)\n",
      "Collecting torch==2.6.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.21.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 43))\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting faiss-cpu==1.10.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 44))\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting open-clip-torch==2.31.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45))\n",
      "  Downloading open_clip_torch-2.31.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 47))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pydantic==2.10.6 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 48))\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting lxml==5.3.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 49))\n",
      "  Downloading lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting pillow==10.4.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 50))\n",
      "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting lark==1.2.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 51))\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ragas==0.2.14 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading ragas-0.2.14-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting unstructured==0.17.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading unstructured-0.17.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting arxiv==2.1.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 54))\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tiktoken==0.9.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 55))\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tenacity==8.5.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 56))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pymilvus==2.5.5 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 57))\n",
      "  Downloading pymilvus-2.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-search-results==2.4.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 58))\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf==3.20.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 59))\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting sqlalchemy==2.0.39 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 60))\n",
      "  Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting llama-index-core==0.11.23 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 61))\n",
      "  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-parse==0.6.4.post1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_parse-0.6.4.post1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-index-readers-file==0.2.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 63))\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting flashrank==0.2.10 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 64))\n",
      "  Downloading FlashRank-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting docx2txt==0.8 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 65))\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 66)) (1.6.0)\n",
      "Collecting rapidocr-onnxruntime==1.4.4 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67))\n",
      "  Downloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting seaborn==0.13.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 68))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting grandalf==0.8 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 69))\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting rouge-score==0.1.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 70))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting langchain-ollama==0.2.3 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 71))\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting mypy==1.15.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 72))\n",
      "  Downloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pinecone==5.4.2 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 73))\n",
      "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting wikipedia==1.4.0 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 74))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn==1.6.1 (from -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 75))\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 1)) (6.0.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.46->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 2))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.46->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.46->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 2)) (4.12.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4)) (2.1.2)\n",
      "Collecting anthropic<1,>=0.49.0 (from langchain-anthropic==0.3.10->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 6))\n",
      "  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting elasticsearch<9.0.0,>=8.13.1 (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch==0.3.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 8))\n",
      "  Downloading elasticsearch-8.19.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting cohere<6.0,>=5.12.0 (from langchain-cohere==0.4.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 10))\n",
      "  Downloading cohere-5.17.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from langchain-cohere==0.4.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 10))\n",
      "  Downloading types_pyyaml-6.0.12.20250809-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 13))\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 13))\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 13))\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting azure-ai-inference<2.0.0,>=1.0.0b7 (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting azure-core<2.0.0,>=1.32.0 (from langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting azure-cosmos<5.0.0,>=4.9.0 (from langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading azure_cosmos-4.9.0-py3-none-any.whl.metadata (80 kB)\n",
      "Collecting azure-identity<2.0.0,>=1.15.0 (from langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading azure_identity-1.24.0-py3-none-any.whl.metadata (86 kB)\n",
      "Collecting pymongo<5.0.0,>=4.5.0 (from langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting simsimd<7.0.0,>=6.0.0 (from langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading simsimd-6.5.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (70 kB)\n",
      "Collecting pinecone-client[grpc] (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pinecone-text (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading pinecone_text-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting olefile (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting pdf2image (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting feedparser (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tavily-python (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading tavily_python-0.7.10-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.21->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 16))\n",
      "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 17))\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 17))\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 17))\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18)) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18))\n",
      "  Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18))\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.29.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 19)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.29.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 19)) (2024.10.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub==0.29.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 19))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.67.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.67.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20)) (1.7.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai==1.67.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20))\n",
      "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.67.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20)) (1.3.1)\n",
      "Collecting kiwipiepy_model<0.21,>=0.20 (from kiwipiepy==0.20.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 22))\n",
      "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m146.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy==0.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 23))\n",
      "  Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 25)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 25))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 25))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading posthog-6.5.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29)) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Collecting rich>=10.11.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber==0.11.5->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 33))\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six==20231228->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 34)) (3.4.1)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer-six==20231228->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 34))\n",
      "  Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.10.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37))\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.10.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.10.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37))\n",
      "  Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.10.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37))\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.10.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 37)) (2.4.7)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (5.5.2)\n",
      "Collecting click<9,>=7.0 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (6.4.2)\n",
      "Collecting jupyter-console (from jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39))\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (from jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (4.3.6)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.2.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42)) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42))\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex (from open-clip-torch==2.31.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45))\n",
      "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting ftfy (from open-clip-torch==2.31.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45))\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting safetensors (from open-clip-torch==2.31.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45))\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting timm (from open-clip-torch==2.31.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45))\n",
      "  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic==2.10.6->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 48))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 48))\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting datasets (from ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting appdirs (from ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting chardet (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-magic (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nltk (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53)) (4.13.3)\n",
      "Collecting emoji (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m248.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rapidfuzz (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53)) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus==2.5.5->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 57)) (77.0.1)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting ujson>=2.0.0 (from pymilvus==2.5.5->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 57))\n",
      "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus==2.5.5->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 57))\n",
      "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy==2.0.39->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 60))\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.11.23->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 61))\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.11.23->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 61))\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.11.23->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 61))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file==0.2.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 63))\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime==1.4.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67))\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting opencv-python>=4.5.1.48 (from rapidocr-onnxruntime==1.4.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67))\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/lib/python3/dist-packages (from rapidocr-onnxruntime==1.4.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67)) (1.16.0)\n",
      "Collecting Shapely!=2.0.4,>=1.7.1 (from rapidocr-onnxruntime==1.4.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67))\n",
      "  Downloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting absl-py (from rouge-score==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 70))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain-ollama==0.2.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 71))\n",
      "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mypy_extensions>=1.0.0 (from mypy==1.15.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 72))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone==5.4.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 73)) (2025.1.31)\n",
      "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone==5.4.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 73))\n",
      "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone==5.4.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 73))\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone==5.4.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 73)) (2.3.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.6.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 75))\n",
      "  Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.6.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 75))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.6.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 75))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42)) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading narwhals-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.67.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 20)) (3.10)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-inference<2.0.0,>=1.0.0b7->azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-core-tracing-opentelemetry (from azure-ai-inference[opentelemetry]<2.0.0,>=1.0.0b7->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity<2.0.0,>=1.15.0->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53)) (2.6)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.12.0->langchain-cohere==0.4.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 10))\n",
      "  Downloading fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six==20231228->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 34)) (1.17.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch<9.0.0,>=8.13.1->elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch==0.3.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 8))\n",
      "  Downloading elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi>=0.95.2->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting sgmllib3k (from feedparser->langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (1.26.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.46->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (5.14.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 42)) (2.1.5)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (2.2.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (1.8.13)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (9.0.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.1.7)\n",
      "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.10.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 17))\n",
      "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Collecting llama-cloud==0.1.37 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.37-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.53-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.52-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.51-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.34 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.34-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.50-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.49-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.48-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.47-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.33 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.33-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.46-py3-none-any.whl.metadata (3.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading llama_cloud_services-0.6.45-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.44-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.43-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.32 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.32-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.42-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.41-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.30 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.30-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.40-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.39-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.38-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.29 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.29-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.37-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading llama_cloud_services-0.6.36-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-cloud==0.1.28 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.28-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.35-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-cloud==0.1.27 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.27-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.34-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-cloud==0.1.26 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.26-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.33-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.32-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.31-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.30-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-cloud==0.1.23 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.23-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.29-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.28-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.27-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.26-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.25-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.24-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading llama_cloud_services-0.6.23-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-cloud==0.1.22 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.22-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.22-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting llama-cloud==0.1.19 (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
      "Collecting llama-cloud-services>=0.6.4 (from llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62))\n",
      "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 62)) (4.3.7)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (2.19.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python>=4.5.1.48 (from rapidocr-onnxruntime==1.4.4->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 67))\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29)) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.34.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.33.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.33.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.32.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.31.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.2 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.28.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.28.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading asgiref-3.9.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.56b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.56b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.56b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.56b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.56b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.55b0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.55b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.54b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.54b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.54b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.54b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.54b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.54b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.33.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.53b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.53b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.32.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is still looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.31.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.49b2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.49b2 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.49b2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.49b0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.49b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.28.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.20->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 4))\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=4.5.0->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14))\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 13))\n",
      "  Downloading transformers-4.55.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas==0.2.14->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 52))\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch==2.31.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 45)) (0.2.13)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.11/dist-packages (from jupyter-console->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (3.0.50)\n",
      "Collecting lz4>=3.1.3 (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of pinecone-client[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pinecone-client[grpc] (from langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading pinecone_client-5.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading pinecone_client-4.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading pinecone_client-4.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading pinecone_client-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading pinecone_client-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading pinecone_client-3.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting grpc-gateway-protoc-gen-openapiv2==0.1.0 (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 15))\n",
      "  Downloading grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith==0.3.18->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 18))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading unstructured_client-0.42.2-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.42.1-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.42.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.41.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.40.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading unstructured_client-0.39.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.38.1-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is still looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading unstructured_client-0.37.4-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.37.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading unstructured_client-0.37.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.35.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading unstructured_client-0.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting unstructured-client (from unstructured==0.17.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 53))\n",
      "  Downloading unstructured_client-0.33.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.33.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.32.4-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.32.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (21.2.0)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (1.4.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer-six==20231228->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 34)) (2.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (4.9.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29)) (1.0.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (4.9.0)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.6.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.43.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 38)) (0.23.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.1.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/lib/python3/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->langchain-azure-ai==0.1.2->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 14)) (2.3.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (0.7.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.22.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "  Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Downloading googleapis_common_protos-1.67.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.64.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.58.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.57.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.57.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Using cached google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.25.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading grpcio_status-1.74.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.57.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.52.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading proto_plus-1.26.0rc1-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.25.0rc0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.1rc0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.0rc3-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.0rc2-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.0.dev1-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.24.0.dev0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.23.0rc2-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.23.0rc1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 29))\n",
      "  Downloading googleapis_common_protos-1.67.0rc1-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "  Downloading googleapis_common_protos-1.63.2rc0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.63.1rc0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.62.0rc2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.62.0rc1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.56.3b1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.17.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.16.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.16.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.16.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.14.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading google_api_core-2.13.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading google_api_core-2.13.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading google_api_core-2.11.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading google_api_core-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12))\n",
      "  Downloading grpcio_status-1.49.0rc3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.49.0rc1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.8.4)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (20.11.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (24.11.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai==2.1.0->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 12)) (0.6.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/dist-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter==1.1.1->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 39)) (0.2.3)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook==7.3.3->-r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt (line 40)) (2.9.0.20241206)\n",
      "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m195.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.46-py3-none-any.whl (417 kB)\n",
      "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m204.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
      "Downloading langchain_anthropic-0.3.10-py3-none-any.whl (25 kB)\n",
      "Downloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Downloading langchain_elasticsearch-0.3.2-py3-none-any.whl (45 kB)\n",
      "Downloading langchain_chroma-0.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading langchain_cohere-0.4.3-py3-none-any.whl (42 kB)\n",
      "Downloading langchain_milvus-0.1.8-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_google_genai-2.1.0-py3-none-any.whl (40 kB)\n",
      "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading langchain_azure_ai-0.1.2-py3-none-any.whl (44 kB)\n",
      "Downloading langchain_teddynote-0.3.44-py3-none-any.whl (48 kB)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading langgraph-0.3.18-py3-none-any.whl (136 kB)\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading openai-1.67.0-py3-none-any.whl (580 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.2/580.2 kB\u001b[0m \u001b[31m134.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deepl-1.21.1-py3-none-any.whl (38 kB)\n",
      "Downloading kiwipiepy-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m192.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m183.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m239.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m170.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m210.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymupdf4llm-0.0.17-py3-none-any.whl (26 kB)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m190.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m251.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m157.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m204.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m193.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading open_clip_torch-2.31.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m200.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading ragas-0.2.14-py3-none-any.whl (187 kB)\n",
      "Downloading unstructured-0.17.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m195.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading pymilvus-2.5.5-py3-none-any.whl (223 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading sqlalchemy-2.0.39-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m289.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m270.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.6.4.post1-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading FlashRank-0.2.10-py3-none-any.whl (14 kB)\n",
      "Downloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m227.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\n",
      "Downloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m191.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m198.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m214.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m510.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m538.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m223.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m446.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m196.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m446.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m219.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m429.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m171.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m430.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m398.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m314.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m427.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m333.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m193.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
      "Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
      "Downloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
      "Downloading azure_cosmos-4.9.0-py3-none-any.whl (303 kB)\n",
      "Downloading azure_identity-1.24.0-py3-none-any.whl (187 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading cohere-5.17.0-py3-none-any.whl (295 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m519.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading elasticsearch-8.19.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.9/926.9 kB\u001b[0m \u001b[31m178.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m136.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m259.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 kB\u001b[0m \u001b[31m162.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m252.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (496 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m428.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
      "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
      "Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m168.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m362.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m340.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m206.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m178.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading posthog-6.5.0-py3-none-any.whl (116 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m370.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m262.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymongo-4.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m240.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m246.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m230.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m239.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m132.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simsimd-6.5.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m306.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m292.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m269.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading types_pyyaml-6.0.12.20250809-py3-none-any.whl (20 kB)\n",
      "Downloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (82 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m158.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpc_gateway_protoc_gen_openapiv2-0.1.0-py3-none-any.whl (12 kB)\n",
      "Downloading pinecone_text-0.11.0-py3-none-any.whl (22 kB)\n",
      "Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tavily_python-0.7.10-py3-none-any.whl (15 kB)\n",
      "Downloading timm-1.0.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.32.3-py3-none-any.whl (180 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading elastic_transport-8.17.1-py3-none-any.whl (64 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading google_api_core-1.34.1-py3-none-any.whl (120 kB)\n",
      "Downloading grpcio_status-1.49.0rc1-py3-none-any.whl (14 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
      "Downloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading narwhals-2.1.1-py3-none-any.whl (389 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m143.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pinecone_client-3.2.2-py3-none-any.whl (215 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading asgiref-3.9.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: google-search-results, docx2txt, rouge-score, wikipedia, kiwipiepy_model, pypika, langdetect, sgmllib3k\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32093 sha256=6b2c34fb76d767377bc89297853e0255e496cf82fe27bda31d4656246a0e6236\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=4024 sha256=f4c93670a4980455532dc41208b7bc7fc5d9c9ca820d400e5544a09da35327b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24988 sha256=ad4c971fc084e748bf3ad7edb5154abb5967ba61e0d987ff7a4fba9441399365\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11757 sha256=42c306e9d6f19bb0fda2cc88170df6c285821f20c4b633ab0ce1d7525d1553b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818076 sha256=8f24446374f3b3b64059ce8a9d0b871a3ebaf08cf9c223393aece5bb1ca864ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/c8/52/3a539d6e9065b191fe1c215e0203dcc3e00601c0e3d3d39824\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=1c2345b4dc9698efaff18134a07939aa415dfe5659ec391d613f2c34db46e5fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993332 sha256=64e31002022e1d7f35b2633361764cb700c64d6453ef2351b33521ae0c15c715\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6090 sha256=96f9c807e63fb4c6b9a5341fb6069282ede9c89f8e2402c0cfa752ab9a2065b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built google-search-results docx2txt rouge-score wikipedia kiwipiepy_model pypika langdetect sgmllib3k\n",
      "Installing collected packages: triton, striprtf, simsimd, sgmllib3k, pytz, pypika, pyclipper, nvidia-cusparselt-cu12, mmh3, kiwipiepy_model, flatbuffers, filetype, durationpy, docx2txt, dirtyjson, appdirs, zstandard, xxhash, wrapt, websockets, watchdog, uvloop, ujson, tzdata, typing-inspection, types-requests, types-pyyaml, tqdm, toml, threadpoolctl, tenacity, sympy, smmap, shellingham, safetensors, regex, redis, rapidfuzz, python-magic, python-iso639, python-dotenv, pyproject_hooks, pypdfium2, pypdf, pymupdf, pydantic-core, pyarrow, protobuf, propcache, pinecone-plugin-interface, pillow, ormsgpack, orjson, opentelemetry-util-http, olefile, oauthlib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, narwhals, mypy_extensions, multidict, mdurl, marshmallow, lz4, lxml, lark, langdetect, kiwisolver, jsonpatch, JPype1, joblib, jiter, isodate, importlib-resources, importlib-metadata, humanfriendly, httpx-sse, httptools, html5lib, grpcio, greenlet, grandalf, ftfy, frozenlist, fonttools, feedparser, fastavro, eval-type-backport, emoji, elastic-transport, dnspython, diskcache, dill, cycler, click, chardet, bcrypt, backoff, asgiref, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yarl, wikipedia, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, sqlalchemy, Shapely, scipy, requests-toolbelt, requests-oauthlib, rank-bm25, python-oxmsg, pymupdf4llm, pymongo, pydeck, pydantic, posthog, pinecone-plugin-inference, pinecone-client, pdf2image, pandas, opentelemetry-proto, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, mypy, multiprocess, milvus-lite, markdown-it-py, langchainhub, konlpy, kiwipiepy, huggingface-hub, google-search-results, gitdb, faiss-cpu, elasticsearch, deprecated, deepl, cryptography, contourpy, coloredlogs, chroma-hnswlib, build, azure-core, arxiv, aiosignal, unstructured-client, tokenizers, tavily-python, scikit-learn, rouge-score, rich, pymilvus, pydantic-settings, pinecone-text, pinecone, pdfminer-six, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, openai, onnxruntime, ollama, nvidia-cusolver-cu12, matplotlib, llama-cloud, langsmith, langgraph-sdk, kubernetes, grpcio-status, grpc-gateway-protoc-gen-openapiv2, google-api-core, gitpython, fastapi, dataclasses-json, azure-cosmos, azure-ai-inference, anthropic, aiohttp, unstructured, typer, transformers, torch, seaborn, rapidocr-onnxruntime, pdfplumber, opentelemetry-semantic-conventions, opentelemetry-instrumentation, msal, llama-index-core, langchain-core, jupyter-console, flashrank, cohere, azure-core-tracing-opentelemetry, altair, torchvision, streamlit, sentence-transformers, opentelemetry-sdk, opentelemetry-instrumentation-asgi, msal-extensions, llama-index-readers-file, llama-cloud-services, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-ollama, langchain-milvus, langchain-elasticsearch, langchain-anthropic, google-ai-generativelanguage, datasets, timm, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, llama-parse, langgraph-prebuilt, langchain-huggingface, langchain-google-genai, langchain, azure-identity, open-clip-torch, langgraph, langchain-community, langchain-azure-ai, chromadb, ragas, langchain-teddynote, langchain-experimental, langchain-cohere, langchain-chroma, jupyter\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.3\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.3:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.0\n",
      "    Uninstalling oauthlib-3.2.0:\n",
      "      Successfully uninstalled oauthlib-3.2.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.55\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.55:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.55\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.25.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.25.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.25.1\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.55\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.55:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.55\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.41\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.41:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.3.14\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.3.14:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.4\n",
      "    Uninstalling importlib-metadata-4.6.4:\n",
      "      Successfully uninstalled importlib-metadata-4.6.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.7.53\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.7.53:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.8.0.87\n",
      "    Uninstalling nvidia-cudnn-cu12-9.8.0.87:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.8.0.87\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 3.4.8\n",
      "    Uninstalling cryptography-3.4.8:\n",
      "      Successfully uninstalled cryptography-3.4.8\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.2.55\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.2.55:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 2.25.1\n",
      "    Uninstalling google-api-core-2.25.1:\n",
      "      Successfully uninstalled google-api-core-2.25.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0.dev20250319+cu128\n",
      "    Uninstalling torch-2.8.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torch-2.8.0.dev20250319+cu128\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.22.0.dev20250319+cu128\n",
      "    Uninstalling torchvision-0.22.0.dev20250319+cu128:\n",
      "      Successfully uninstalled torchvision-0.22.0.dev20250319+cu128\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0.dev20250319+cu128 requires torch==2.8.0.dev20250319, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed JPype1-1.6.0 Shapely-2.1.1 absl-py-2.3.1 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 altair-5.5.0 annotated-types-0.7.0 anthropic-0.64.0 appdirs-1.4.4 arxiv-2.1.3 asgiref-3.9.1 azure-ai-inference-1.0.0b9 azure-core-1.35.0 azure-core-tracing-opentelemetry-1.0.0b12 azure-cosmos-4.9.0 azure-identity-1.24.0 backoff-2.2.1 bcrypt-4.3.0 build-1.3.0 chardet-5.2.0 chroma-hnswlib-0.7.6 chromadb-0.6.3 click-8.2.1 cohere-5.17.0 coloredlogs-15.0.1 contourpy-1.3.3 cryptography-45.0.6 cycler-0.12.1 dataclasses-json-0.6.7 datasets-4.0.0 deepl-1.21.1 deprecated-1.2.18 dill-0.3.8 dirtyjson-1.0.8 diskcache-5.6.3 dnspython-2.7.0 docx2txt-0.8 durationpy-0.10 elastic-transport-8.17.1 elasticsearch-8.19.0 emoji-2.14.1 eval-type-backport-0.2.2 faiss-cpu-1.10.0 fastapi-0.116.1 fastavro-1.12.0 feedparser-6.0.11 filetype-1.2.0 flashrank-0.2.10 flatbuffers-25.2.10 fonttools-4.59.0 frozenlist-1.7.0 ftfy-6.3.1 gitdb-4.0.12 gitpython-3.1.45 google-ai-generativelanguage-0.6.18 google-api-core-1.34.1 google-search-results-2.4.2 grandalf-0.8 greenlet-3.2.4 grpc-gateway-protoc-gen-openapiv2-0.1.0 grpcio-1.67.1 grpcio-status-1.49.0rc1 html5lib-1.1 httptools-0.6.4 httpx-sse-0.4.0 huggingface-hub-0.29.3 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.5.2 isodate-0.7.2 jiter-0.10.0 joblib-1.5.1 jsonpatch-1.33 jupyter-1.1.1 jupyter-console-6.6.3 kiwipiepy-0.20.4 kiwipiepy_model-0.20.0 kiwisolver-1.4.9 konlpy-0.6.0 kubernetes-33.1.0 langchain-0.3.21 langchain-anthropic-0.3.10 langchain-azure-ai-0.1.2 langchain-chroma-0.2.2 langchain-cohere-0.4.3 langchain-community-0.3.20 langchain-core-0.3.46 langchain-elasticsearch-0.3.2 langchain-experimental-0.3.4 langchain-google-genai-2.1.0 langchain-huggingface-0.1.2 langchain-milvus-0.1.8 langchain-ollama-0.2.3 langchain-openai-0.3.9 langchain-teddynote-0.3.44 langchain-text-splitters-0.3.7 langchainhub-0.1.21 langdetect-1.0.9 langgraph-0.3.18 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.74 langsmith-0.3.18 lark-1.2.2 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-core-0.11.23 llama-index-readers-file-0.2.2 llama-parse-0.6.4.post1 lxml-5.3.1 lz4-4.4.4 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-3.10.1 mdurl-0.1.2 milvus-lite-2.5.1 mmh3-4.1.0 msal-1.33.0 msal-extensions-1.3.1 multidict-6.6.4 multiprocess-0.70.16 mypy-1.15.0 mypy_extensions-1.1.0 narwhals-2.1.1 nltk-3.9.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 oauthlib-3.3.1 olefile-0.47 ollama-0.5.3 onnxruntime-1.22.1 open-clip-torch-2.31.0 openai-1.67.0 opencv-python-4.11.0.86 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.11.2 ormsgpack-1.10.0 pandas-2.2.3 pdf2image-1.17.0 pdfminer-six-20231228 pdfplumber-0.11.5 pillow-10.4.0 pinecone-5.4.2 pinecone-client-3.2.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.11.0 posthog-6.5.0 propcache-0.3.2 protobuf-3.20.3 pyarrow-21.0.0 pyclipper-1.3.0.post6 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.10.1 pydeck-0.9.1 pymilvus-2.5.5 pymongo-4.14.0 pymupdf-1.25.4 pymupdf4llm-0.0.17 pypdf-4.3.1 pypdfium2-4.30.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 ragas-0.2.14 rank-bm25-0.2.2 rapidfuzz-3.13.0 rapidocr-onnxruntime-1.4.4 redis-5.2.1 regex-2025.7.34 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.1.0 rouge-score-0.1.2 safetensors-0.6.2 scikit-learn-1.6.1 scipy-1.16.1 seaborn-0.13.2 sentence-transformers-5.1.0 sgmllib3k-1.0.0 shellingham-1.5.4 simsimd-6.5.0 smmap-5.0.2 sqlalchemy-2.0.39 starlette-0.47.2 streamlit-1.43.2 striprtf-0.0.26 sympy-1.13.1 tavily-python-0.7.10 tenacity-8.5.0 threadpoolctl-3.6.0 tiktoken-0.9.0 timm-1.0.19 tokenizers-0.21.4 toml-0.10.2 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 transformers-4.50.3 triton-3.2.0 typer-0.16.0 types-pyyaml-6.0.12.20250809 types-requests-2.32.4.20250809 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 ujson-5.10.0 unstructured-0.17.0 unstructured-client-0.32.3 uvicorn-0.35.0 uvloop-0.21.0 watchdog-6.0.0 watchfiles-1.1.0 websockets-15.0.1 wikipedia-1.4.0 wrapt-1.17.3 xxhash-3.5.0 yarl-1.20.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/teddylee777/langchain-kr/main/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDrive\n",
      "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.4/987.4 kB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-api-python-client>=1.2 (from PyDrive)\n",
      "  Downloading google_api_python_client-2.179.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting oauth2client>=4.0.0 (from PyDrive)\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.11/dist-packages (from PyDrive) (6.0.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.20.2)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyasn1>=0.1.7 (from oauth2client>=4.0.0->PyDrive)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyasn1-modules>=0.0.5 (from oauth2client>=4.0.0->PyDrive)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa>=3.1.4 (from oauth2client>=4.0.0->PyDrive)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/lib/python3/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.16.0)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->PyDrive)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2025.1.31)\n",
      "Downloading google_api_python_client-2.179.0-py3-none-any.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m421.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Building wheels for collected packages: PyDrive\n",
      "  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyDrive: filename=pydrive-1.3.1-py3-none-any.whl size=27539 sha256=9a4cbf8a71f219c67737b3d3c78ffaeed5522e478b1043cef05262da4a01c88f\n",
      "  Stored in directory: /root/.cache/pip/wheels/31/d5/09/88865e0059104686eb8365ca1d36a8b27deef34232c3b62c90\n",
      "Successfully built PyDrive\n",
      "Installing collected packages: uritemplate, pyasn1, protobuf, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, oauth2client, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, PyDrive\n",
      "Successfully installed PyDrive-1.3.1 cachetools-5.5.2 google-api-core-2.25.1 google-api-python-client-2.179.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 googleapis-common-protos-1.70.0 oauth2client-4.1.3 proto-plus-1.26.1 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 uritemplate-4.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mykeys\n",
    "\n",
    "project_name = 'CH04_Huggingface'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = mykeys.get_key('LANG')\n",
    "os.environ[\"OPENAI_API_KEY\"] = mykeys.get_key('GPT')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = mykeys.get_key('GOO')\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = mykeys.get_key('HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH04_Huggingface\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# set_enable=False 로 지정하면 추적을 하지 않습니다.\n",
    "logging.langsmith(project_name, set_enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m413.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf-xet, huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.29.3\n",
      "    Uninstalling huggingface-hub-0.29.3:\n",
      "      Successfully uninstalled huggingface-hub-0.29.3\n",
      "Successfully installed hf-xet-1.1.7 huggingface_hub-0.34.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|system|>\n",
    "You are a helpful assistant.<|end|>\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.20.3\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.20.3) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.20.3) (2025.1.31)\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.34.4\n",
      "    Uninstalling huggingface-hub-0.34.4:\n",
      "      Successfully uninstalled huggingface-hub-0.34.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.50.3 requires huggingface-hub<1.0,>=0.26.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.20.3 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires huggingface-hub>=0.23.0, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub==0.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m chain = prompt | llm | StrOutputParser()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is the capital of South Korea?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:1526\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1523\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1525\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1528\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1529\u001b[39m     )\n\u001b[32m   1530\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = invocation_params[\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    313\u001b[39m         json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: invocation_params},\n\u001b[32m    314\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    315\u001b[39m         task=\u001b[38;5;28mself\u001b[39m.task,\n\u001b[32m    316\u001b[39m     )\n\u001b[32m    317\u001b[39m     response_text = json.loads(response.decode())[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# 사용할 모델의 저장소 ID를 설정합니다.\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=256,  # 생성할 최대 토큰 길이를 설정합니다.\n",
    "    temperature=0.1,\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],  # 허깅페이스 토큰\n",
    ")\n",
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "response = chain.invoke({\"question\": \"what is the capital of South Korea?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import os\n",
    "\n",
    "client = InferenceClient(\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    ")\n",
    "\n",
    "# LLMChain을 초기화하고 프롬프트와 언어 모델을 전달합니다.\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "# 질문을 전달하여 LLMChain을 실행하고 결과를 출력합니다.\n",
    "response = chain.invoke({\"question\": \"what is the capital of South Korea?\"})\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n",
    "response = client.text_generation(\n",
    "    prompt=\"What is the capital of South Korea?\",\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Endpoint URL을 아래에 설정합니다.\n",
    "hf_endpoint_url = \"https://slcalzucia3n7y3g.us-east-1.aws.endpoints.huggingface.cloud\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m llm = HuggingFaceEndpoint(\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 엔드포인트 URL을 설정합니다.\u001b[39;00m\n\u001b[32m      3\u001b[39m     endpoint_url=hf_endpoint_url,\n\u001b[32m      4\u001b[39m     max_new_tokens=\u001b[32m512\u001b[39m,\n\u001b[32m      5\u001b[39m     temperature=\u001b[32m0.01\u001b[39m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 주어진 프롬프트에 대해 언어 모델을 실행합니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m대한민국의 수도는 어디인가요?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:1526\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1523\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1525\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1528\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1529\u001b[39m     )\n\u001b[32m   1530\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = invocation_params[\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    313\u001b[39m         json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: invocation_params},\n\u001b[32m    314\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    315\u001b[39m         task=\u001b[38;5;28mself\u001b[39m.task,\n\u001b[32m    316\u001b[39m     )\n\u001b[32m    317\u001b[39m     response_text = json.loads(response.decode())[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    # 엔드포인트 URL을 설정합니다.\n",
    "    endpoint_url=hf_endpoint_url,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.01,\n",
    ")\n",
    "\n",
    "# 주어진 프롬프트에 대해 언어 모델을 실행합니다.\n",
    "llm.invoke(input=\"대한민국의 수도는 어디인가요?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\n",
    "# Human: {prompt}\n",
    "# Assistant:\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\",\n",
    "        ),\n",
    "        (\"user\", \"Human: {question}\\nAssistant: \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m대한민국의 수도는?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:1526\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1523\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1525\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1528\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1529\u001b[39m     )\n\u001b[32m   1530\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = invocation_params[\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    313\u001b[39m         json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: invocation_params},\n\u001b[32m    314\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    315\u001b[39m         task=\u001b[38;5;28mself\u001b[39m.task,\n\u001b[32m    316\u001b[39m     )\n\u001b[32m    317\u001b[39m     response_text = json.loads(response.decode())[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "chain.invoke(\"대한민국의 수도는?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HuggingFace Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스 모델/토크나이저를 다운로드 받을 경로\n",
    "# (예시)\n",
    "\n",
    "import os\n",
    "\n",
    "# ./cache/ 경로에 다운로드 받도록 설정\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"./cache/\"\n",
    "os.environ[\"HF_HOME\"] = \"./cache/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-16267mhm\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-16267mhm\n",
      "  Resolved https://github.com/huggingface/transformers to commit e446372f76fea9b2768c311286659420ec139348\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.56.0.dev0)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (1.1.7)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.56.0.dev0-py3-none-any.whl size=12387064 sha256=32ce79180fbe23e8d057328c2bfec890194154813b51791a8a87494d51b8cbf0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_o72sjo8/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, transformers, accelerate\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.50.3\n",
      "    Uninstalling transformers-4.50.3:\n",
      "      Successfully uninstalled transformers-4.50.3\n",
      "Successfully installed accelerate-1.10.0 huggingface-hub-0.34.4 transformers-4.56.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.0.dev0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import transformers python package. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_pipeline.py:99\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m    100\u001b[39m         AutoModelForCausalLM,\n\u001b[32m    101\u001b[39m         AutoModelForSeq2SeqLM,\n\u001b[32m    102\u001b[39m         AutoTokenizer,\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline \u001b[38;5;28;01mas\u001b[39;00m hf_pipeline  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py:28\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m     31\u001b[39m     is_essentia_available,\n\u001b[32m     32\u001b[39m     is_g2p_en_available,\n\u001b[32m     33\u001b[39m     is_librosa_available,\n\u001b[32m     34\u001b[39m     is_mistral_common_available,\n\u001b[32m     35\u001b[39m     is_pretty_midi_available,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_mistral_common_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_huggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m llm = \u001b[43mHuggingFacePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmicrosoft/Phi-3-mini-4k-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_new_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m llm.invoke(\u001b[33m\"\u001b[39m\u001b[33mHugging Face is\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_pipeline.py:107\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline \u001b[38;5;28;01mas\u001b[39;00m hf_pipeline  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    110\u001b[39m     )\n\u001b[32m    112\u001b[39m _model_kwargs = model_kwargs.copy() \u001b[38;5;28;01mif\u001b[39;00m model_kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Could not import transformers python package. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "llm.invoke(\"Hugging Face is\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텍스트:\n",
      "\n",
      "A Large Language Model (LLM) like me, ChatGPT, is a type of artificial intelligence (AI) model designed to understand, generate, and interact with human language. These models are \"large\" because they're built from vast amounts of text data and have billions or even trillions of parameters. Parameters are the aspects of the model that are learned from training data; they are essentially the internal settings that determine how the model interprets and generates language. LLMs work by predicting the next word in a sequence given the words that precede it, which allows them to generate coherent and contextually relevant text based on a given prompt. This capability can be applied in a variety of ways, from answering questions and composing emails to writing essays and even creating computer code. The training process for these models involves exposing them to a diverse array of text sources, such as books, articles, and websites, allowing them to learn language patterns, grammar, facts about the world, and even styles of writing. However, it's important to note that while LLMs can provide information that seems knowledgeable, their responses are generated based on patterns in the data they were trained on and not from a sentient understanding or awareness. The development and deployment of LLMs raise important considerations regarding accuracy, bias, ethical use, and the potential impact on various aspects of society, including employment, privacy, and misinformation. Researchers and developers continue to work on ways to address these challenges while improving the models' capabilities and applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Summarizes TEXT in simple bullet points ordered from most important to least important.\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "KeyPoints: \"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm\n",
    "\n",
    "text = \"\"\"A Large Language Model (LLM) like me, ChatGPT, is a type of artificial intelligence (AI) model designed to understand, generate, and interact with human language. These models are \"large\" because they're built from vast amounts of text data and have billions or even trillions of parameters. Parameters are the aspects of the model that are learned from training data; they are essentially the internal settings that determine how the model interprets and generates language. LLMs work by predicting the next word in a sequence given the words that precede it, which allows them to generate coherent and contextually relevant text based on a given prompt. This capability can be applied in a variety of ways, from answering questions and composing emails to writing essays and even creating computer code. The training process for these models involves exposing them to a diverse array of text sources, such as books, articles, and websites, allowing them to learn language patterns, grammar, facts about the world, and even styles of writing. However, it's important to note that while LLMs can provide information that seems knowledgeable, their responses are generated based on patterns in the data they were trained on and not from a sentient understanding or awareness. The development and deployment of LLMs raise important considerations regarding accuracy, bias, ethical use, and the potential impact on various aspects of society, including employment, privacy, and misinformation. Researchers and developers continue to work on ways to address these challenges while improving the models' capabilities and applications.\"\"\"\n",
    "print(f\"입력 텍스트:\\n\\n{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# chain 실행\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py:3025\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3023\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3024\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3025\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m   3026\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3027\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:390\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    386\u001b[39m     **kwargs: Any,\n\u001b[32m    387\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    388\u001b[39m     config = ensure_config(config)\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    401\u001b[39m         .text\n\u001b[32m    402\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:763\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **kwargs: Any,\n\u001b[32m    761\u001b[39m ) -> LLMResult:\n\u001b[32m    762\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:966\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    952\u001b[39m     run_managers = [\n\u001b[32m    953\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    954\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m    964\u001b[39m         )\n\u001b[32m    965\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    778\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    779\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    786\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    791\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    795\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    796\u001b[39m         )\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/llms.py:1526\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1523\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1525\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1527\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1528\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1529\u001b[39m     )\n\u001b[32m   1530\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    309\u001b[39m     invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = invocation_params[\n\u001b[32m    310\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    313\u001b[39m         json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: invocation_params},\n\u001b[32m    314\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    315\u001b[39m         task=\u001b[38;5;28mself\u001b[39m.task,\n\u001b[32m    316\u001b[39m     )\n\u001b[32m    317\u001b[39m     response_text = json.loads(response.decode())[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "# chain 실행\n",
    "response = chain.invoke({\"text\": text})\n",
    "\n",
    "# 결과 출력\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hugging Face Local Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import transformers python package. Please install it with `pip install transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/huggingface_pipeline.py:92\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     93\u001b[39m         AutoModelForCausalLM,\n\u001b[32m     94\u001b[39m         AutoModelForSeq2SeqLM,\n\u001b[32m     95\u001b[39m         AutoTokenizer,\n\u001b[32m     96\u001b[39m     )\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline \u001b[38;5;28;01mas\u001b[39;00m hf_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py:28\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m     31\u001b[39m     is_essentia_available,\n\u001b[32m     32\u001b[39m     is_g2p_en_available,\n\u001b[32m     33\u001b[39m     is_librosa_available,\n\u001b[32m     34\u001b[39m     is_mistral_common_available,\n\u001b[32m     35\u001b[39m     is_pretty_midi_available,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_mistral_common_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# HuggingFace 모델을 다운로드 받습니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m hf = \u001b[43mHuggingFacePipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeomi/llama-2-ko-7b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 사용할 모델의 ID를 지정합니다.\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 수행할 작업을 지정합니다. 여기서는 텍스트 생성입니다.\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 파이프라인에 전달할 추가 인자를 설정합니다. 여기서는 생성할 최대 토큰 수를 10으로 제한합니다.\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_new_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/langchain_community/llms/huggingface_pipeline.py:100\u001b[39m, in \u001b[36mHuggingFacePipeline.from_model_id\u001b[39m\u001b[34m(cls, model_id, task, backend, device, device_map, model_kwargs, pipeline_kwargs, batch_size, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline \u001b[38;5;28;01mas\u001b[39;00m hf_pipeline\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    105\u001b[39m _model_kwargs = model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    106\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id, **_model_kwargs)\n",
      "\u001b[31mImportError\u001b[39m: Could not import transformers python package. Please install it with `pip install transformers`."
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "# HuggingFace 모델을 다운로드 받습니다.\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"beomi/llama-2-ko-7b\",  # 사용할 모델의 ID를 지정합니다.\n",
    "    task=\"text-generation\",  # 수행할 작업을 지정합니다. 여기서는 텍스트 생성입니다.\n",
    "    # 파이프라인에 전달할 추가 인자를 설정합니다. 여기서는 생성할 최대 토큰 수를 10으로 제한합니다.\n",
    "    pipeline_kwargs={\"max_new_tokens\": 512},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_mistral_common_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer, pipeline\n\u001b[32m      4\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mbeomi/llama-2-ko-7b\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 사용할 모델의 ID를 지정합니다.\u001b[39;00m\n\u001b[32m      5\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m      6\u001b[39m     model_id\n\u001b[32m      7\u001b[39m )  \u001b[38;5;66;03m# 지정된 모델의 토크나이저를 로드합니다.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m     31\u001b[39m     is_essentia_available,\n\u001b[32m     32\u001b[39m     is_g2p_en_available,\n\u001b[32m     33\u001b[39m     is_librosa_available,\n\u001b[32m     34\u001b[39m     is_mistral_common_available,\n\u001b[32m     35\u001b[39m     is_pretty_midi_available,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_available \u001b[38;5;28;01mas\u001b[39;00m is_bitsandbytes_available\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_mistral_common_available' from 'transformers.utils' (/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"beomi/llama-2-ko-7b\"  # 사용할 모델의 ID를 지정합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id\n",
    ")  # 지정된 모델의 토크나이저를 로드합니다.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)  # 지정된 모델을 로드합니다.\n",
    "# 텍스트 생성 파이프라인을 생성하고, 최대 생성할 새로운 토큰 수를 10으로 설정합니다.\n",
    "pipe = pipeline(\"text-generation\", model=model,\n",
    "                tokenizer=tokenizer, max_new_tokens=512)\n",
    "# HuggingFacePipeline 객체를 생성하고, 생성된 파이프라인을 전달합니다.\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m prompt = PromptTemplate.from_template(template)  \u001b[38;5;66;03m# 템플릿을 사용하여 프롬프트 객체 생성\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 프롬프트와 언어 모델을 연결하여 체인 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m chain = prompt | \u001b[43mhf\u001b[49m | StrOutputParser()\n\u001b[32m     14\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33m대한민국의 수도는 어디야?\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 질문 정의\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     17\u001b[39m     chain.invoke({\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question})\n\u001b[32m     18\u001b[39m )  \u001b[38;5;66;03m# 체인을 호출하여 질문에 대한 답변 생성 및 출력\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'hf' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the following question in Korean.\n",
    "#Question: \n",
    "{question}\n",
    "\n",
    "#Answer: \"\"\"  # 질문과 답변 형식을 정의하는 템플릿\n",
    "prompt = PromptTemplate.from_template(template)  # 템플릿을 사용하여 프롬프트 객체 생성\n",
    "\n",
    "# 프롬프트와 언어 모델을 연결하여 체인 생성\n",
    "chain = prompt | hf | StrOutputParser()\n",
    "\n",
    "question = \"대한민국의 수도는 어디야?\"  # 질문 정의\n",
    "\n",
    "print(\n",
    "    chain.invoke({\"question\": question})\n",
    ")  # 체인을 호출하여 질문에 대한 답변 생성 및 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMs2OSEsEhI+eP+P38efuYH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
